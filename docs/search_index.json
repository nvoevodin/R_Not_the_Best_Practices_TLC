[
["index.html", "R, Not the Best Practices Preface 0.1 What This Book Is and Is Not 0.2 What Will This Book Teach You", " R, Not the Best Practices Nikita Voevodin 2020-02-20 Preface R, Not the Best Practices by Nikita Voevodin is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. Welcome to R, Not the Best Practices. You, probably, selected this book for one of the following three reasons; one, you saw the title, the cover and thought well this might be interesting. Two, you know that books that are called something something, best practices are hard to follow, because they are written by someone who already forgot how it feels to not know anything. Third, someone referred you to this book, because they learned a lot from it themselves. My hope is that your reason is somewhere between the second and third points; although even if it is the first, you will not regret it. Why is this book called Not the Best Practices? Simple; you do not learn by looking at perfect code. If I wrote a vectorized loop with a custom function and told you that it was the most efficient way and best practice, you likely would never understand what the hell was going on and probably would quit. That was my experience with the majority of tutorials that I went through; at some point I would just stop getting what was going on. But because I had invested some time and money into a course, I would force myself through it regardless. Unfortunately, that tactic results in very little progress and a lot of frustration and discouragement. Writing this book, I want it to be nothing like those experiences. There will be some boring, basic things that I just have to cover, but the majority of it will be practical and interactive. 0.1 What This Book Is and Is Not This book is not written by an academic. I am not an R professor or creator of some fancy library. I am a professional data analyst and an R, SQL and JavaScript practitioner. This book is not a set of best practices. I do not care about the cleanliness of your code, especially at this stage in your R career. The only thing that matters is whether your code gets the job done; best practices will come later. This book is a set of tips, tricks and hacks, both good and bad, that will make things work for you when you need them to. This book will not filter words. I believe that learning to code can be dull, boring, and discouraging. Therefore, I will try to maintain your interest by using some seasoned language. In fact, this is the ‘Vanilla’ version of this book available. I if prefer spicy language, go to the 18+ version of this book. This book will not use stupid generic data. I have seen and practiced with a bunch of stupid and semi-generic data that makes no sense. It really traumatized me and I do not want you to experience the same pain. Not only will we be working with real data (real vehicles vin numbers, and NYPD car crash data), but also, we will be pulling that data from a real SQL database that I specifically set up for this book. You can be sure that we will not be writing stupid ‘hello world’ examples at every turn. By the end of this book you will have something interesting to show for the time that you invested. This book is not only about R. In production, R goes hand in hand with other languages. The most important one we will cover is SQL, the language of database interaction. We will be using a SQL database and the SQL language to write commands and pull our practice data into R. In addition I will also explain a good deal about other programming languages and how they interact or do not interact with R. Finally, this book was never intended for you (I’m kind of kidding). When coding, after a while, you will begin to forget everything you learned; as a developer the world moves quickly and you are constantly learning new things. This book is therefore my documentation, a reminder of the things I have done and processes I have built; perhaps as a consequence you might learn a thing or two so stick around. 0.2 What Will This Book Teach You This book will follow the first three months of learning R at my new job. Before that I was just okay at computers. I played games, used the interweb and Microsoft Word and Excel for professional stuff. I did not know anything about programming nor did I know a single programmer. Code for me was just that, code, a random string of matrix letters that meant nothing. Since the memories of not knowing anything are still fresh, I feel quite confident that I should be able to put myself in your shoes and bring you to the level of proficiency that you should be after learning R for three months. Yes, three months. This book will cover my first quarter of dealing with R and programming in general. You may be thinking, oh man, this guy will only show me some real basic stuff! You are wrong. I will show you basic stuff, there is no way around it, if you want to learn. However, most of this book deals with practical examples, things that you face ninety five percent of the time. For instance, the core of this book revolves around the main assignment I received on the second week of my job. That assignment took me off guard and it took me two months of non-stop learning in R and SQL to complete. By the end of that assignment I felt comfortable with most basic tasks where I needed to work with data. I will lead you through the same experience with many tips and tricks along the way. You will learn how to interact with databases in R, pull data, aggregate and reshape it to your liking; merge it with other data; save it; work with different data and time formats; create useful static and dynamic plots; fit all that nice stuff into presentable reports; create bad and great maps; use all that again to create dashboards; and finally build a simple web app as a bonus. Along the way, I will be telling you about mine and other programmers’ experiences and touch on some peripheral programming topics. If all that is not enough for you, feel free to close this book and get yourself something like R for Dummies or something. This book is, ultimately, what and how I wanted to be taught when I was a noob. Special thanks go to Fausto Lopez for proofreading this book. Fausto is a Director of Data Engineering &amp; Analytics at NYC Taxi and Limousine Commission. "],
["languages-infrastructure-and-myself.html", "Languages, Infrastructure, and Myself 0.3 Programming Languages and R’ Place Among Them 0.4 About Infrastructure 0.5 About Me", " Languages, Infrastructure, and Myself 0.3 Programming Languages and R’ Place Among Them 0.3.1 R Let’s face it, you are new to programming and explaining that R is a functional language and that Java is an object-oriented language won’t make any sense to you. Instead, I’ll give you a few of my thoughts on how I see the R universe, and how it interacts with other languages. I will not cover all the languages, not even close, and I might not even be hundred percent accurate all the time; however, I will cover everything that I think you need to start with R and reach a solid post-noob level. The goal here is to make sure you have an overall understanding of the environment you are working in. I want to make sure that you retain as much information as possible. Once you feel comfortable with your level, obviously, go ahead and learn some advanced geek stuff about different languages, the who the what the why. Firstly, R is an open-source aka free programming language that focuses on working with data, statistical computation, and graphical visualization. It is widely used by academics, statisticians, data miners, and big data companies to work with all sorts of information. Just to give you a perspective of how popular it is in its field, here is a list of 10 largest R users: Facebook Google Twitter Microsoft Uber Airbnb IBM HP Ford New York Times Some of these might not exist when you are reading this (UBER lol). These companies use R for things like behavior analysis, data forecasting, advanced visualizations and statistical modeling. We will not be doing those things, but it is good to know that the language that you are using is popular with some of the big names. Secondly, R is different from most other languages because of how it works with data; this is its main advantage and appeal. The following diagram spells out my thoughts on this point: Important Diagram. 0.3.2 Excel You’re probably familiar with Excel and know what an excel table looks like. When you start working with R, you’ll notice that tables are your bread and butter, just like in excel. Next you’ll probably think that tables are supported by every language, for example JavaScript, Java, PHP and other big ones. You are wrong. These languages do not work with data like Excel or R. Simple operations like joining two tables and aggregating, something that would take two or three lines of code in R, will require some substantial coding and time in those languages, especially if you are new. But how DO those languages work with data? It’s possible to use them for data analysis, but it’s simply not their specialty. Most of the time, these languages connect to a SQL database and use the SQL language to interact with tabular data. You don’t need to worry about that right now. All you need to remember is that R is designed to work with data, and you will be much more efficient using R compared to the languages mentioned above. But what about these other languages in the diagram? 0.3.3 STATA, SPSS, and SAS STATA, SPSS, and SAS are powerful but outdated and expensive statistical packages that also work with tabular data just like excel and R. They are not programming languages and unless you want to find yourself hungry, crawling on the floor looking for rats to eat in your studio that you share with some unemployed actor, because nobody wants that junk, I would recommend to stay away from them. 0.3.4 Python Python is a full-fledged general-purpose programming language. It’s very hot right now and it seems like every homeless guy knows it already. That, plus the fact that Python is not specifically built to work with data makes me think that a combination of R with something like JavaScript makes more sense. Don’t get me wrong, Python is a great and powerful language and is really dominating R at the moment. I used both and found R easier to set up and start working with. To put it simply, Python tries to mimic what R does natively by creating additional packages that are just not as powerful. Pythonistas might dispute that but if you are reading this, I am assuming that you have made your choice, at least for the moment, and I’m just trying to confirm that thought. 0.3.5 Diagram and Related Languages So to sum this up, if you look at the diagram again from right to left: Excel is a point and click tool and you should only use it for some final touches; STATA, SPSS, and SAS are the bottom of the barrel and you should stay away from them; and R and Python are both programming languages that you really can’t go wrong with. This was an overview of what R is and how it compares to some other similar and not so similar languages. Right now, though, we don’t need to know anything else about them, because we won’t be interacting with any of them for the first half of the book. There are four languages that we will be interacting with throughout this book. Don’t get scared, as they will be introduced very slowly. These languages are SQL, HTML, CSS, and JavaScript. If you never heard of them, don’t start googling them as you do not need them now. Maybe, google SQL, but that’s it. By the time you are finished with this book, you will have a some understanding of SQL. CSS, HTML and JavaScript will be introduced in the next books. However, I’ll still explain what they all do in this chapter. That’ll serve you well as an entry point to these languages should you decide to branch out beyond R. 0.3.6 SQL Let’s start with SQL. One of the things you’ll be doing almost every day is interacting with a database or databases. I know, because that’s what I’ve been doing since the second day at my R-requiring job. That is what I’m still doing today and that’s what I’ll be doing for as long as I am programming in any language. Here is a brief intro to SQL: SQL is sort of a programming language, but it really isn’t. It’s a language that you’ll use to interact with databases. You can’t really avoid using SQL as it’s the only way to get or add data from or to a database, and if there is another way that I don’t know about, then you don’t need to know about it at the moment either, because it’s definitely some nonsense way nobody uses. Just remember, SQL is your language for database interaction. SQL is important, and the best thing about it is that it is quite easy to pick up, at least the basics. SQL is quite easy. Obviously, there is a bunch of complicated and advanced stuff that you can do with SQL, but you will not need that now. Instead, we will do some very simple pulls in SQL and compliment it with some R language to clean and aggregate our data. After you finish the book and build a few small apps requiring some basic SQL, you will obviously spread your wings and learn some advanced SQL, but that will be later. So, that was SQL. If you’re new like I was a couple of years ago you also want to know what a database is and why we need it. A database is just that, a base with data, storage where you keep all kinds of information in the form of tables. Imagine an Excel table. If you can’t imagine an excel spreadsheet, then you should really take some prerequisites before continuing. Well, database is just a collection of such tables. Why can’t we just use an excel file for our data storage needs? We could, but an excel table can only hold so much. Imagine you’re running a store that sells 1 million bananas every day. You’ll have to create a new spreadsheet every day just to keep your banana selling records. What if you’re also selling some rifles? Your records will get out of hand very quickly and you’ll start losing a lot of information. Instead of paying attention to your weird banana/rifle selling business, you’ll be worrying about your excel spreadsheets not opening. Databases solve that problem. They are built specifically to store virtually infinite number of banana and rifle records and they help us link information across those tables. On top of that, databases are fast, and the SQL language makes working with them easy. So, remember, for a lot of data (millions of rows) we are using databases and SQL. You can still use an excel type of file to do some small jobs and share them via emails and so forth, nothing wrong with that; we will in fact do some of that. 0.3.7 About HTML/CSS/JavaScript Cascading Style Sheets. Fancy, right? CSS is not really a programming language; it’s a styling language. Every color, every curved line, sliding panel, animation, and all the fancy stuff that you see when you browse the internet or use apps is styled using CSS or at least some implementation of CSS. I mentioned that CSS is not a programming language; it’s instead a part of the family of three languages, HTML/CSS/JavaScript. Basically, these three languages power the modern internet. Nearly 100% of what you see when opening your browser is these languages. They DO work with other languages to do some stuff behind the scenes like shopping carts, statistics, machine learning, etc. but, generally, whatever you see in front of you is some combination of these three languages. To cement it in your head, I want you to think about these languages as a sentence structure. HTML is a noun; it defines the object. The object being a web page. So, HTML creates a web page, just an empty skeleton, no colors, no pop ups, no styling, nothing really works yet. All you are seeing are some text, some buttons, drop downs maybe, unformatted pictures, but they aren’t really doing anything yet. Hopefully, you get the picture. If not, check out the one below. JS/HTML/CSS as a sentence. CSS in this setup is the adjective; CSS adds colors, lines, animation, and other visuals to that empty web page that we created with HTML. At this point we have a nicely styled web page that doesn’t really do much, which you can get away with in some cases. Below is one of the Amazon pages. You can sometimes experience the view on the right when, let’s say, you lose internet connection. A server, first, loads the structure of a page and then applies the CSS. Below, the un-styled page is on the right and styled on the left. Html ith and without CSS. If you want your website or your app to do something, you’re going to need JavaScript. JavaScript in this setup is the verb that defines the actions of the page, the page that we just made with HTML and styled with CSS. A simple example of what JavaScript does in combination with the other two is the following: HTML creates a button; CSS makes it blue and its text white and adds animation to it when its clicked; JavaScript makes sure that when you click that button something happens, a plot is generated or a set of data is printed, or some calculation is happening and the result is shown on the screen. I hope this paints a clear picture of this family of languages and how they interact with each other, and with you. 0.3.8 Using the HTML/CSS/JavaScript in This Book. We are not going to touch on any of these in the first book. You will be learning the fundamentals of R and won’t be creating any web pages or web apps that would require styling or interactivity. You will start seeing some CSS styling starting with the second book, where we’ll start introducing you to the R library for creating web apps called Shiny. The third and fourth books will mostly revolve around Shiny and web apps, and that is where we will be using CSS, HTML, and JavaScript. Fortunately, Shiny is HTML/CSS/JavaScript all wrapped up in one, and that is its beauty. Using Shiny, you don’t need any prior knowledge of HTML, CSS, or JavaScript. Everything is wrapped for you in the nice package, and the only things that you need to worry about are the data, logic, and functionality of your app. Having said that, Shiny does limit you to its built-in styles and functionality. There are many auxiliary libraries surrounding Shiny that expand its functionality but sometimes, it won’t be possible to find exactly what we want. That’s where we’ll need CSS and a little bit of HTML and JavaScript. I’m letting you know right now, ahead of time that we won’t be doing a lot of HTML and JavaScript. We will use these two in small amounts, mostly in the form of tricks and hacks to make our apps look cool. Most of our customization will be done using CSS. Don’t sweat researching HTML and JavaScript, you won’t need any knowledge to keep up when we use it. To sum up: we’ll focus on R fundamentals and some SQL at first. In the later books, as we move into web applications and start using Shiny library, we’ll introduce some CSS; and once we move deeper and get better, we’ll be using much more CSS and adding some HTML and JavaScript hacks and tricks to make our apps look amazing. 0.4 About Infrastructure Apart from R itself, Shiny tools, SQL, and the side languages mentioned in the previous section, there is infrastructure. Infrastructure is everything that makes the production and consumption of your product possible. Infrastructure is very important. The infrastructure we cover in this and later books will include database and storage and hosting options, API calls, optimization, and some other tools like docker and electron, which also fall under the category of infrastructure. 0.4.1 Databases We’ve already covered some ground on databases and SQL. However, there is a second side to databases, building your own database. In that scenario, you’re serving as a data engineer providing infrastructure for yourself or for others. I will teach you to do that in the next books. You’ll use our database in this book. But I’m jumping ahead right now, you don’t need to worry about this for now. 0.4.2 Hosting Imagine that you’ve just built your first app. It’s now on your computer and you can play with it. Very cool, except, nobody else can really see it besides you. Your app must live somewhere else besides your computer, and hosting accomplishes just that. Hosting lets you release your product to the public. Same applies to web sites and databases. Good news is that there are free options for your hosting, and you can even set up your own straight from your home computer. Hosting and databases go hand in hand and will be two of the most important infrastructure topics in the following books. Other things will revolve around these two. 0.4.3 Other tools In the fourth book, we will start introducing more advanced concepts and tools like API calls, dockerized apps, optimization and some others. Even though I call these tools advanced, it doesn’t mean they are inherently hard to learn. In fact, they are much easier to pick up once you’re ready. The reason they’re in the advanced category is that you must first learn all the things that I’ve been talking about up until now before you even need to know what these advanced things do. The reality is you just don’t need them in the beginning. That was our brief introduction into the topic of infrastructure. The coolest thing about infrastructure is that it, maybe, sounds boring at first. You’re thinking, I just want to create something cool. And apps are what I and everybody see and that is why it is cool. Well, my answer to you is, You will be surprised, by how exciting it is to build your own database for the first time, connect to it, load and pull some data, and for all this to work. Or to set up your hosting, put your app there and open it from your phone and start sending that shit to your friends to brag. You will see, just like I did! All I’m saying is do not assume that back end (nerd’s term for the infrastructure that we are talking about now) is something boring or something you do not want to be doing. I can almost guarantee that once you’ve built your first few apps and showed them to people, you’ll be more exited to talk about the stuff behind that app, the stuff that makes it run. The picture in front of peoples’ eyes, the front-end, will become a noob thing at that point. 0.5 About Me In this section, I think, I’m trying to relate to you, a person with no computer science degree. It is a general idea that coding is hard. And what I say to this is, It is absolutely CORRECT! Coding is incredibly hard and all those pretend-gurus on YouTube that say learn xyz language in 20 minutes or 5 hours or 1 month are lying. Those videos are click bait that won’t teach you anything. It will take you at least 4-5 months of consistent everyday work to get to an initial comfort level. Now, having said all that downbeat stuff, I want to assure you that you don’t need a computer science degree to become a professional software engineer or a data engineer or a database engineer. I don’t hold a computer science degree; yet, I’ve been quite successful with coding and feel qualified to teach you. But what about those people who went to school for this? Firstly, you should only worry about your own skills as there will always be better programmers than you. So what? The demand for coding specialists will only increase and there will never be enough people who programmed since kindergarten. That’s where YOU come in. Secondly, what do you think kids at college do? At best, if they’re full-time, they go to school twice a week, take two coding classes at best (A WEEK), then some other two useless classes like underwater poetry and hipster studies just to graduate. After that, they go home and relax for the rest of the week or play video games or both. Only a minority will commit an appropriate amount of time to learning code. What do you think they know in the end? Obviously, they’re going to have some fancy resume that will say something like Python, C++, JavaScript, PHP, Spark mumbo jumbo. But when you sit them down and ask them to build something, they’ll be lost. It’s not to say that there is much wrong with learning at the job, it’s just I don’t want you to operate under assumption that you’re so far behind its impossible to catch up. I recently watched a documentary about hackers and the companies guarding against them. In that documentary they showed unpaid guys in their hoodies, hacking and learning from home every day, almost all day, way past nine to five with real commitment and intent, just for fun. At the same time, they show a private company with a bunch of college graduates-programmers struggling to prevent their clients from hacker attacks. You can see all that nice equipment, interactive maps, and so forth. But they still lose to those hackers a lot of times. Why is that? The reason is dedication. I am sure there are exceptions, but just like with college students, majority of employees are there nine to five, they will take any break possible and are really looking forward to the end of the day, or to accumulate enough vacation days to get the out for a while. The hacker bro, on the other hand, sits there and learns relentlessly about some new cool way to mess someone up. You might say, but he is outnumbered. In programming, you are only as good as the number of hours that you have coded, not the number of degrees you got or years you have spent to get them. A hacker doesn’t need to spend more hours programming than the whole team of that company combined, just more than their best programmer. In that situation, it’s like a case of zero multiplied by any number is still zero. If that hacker is much better than their best person, he will run circles around them, and they won’t be able to do much. This little story is just my way to cement something in your head. Unlike medical or legal fields, in coding, you are only as good as your code. And the only way to improve is to code. Certificates alone will not get you very far. So, what makes me say with confidence that you do not need a degree to succeed at this, and moreover, what makes me qualified to teach you all these things? Well allow me to introduce myself, the anti-hero of this book. My name is Nikita Voevodin, I am a professional data analyst and software developer with a concentration in interactive visualizations and database infrastructure. I spent the last half of the decade doing legislative, budget, policy, and data analysis for New York City and New York State. My work involved developing and automating big data processes, building and interacting with databases, creating apps and dashboards for my superiors and the public, as well as conducting high level research to empower legislation in the area of city transportation. I hold three separate degrees, BS in economics, BA in political science, and MPA in public policy. As you can see, I don’t hold a degree in computer science, or anything related. In fact, apart from having a PC since I was nine and using it mostly for games, and learning some excel in college, I had no coding background of any kind. I never even knew anybody who coded. This book is the chronological representation of my progress from zero to a quite high level of proficiency. Now, what makes me qualified to teach you? Ultimately, you will be the judge of that, but I would also like to list some of my portfolio items in R. First, I went from knowing practically nothing about programming to doing some advanced stuff within a year. Secondly, I am an author or co-author of R Shiny apps like: 0.5.1 TLC DataHub The ‘Hub’ as I call it, is by far the most complete and advanced thing that I created. It is used by hundreds of users every day and is listed on the front page of the Taxi &amp; Limousine Commission of New York City. Here is the intro about it: TLC Data Hub offers users a new and convenient location to access and visualize taxi and for hire industry data. TLC Data Hub uses public data available on NYC Open Data and the TLC website and does not use, track or display any private information of the drivers or companies. The Hub currently consists of two dashboards. The Trip Viz dashboard allows the public to run queries on TLC-collected trip data while the ‘Industry metrics’ dashboard provides standard visualizations of monthly industry trends. TLC Data Hub 0.5.2 TLC VIN Decoder The decoder is a utility app that utilizes the NHTSA API to give you a lot of useful information about either a single vehicle or a list of vehicles that you pass into it. It is used by the Taxi &amp; Limousine Commission of New York City to keep track of electric vehicles, for example. TLC VIN Decoder 0.5.3 TLC DataMeetup App I am or used to be a host of monthly data meetups at TLC. TLC Data Meetup is or was a venue where employees interested in technology would come together to share ideas, tips, and tricks in relation to technology and their research. My manager Fausto Lopez and I created the following app to streamline the processes of registration and presentation. TLC Data Meetup App Components from these apps will become the base for this and the following books. Finally, I have built databases, countless algorithms, and have completed multiple large data analysis projects for different agencies within the City of New York. Most importantly, I taught all these things to myself, I have clear understanding of what it is like to start from scratch, and I have a vision of how a completely new-to-programming person should start learning code. 0.5.4 Flow of This Book As I said before, coding is mostly dry and dull subject for most people. My goal, therefore, is to keep your attention and interest for as long as possible. Besides spicy language and seasoned jokes, I decided to add an element of a story telling. The story will not be present everywhere, because there are some basics that we just must run through. However, I’ll try to keep the whole thing in the boundaries of the story, which, in the first book, is based on my first three - four months of learning R. Let the game begin! Or, RELEASE the KRAKEN! R, Not the Best Practices by Nikita Voevodin is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. "],
["first-three-months-maggot.html", "First Three Months (Maggot) 0.6 Messing Around", " First Three Months (Maggot) Congratulations, you’ve accepted that job offer and are just waiting for that first day. The job description mentioned the need for some experience working with data and some good excel knowledge. But during your interviews you noticed something; your interviews were more on the technical side and a lot of people in the office were using those dark screen hacking terminals that you’ve only seen on TV. Nobody told you that you needed to learn programming, but you’re suspecting that you just might have to. Disclaimer: I don’t expect your situation to be similar. It doesn’t have to be. You might be looking for a job and just trying to improve your chances, or you already have a job and want to acquire a new skill. To keep this book somewhat interesting, as I mentioned before, we will follow my path to R proficiency. Hopefully, you can relate to my story. Anyway, you sit home and google some R tutorials and don’t really know where to start. Before I list some good resources that I used to start, we’re going to need to install R and R Studio on your computer. First, what is the difference between R and Rstudio? R is a programming language just like any other language; before you start using it, it has to be installed. If you ever played video games on your computer, you should be familiar with those damn messages: install the latest C++ dll something. Basically, when you see this message, it means that the programming language that your game runs on is not there or is outdated. Once you install that update, your game runs. Games are built using computer languages (usually, something like C++ or C# for big games and Java or Python for small ones). When you are playing a game, there are scripts running in the background that you do not even see. Same is needed to start coding. In our case, we need to install R. What is Rstudio then? Rstudio is basically a notepad (also called text editor) that understands the R language and makes it run. There are many text editors out there, but Rstudio is built specifically for R and it’s the one you should use. Once you develop your skills a bit more, you can start looking at other text editors. For example, the most popular general use text editor right now is Visual Studio Code. You can use it for R, but it’s not built for data analysis so don’t worry about it right now. Let’s jump straight into the Rstudio installation process. I won’t hold your hand too much during the installation process. If you want to actually learn to code, some things you’ll have to figure out on your own. Both R and Rstudio will run on every major operation system. For example, I am using Linux Ubuntu, but I also have them installed on my windows PC at work, and I previously used them on MAC as well. Once installed, everything will run just the same on any platform. So, go to one of R repositories to install R. Downloading R. After that is done, go to the Rstudio page and install the latest Rstudio for your system. Downloading RStudio. That’s it. We are ready to start coding. Well, in your case, let the horrible grind of the first few weeks begin! 0.6 Messing Around Your boss sits you down and tells you: play with R for a while, I’ll give you your first task in a couple of days. Your first few days at the job are slow and encouraging. You are meeting new people and everything is nice. Things are being installed on your computer and, for now, you’re just reading some literature about your organization and some of the latest initiatives. Your boss gives you some space to settle down and play around with your new setup. He tells you that your first task will be cleaning some of his old code. Your naive ears hear, take your time, your first assignment will be easy, you will just add some commas and some narrative to my code. Nothing to worry about. 0.6.1 First Script First thing to do is to open the Rstudio. When you open it for the first time you should see something like this: RStudio. Go ahead and create your first script. For that, go to the upper left corner, click on the + icon, and chose the R script option, which should be first. You should see something similar to the picture below. Get used to this view as it will be the one you will be seeing a lot from now on. RStudio. 0.6.2 Layout Rstudio is quite a complicated text editor. It has a shit ton of advanced features and settings. I myself don’t even know most of them, and absolutely encourage you to look into them once you know what the hell you’re doing. And since right now you probably don’t know what the hell you’re doing, you will only focus on the things you need to start. There are only four areas of the screen that you need to know about now. And I also drew it for you on the screenshot (see below). The first screen is where you’ll write your code. This is your main area. Go ahead and write this: myFirstLineOfCode &lt;- &#39;This is my first line of code!&#39; RStudio. Click ‘Run’ (the upper right side of the main area) (see below). Instead of clicking ‘Run’ every time, you can just highlight the chunk of code that you’d like to run and press ‘Ctrl + Enter’. Also, you can just click anywhere on the code that you want to run and press ‘Ctrl + Enter’, same thing. Go ahead, and try all three. A couple of things just happened. In the area number two, you should now see the variable ‘myFirstLineOfCode’ as well as what is inside of that variable - ‘This is my first line of code!’ In this window, you will be seeing all the variables, tables, and other data that you created or imported. Whatever is available at the moment. RStudio. What else happened? In the view number three, you can see the code that you ran (see below). If you ran it three times, you would see it three times. The main use case of this area for us to check if our code is running, finished running, or generated errors or warnings. Let’s generate an error. Type your name without parentheses in the view number one and run it. It should generate an error in the view number three (something like: ‘Error: object ’Nikita’ not found’). RStudio. Just like this, we know something is wrong with our code. This is not all the third view can do, but this is how we’re going to be using it. Just for the sake of awareness, I would like to show you what else it can do. Type this in the third view (see below): test &lt;- &#39;testing the third view&#39; RStudio. Hit ‘Enter’. Same as the main view, it ran this code without clicking Run or ‘Ctrl + Enter’ and stored the result in the second view. The difference is the code is now gone. It’s useful to test your code or to run something quickly, but we won’t be using it now. Just wanted to show you. Now, let’s look at the view number four (see below). RStudio. This view won’t be super useful for us now so don’t worry about it right now. Basically you should be seeing the folder that you are currently in. Also, when we create graphs and maps, they will appear there. That is about all you need to know about the fourth view right now. In fact, this is about all you need to know about the layout. Let’s move on 0.6.3 Saving R File Now, let’s save this file and see where it goes. When you’re new, there’s always that fear that you’ll break something and won’t be able to get it to work again. One thing I want to do right from the start is kick that fear out of you. To do that, in this and the next few sections, we’ll try to do some things that will seem damaging to your setup. I’ll show you that you can’t really do much damage or lose a lot of data by doing routine operations, and if something really goes wrong, you can restore things. So, go ahead and save our script by clicking the floppy disk icon on top (I hope, I do not need to explain to you how to save files. This operation is pretty universal) (see below). RStudio. Now, close the Rstudio. Go to the folder where you saved your file and open it. You should be where you left off. 0.6.4 Simulating a Problem. Now, let’s simulate a problem. Let’s see what happens if your Rstudio session freezes or your computer just crashes. So, lets add another line of code to our script and see what happens if we forget to save it and windows messes up again. Go ahead and add this line of code right under the first one: mySecondLineOfCode &lt;- &#39;This is my second line of code!&#39; Run it. I hope you remember how. Now, do me a favor, open the activity monitor by pressing ‘ctrl + alt + del’ and selecting it if you are on windows. Kill the Rstudio process (see below). RStudio. We never saved our code; imagine you had hundreds of lines of code that you never saved (obviously, that would be stupid, but happens). It happened to me a few times with excel and word, and I did not have auto-save enabled and I lost hours of my life rewriting things, because windows decided to mess me up. Fortunately, this won’t happen to you with Rstudio. Now, do not open the file that you saved, instead just open Rstudio again. Yes, you need to open a completely new Rstudio session. If you are on Windows for example, go to start, find Rstudio and click on it; if it is on your desktop, open from there. It should open with that second line there. We just simulated a hard stop of your Rstudio session. That should eliminate some portion of the fear about losing your progress. Things like that happen more often than you think. If you’re loading more data than you RAM can handle or if you have a weak CPU, chances are you will see freezes quite often. You will deal with this a lot; restarting your computer and reopening R sessions. Your code in most situations will still be there. Tip: 8 gigs of RAM is absolute minimum for working with data, 16 is OK. I have 16 at home and 64 at work, for example. That is in 2019-2020. 0.6.5 Re-installing RStudio When you are just starting, you are going to end up experimenting with your setup quite a bit. That might or might not lead to breaking things, or, at least, to having them work in a way you didn’t expect. What do you do? Just not experiment? Not really. It is just like with learning to ski or snowboard; first thing you need to know is how to stop. If you learn how to stop first, then, no matter what, you’re safe and probably won’t break your neck. Same here, when you know that you can always start from scratch, you’re in control, and you learn faster. So, let’s imagine that we did something that made our Rstudio setup really unusable. There is nobody to help us. What do we do? Sage Tip: Delete and reinstall. Proven method, patented by myself. Go to your control panel if you are on windows and delete Rstudio. If you are on MAC, just drag it to trash. If you are on Linux, I expect you to know what to do. Now, just follow the steps that we used to install it. When you open it, you will have a clean Rstudio; but you’ll still be able to easily access all the code scripts that you saved so far. Go ahead and open your new Rstudio. Once opened, go and open that script that we saved. You should see the same line of code that we had (see below): RStudio. 0.6.6 Messing with Packages As a final step of kicking the fear of screwing up your setup, we are going to install a few packages and remove them. Packages and Libraries are used interchangeably in R; they mean the same thing. Any Joe Shmoe can write and publish a package in R, given enough knowledge. A package is just a collection of functions that make your life easier. It can even be just one function. For example, R has a number of built-in functions like read.csv() for reading csv files. Some guy thought that he could do better and wrote his own function that reads CSVs faster and gives you more options. That function is called fread(), and it is a part of the data.table package. In order to use it, you first need to install the data.table package. There are tons of packages out there, and we’ll be using a lot of them. Packages for files, maps, aggregations, graphs, web apps, etc. I hope you’re getting it so far; we are going to dive deeper into packages a bit later. For now, let’s just install a few. Go to the top of our script, even above our first line of code. Yes, just move it a few lines down. Write this: install.packages(&#39;data.table&#39;) install.packages(&#39;dplyr&#39;) install.packages(&#39;shiny&#39;) Highlight all three entries and ether press ctrl + Enter or just click Run. You’ll see a bunch of cool looking installs going on. Wait till everything is done. Now, how do I tell that it’s done? In the top right corner of the third view you should notice a red circle with sign ‘stop’ on it. You will only see it when RStudio is busy, in other words, when something is running. Once that red button goes away, that means it’s done. Now, these three packages are installed and you don’t need that code there anymore. Erase those three lines and instead write these: library(data.table) library(dplyr) library(shiny) Highlight these three now and run them. And that’s it, you installed and loaded your first three packages/libraries. Your session should look like this now: RStudio. Now, it is time to uninstall these. You would ask, why? Why the hell not? But seriously, there are two reasons. First of all, I want you to know how, and secondly, sometimes a package may conflict with another package resulting in your code messing up. Sometimes a package just won’t update and will start kicking errors. It’s not always straightforward and obvious what’s happening. We’ll be installing so many different packages that one day everything might be working smoothly and the next day your code is just not running. Then, you end up just like Nicholas Cage in ‘Gone in 60 Seconds’ talking to your code just like he did to his car Eleanor - ‘Come on baby, do not be like that, please work’. To make sure you don’t sit there for too long, like I did, figuring that stuff out, I’ll teach you a few troubleshooting tricks. Let’s come back to uninstalling our packages. Run the following: uninstall.package(&#39;data.table&#39;) uninstall.package(&#39;dplyr&#39;) Erase these two lines. If it worked, running the following will not work, because the packages are not there anymore: library(data.table) library(dplyr) Good. What about the third one? Let’s simulate another problem. At some point, eventually, you will encounter a strange piece of work error – you will be trying to load a library, but it will say that there is no such package or something. You will then try to install that package and it will either install it or will tell you that that package is already installed. You will then try to load the library, but the same annoying stuff will happen again and again and again. You will be like, ‘WHAT DA HELL?!. You’ll then try to do what we have just done and will try to uninstall that package. It might say something like: package is not there and cannot be uninstalled or it will uninstall it but when you repeat the whole circle again, same result. What’s happening? You might have opened a second RStudio session at some point, and it started installing packages to different folders. You don’t have to completely follow this logic. Just remember. If something of this nature is happening to you, here is how to fix it. We are going to locate the folder where our packages are getting installed into. Then, just find the package folder in question and freaking delete it. It might tell you that the folder is in use and cannot be deleted, just restart your computer and delete. After that, open your script that you had the problem with, install that package, and load the library, everything should work fine now. So, let’s do it for the Shiny package. Save your script, close RStudio. If you are on Windows, your R folder should be in the Documents. So, go to Documents/R/R-…/ and delete the ‘shiny’ folder. If it is in use, restart your PC, come back and try deleting again. Let’s confirm. Open your script again and try: library(data.table) library(dplyr) library(shiny) Non should work, because we uninstalled the first two libraries in the previous steps and the ‘shiny’ library manually. That’s it. This is how you do a soft and hard delete of your packages. This concludes our R-fear exorcism ritual. 0.6.7 Dark Mode One thing that you must do, and I can’t emphasize ‘must’ here enough, is to switch your RStudio color theme to a dark mode. If you don’t do this, your code will not work. On top of that, people will think that you’re a noob. The darker your screen is the better coder you are. Proven by scientists. This is a joke, of course, but I do want you to change to the dark mode. From experience, it helps you focus better and keeps your eyes more relaxed. Also, it does look like you know what you’re doing if your screen is dark. It shows that you’re advanced enough to tinker with the text editor settings. When others see you as advanced, you’re automatically creating that level of expectation for yourself to get better, which, in turn, speeds up your progress. Every time that I helped some of my colleagues at work with their code, by far the most painful part of the experience for me was looking at their bright noob screens. Therefore, go to the ‘Tools’ on top of the Rstudio → Global Options → Appearance and in the editor theme pick ‘cobalt’. RStudio. That’s it. All that ranting was just for this. Now, this book will have the white theme. Why? Because when I will decide to publish, I do not want to spend a fortune on color, that would be stupid. But you should know, I will be creating illustrations for this book wearing sunglasses. What a hypocrite, right? Maybe I will switch to cobalt as well later. You will notice if I do. 0.6.8 Second R Session. Another trick I want to show to you is using multiple Rstudio sessions at the same time. You see, R is a single process language, which means that it can only tackle one command at a time. Commands are the lines of code that we were just running. The following is a command: mySecondLineOfCode &lt;- &#39;This is my second line of code!&#39; Each assignment like this, or a call to a function (like install.packages() or library()) is a command and is processed one at a time in the order that you have written it. In most cases, you will never even notice or it will not be a problem, because it is so quick. However, there are going to be many many many cases when a command will be taking an insane amount of time, and you will have to sit there like a steaming piece of work and wait for that command to run before you can execute the next one. In most cases, a command that would take a long time to run is something like a SQL call to some old and slow or just overloaded database. I have wasted some good hours of my life interacting with such piece of work databases. Sometimes, I waited for one to four hours at a time for my SQL command to run before I could continue. In the most extreme cases, I had to leave the script running overnight to come back in the morning to see that It has not finished, and be like: ‘NOOOOO!!!’. API calls will give you similar issues, but less often. Anyway, do not be super afraid as it does not happen all the time, especially in a modern setup, and when it does, it’s not really your fault. There is not much we can do to make a process run faster. When you become a little bit more advanced, you’ll be able to, maybe, break your database pulls into segments to speed them up a bit and to have more control over them. You can also, sometimes, use parallel processing to assign tasks to different cores of your computer processor. These are more advanced topics and you don’t need to worry about them for now. The simplest solution right now is to just let that long process run for as long as it needs to, but at the same time doing something else in another Rstudio session. Yes, just open a second Rstudio and create a new script in there. Before, I mentioned that you can run into some issues with your packages if you are working in two sessions at the same time. Yes, you can, but it’s not worth worrying about it. You will not learn anything unless you run into the issues like that. You live, you learn. And you already know how to fix them if you do, right? Most of the time, I have three to five sessions opened at the same time. It is helpful not only to hack around a slow code, but also as a point of reference when working on a new project. You will be reusing your code a lot and having it opened and available for copying and pasting in front of you is very useful. I do not want to be an all talk but no-show kind of guy, so I want to actually show you how all this works. We’re not pulling big and long data from databases yet, but I do want to show you what a busy session looks like. I will write a loop that prints a piece of text every few seconds. You are not ready to learn loops yet, but basically, a loop will make my text print for as many times as I tell it too, and until it is done, the Rstudio will be busy, and we will not be able to use it. So, you can stay on the same script or you can open a new one. You don’t have to save anything, we are just practicing. Type the following in the view number one: This line creates a sequence of numbers from 1 to 25 and stores them in the variable ‘sequence’. sequence &lt;- seq(1:25) This loop reads like this: for each thing inside of the variable ‘sequence’ (so, for 1,2,3,4,5….25) print ‘im busy’, then wait for four seconds and do it for the next thing in the ‘sequence’. Once it is done going through the sequence, it will continue. In our case, it will print ‘done’. for (i in sequence){ print(&#39;im busy&#39;) Sys.sleep(4) } print(&#39;done&#39;) Here, I’m just trying to simulate a busy Rstudio session. I am using a loop for this. In the real world, the place of that loop will be taken, let’s say, by a lengthy database pull, and the place of the print(‘done’) will be taken by some other functions, which, let’s say, will do something to the data that the pull will return. I hope that it is clear, but it does not have to be. You should not be looking into loops just yet. The only purpose of this loop is to keep Rstudio busy. Now, let’s do it again. Run all three. Notice how things are being printed in the view number three. Also, notice the red stop button in the corner of this view. This means that the session is busy, right? Now, open another Rstudio. Create a new script and write a command there. You can write: something &lt;- &#39;I can do whatever here&#39; print(something) Now, run these two lines. As you can see, they ran even as the other Rstudio is still executing its loop. There you go. This is all you need to know about the layout and working with Rstudio in general . . . for now. R, Not the Best Practices by Nikita Voevodin is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. "],
["your-code-basics.html", "Your Code Basics 0.7 Data Types &amp; Structures 0.8 Coding Tools", " Your Code Basics This section covers the fundamentals of the R language. Things like data types and structures, functions and libraries, data formats, loops and more, are all the horrible things that you need to have some understanding of right now. I wish we could skip this shit and go straight to good stuff, but unfortunately, we can’t. These topics will come up again and again and you will just fuck yourself up if you don’t at least know about them. I will try to keep it as interesting as possible so bear with me on the adult material. Remember, you’re still sitting in your cubicle at work familiarizing yourself with R. Your boss is out for a while and gave you a few days to settle down and get more comfortable with R in particular. Nobody else has really bothered you up until now, but you suspect that it might change soon. You don’t want to look like an incompetent degenerate, so you jump back into learning R. 0.7 Data Types &amp; Structures We have already written a few lines of code. Let’s just erase all that trash and start over. Erasing and starting over is very useful in the beginning because it helps you get better. Rewriting the same stuff over and over with some minor improvements really cements the fundamentals in your head. Start a new script and write the following lines of code: president &lt;- &#39;Trump&#39; age &lt;- 70 goodPresident &lt;- TRUE # Or you can write false here, it is up to you There are four simple data types in R. Characters, numbers, booleans (logical), and stupid factors. Nerds will tell you that there are more types. There are, they are called complex, integers and some other nonsense. Leave these types to them, you do not need them right now. Let’s go in order. In this book, I’ve tried to illustrate code the way it looks in real life. However, sometimes a line of code can be too long and won’t fit on a single line of a book (even digital), resulting in a scroll view, which isn’t a good reading experience. Therefore, from time to time, you will see me breaking a single code line in two or three lines. Don’t worry, it will work just the same in Rstudio. It might just look weird at first. Example: Something that looks like this: president &lt;- &#39;Trump&#39; Will sometimes look like this: president &lt;- &#39;Trump&#39; 0.7.1 Characters Character type is just that – characters, letters, text, sentences, names and so forth. There is not much to it. Any text that you print or store in a variable or table is a character. Numbers can be characters, dates can be characters, factors and logicals can be converted to characters. A simple example is the line of code we wrote earlier: president &lt;- &#39;Trump&#39; The character string ‘Trump’ is stored inside of the variable ‘president’. What is a character string? It is just a bunch of characters put together. The, character string ‘Trump’ is a combination of characters ‘T’,’r’,’u’,’m’,’p’. What can we do with characters? Lots of things, actually. Characters store names, descriptions, text, and other things of that nature, nothing special here. Some interesting things that we can do with characters are counting them, chopping them up and combining different strings together; we can also filter by characters or by a number of characters in a string and we can group by characters. Let’s just look at some of those. In the following chunk, we will paste two strings together and print the result. # Storing &#39;Donald&#39; inside of the variable &#39;presidentFirst&#39; presidentFirst &lt;- &#39;Donald&#39; # Storing &#39;Trump&#39; inside of the variable &#39;presidentLast&#39; presidentLast &lt;- &#39;Trump&#39; #Now, lets put them together and store them in the third variable presidentFull &lt;- paste(presidentFirst,presidentLast) #Print the result print(presidentFull) ## [1] &quot;Donald Trump&quot; We just created two-character strings, stored them into two separate variables, and pasted them together into the variable as one string. Simple and cool. We did not necessarily need to store the strings in the variables. You can also do it like this: presidentFull &lt;- paste(&#39;Donald&#39;,&#39;Trump&#39;) print(presidentFull) ## [1] &quot;Donald Trump&quot; # Or even shorter, like this: print(paste(&#39;Donald&#39;,&#39;Trump&#39;)) ## [1] &quot;Donald Trump&quot; As you can see, the results of all three methods are the same. Here, we used the function paste(). It’s a very useful function, and we will be using it a lot. Have you noticed that when we pasted those strings together, there was a space automatically added? We pasted ‘Donald’ and ‘Trump’ together and got ‘Donald Trump’? If you are not a programmer, this is something you would expect. Because, why the hell not? In programming, you have to be precise, because a computer does not know what the fuck is going on. It just interprets your commands. This time, it just so happened, that this particular function paste() automatically adds a space between the things that you are trying to put together. But what if you did not want that space there? For that, there is a second variation of the paste() function called paste0(). Let’s see how it works. # Check it out. This prints them together without a space. presidentFull &lt;- paste0(&#39;Donald&#39;,&#39;Trump&#39;) # Printing. print(presidentFull) ## [1] &quot;DonaldTrump&quot; Very nice. You probably won’t understand why at the moment, but the paste0() function is much cooler and we’ll use it more often than ‘paste,’ because it gives us more control. It allows us to add a space whenever we want, and by avoiding that default setting it runs faster. Now, look at how you can add that space using paste0(). # Here, we are basically pasting a third string # (which is an empty space) in between &#39;Donald&#39; and &#39;Trump&#39; presidentFull &lt;- paste0(&#39;Donald&#39;,&#39; &#39;,&#39;Trump&#39;) # Printing print(presidentFull) ## [1] &quot;Donald Trump&quot; Pasting things together is very useful and simple thing. I want to show you a couple more things that we can do with characters. Chopping character strings up will be something we will be doing a lot. Here is how it works. Let’s say we have ‘Donald’ and ‘Trump’, but we want to convert it into ‘Dump’. # First, lets store the names first &lt;- &#39;Donald&#39; last &lt;- &#39;Trump&#39; To get ‘Dump’ out of ‘Donald’ and ‘Trump’, we are going to need to get the first letter of the first name and the last three letters of the last name. We will be using function substr() for this. D &lt;- substr(first,1,1) print(D) ## [1] &quot;D&quot; Function substr() takes a character string, a character’s position to start chopping, and a finish position. So, we basically said: take ‘Donald’, start with ‘D’ and finish at ‘D’ and store that in the variable ‘D’. Let’s do it again, but without storing and variables, and in one line: print(substr(&#39;Donald&#39;,1,1)) ## [1] &quot;D&quot; Good, now we need the ‘ump’ part. Same thing, but different numbers. ump &lt;- substr(last,3,5) print(ump) ## [1] &quot;ump&quot; Now, we need to paste these together and we already know how to do it. Dump &lt;- paste0(D,ump) print(Dump) ## [1] &quot;Dump&quot; Substr() will be a big part of your day to day programming. It is a very simple but very important function. It can be a little confusing in the beginning. Are these positions inclusive or exclusive? They are inclusive, but you’re likely to forget that. Don’t worry, it will become natural later. As you might have noticed, every time I execute a function, I print the result. I’m only doing it for you, and you don’t really have to do it. In real life, I don’t print the results of every single operation, because I understand what the code output will be. However, it’s still a good practice to print your result, at least in the beginning. Let’s move on. One last function I want to show you that you will be using a lot is trimws(). This function eliminates white spaces around a character string that you are passing to it. As you should remember from our paste() exercise, R can treat an empty space as a separate character. Imagine that you are dealing with some hand typed data; instead of typing ‘Donald’, someone typed ‘Donald’ or’ Donald’. These empty spaces make those two entries almost unusable because they won’t match the proper ‘Donald’ entry. That is where we’ll absolutely need functions like trimws(). Let’s simulate a situation to see how it works: # Normal first1 &lt;- &#39;Donald&#39; # With space after. first2 &lt;- &#39;Donald &#39; Now, let’s check if they are the same shit; for this we need a logical equality operator ‘==’. It works just like a regular equal ‘=’ sign but returns true or false. This is how we can compare characters and other non-numbers. Do not worry about it now, we will talk about it in depth later. So, let’s see if ‘Donald’ equals ‘Donald’: first1 == first2 ## [1] FALSE As you can see, they are not. Lets fix it. # Eliminating white spaces. first2 &lt;- trimws(first2) # Printing print(first2) ## [1] &quot;Donald&quot; Lets check again: first1 == first2 ## [1] TRUE Now they are, because we trimmed that empty space. Perfect. This sums up characters for now; I showed you a few things that we can do with them. There are many more functions, and many interesting things we can do with characters, but the main point of this introduction is to get you to see the distinction between different data types. As we move along, you will see these functions more often along with other new functions. 0.7.2 Numbers In R, numbers are called numerics. There are also integers and complex numbers, but don’t even worry about this right now as we won’t be working with them. For us, right now, numbers are numbers, and that is it. As far as you are concerned, 15.5 is a number, 5 is a number, 0 is a number. Everything you can do with numbers anywhere else; you can also do here. Let’s take a look at some basic operations. One distinction to get out of the way. Check this out: #This is a number and the function class() lets us check that: class(70) ## [1] &quot;numeric&quot; #This is a character: class(&#39;70&#39;) ## [1] &quot;character&quot; Sage Tip: Adding parenthesis around a number will make it a character. Remember! Now, back to the operatons: # Storing age in &#39;age&#39;. age &lt;- 70 # Storing term length in &#39;presidencyTerm&#39;. presidencyTerm &lt;- 4 Adding the two variables to get Trump’s age by the end of the first term. # Adding and storing. finalAge &lt;- age + presidencyTerm # Printing. print(finalAge) ## [1] 74 Or simply: finalAge &lt;- 70 + 4 print(finalAge) ## [1] 74 Lets print his year of birth: print(2019 - age) ## [1] 1949 Hopefully, you get the idea; hopefully I don’t have to teach you basic math or statistics. You can definitely do more with numbers in R, but the main point of this part is to show you that numbers in R are the same as the numbers anywhere else. 0.7.3 Booleans or Logicals You probably haven’t noticed, but we already used this variable type when checking if ‘Donald’ was equal to ‘Donald’ with space in the end. Booleans are also called ‘Logicals,’ and they are quite simple, because there are only two of them: ‘True’ and ‘False’. Also, you should know that, both, True and False have the corresponding numbers 1 and 0 that basically mean the same thing. Don’t worry about the numbers part; I’ll show you how that works. First, let’s see if TRUE and 1 and FALSE and 0 are the same things. 1 == TRUE ## [1] TRUE 0 == FALSE ## [1] TRUE As you can see, both returned as TRUE, which means they’re equal to each other. Now, let’s prove that not every number is equal to TRUE: 25 == TRUE ## [1] FALSE 32 == FALSE ## [1] FALSE See? We are not going to be using 0 and 1 as true or false really, but you should be aware that there is such a thing. Let’s see how we WILL be using Booleans: &#39;Trump&#39; == &#39;Trump&#39; ## [1] TRUE &#39;Trump&#39; == &#39;Obama&#39; ## [1] FALSE 7 == 7 ## [1] TRUE Now, to the big one: I’m going to show you an {if else} operation here. I will briefly explain what it does, but you don’t have to remember it right now. We’ll get into ‘if else’ later. #0 president &lt;- &#39;Trump&#39; #1 if (president == &#39;Trump&#39;){ #2 print(paste(president, &#39;is the president&#39;)) #3 print(president == &#39;Trump&#39;) #4 } else { #5 print(paste(president, &#39;is not the president&#39;)) } ## [1] &quot;Trump is the president&quot; ## [1] TRUE What the fuck just happened here? Number 0: we stored ‘Trump’ in the president variable. Number 1: in the {if else statement} we basically asked: ‘does variable president equal ’Trump’?’ and if it does, run the Number 2 and Number 3. Number 2: paste together the contents of the variable president and the character string ‘is the president’ and print it. Number 3 Print a logical expression comparing the contents of the variable president to ‘Trump,’ it only has 2 options as you remember. In Number 4 we basically check what should happen if Number 1 is FALSE. If the variable president doesn’t equal ‘Trump’, Number 5 should kick in. Number 5 here is pretty much the same as Number 2. The main point of the {if else} statements is that only one of these two options can be TRUE and therefore, only one gets executed, in this case it is the Number 2 and Number 3. Now, let’s change the president variable to good old Obama, and see if he is still president. president &lt;- &#39;Obama&#39; if (president == &#39;Trump&#39;){ print(paste(president, &#39;is the president&#39;)) } else { print(paste(president, &#39;is not the president&#39;)) } ## [1] &quot;Obama is not the president&quot; If all of that sounded like a lot of nonsense to you, do not worry about it. The ‘if else’ example is too much for now anyway. Just remember that Booleans (Logicals) consist of only two values, TRUE and FALSE. They exist so we could compare not only numbers but characters and other data types as well. 0.7.4 Factors As I mentioned before, factors are stupid and we are going to try to avoid them as much as possible. If you want to learn about factors, you’re not going to do it here. I am going to give you a basic explanation and some examples; I will also explain why I think they are stupid. Think of factors as categories or levels. Genders would be a factor; colors would be factors as well. We haven’t reached ‘vectors’ and other data structures yet, but I need to use a vector here to show you factors. So, don’t worry if you can’t follow 100%. Let’s store some colors in a vector of character strings. # c() is how you specify a vector. colors &lt;- c(&#39;red&#39;,&#39;blue&#39;,&#39;green&#39;,&#39;red&#39;,&#39;blue&#39;, &#39;green&#39;,&#39;red&#39;,&#39;blue&#39;,&#39;green&#39;) This string is not a factor yet, but it’s a good candidate to be one. There are a limited number of colors and colors can be treated as categories. Let’s first check what is colors. # Checking the class. class(colors) ## [1] &quot;character&quot; As you can see, it says ‘character’, more like a group of characters, but it will say character. Fine. Let’s convert it to a factor. I will use the function ‘factor()’, but do not try to remember it, we will never use it. Never! # Converting to factor and storing. fColors &lt;- factor(colors) # Lets check again. class(fColors) ## [1] &quot;factor&quot; As you can see, it is a factor now. Finally, I want to print them side by side to show the difference: # Printing the vector &#39;colors&#39; print(colors) ## [1] &quot;red&quot; &quot;blue&quot; &quot;green&quot; &quot;red&quot; &quot;blue&quot; &quot;green&quot; &quot;red&quot; &quot;blue&quot; &quot;green&quot; # Printing the factor &#39;fColors&#39; print(fColors) ## [1] red blue green red blue green red blue green ## Levels: blue green red Factors group categories into levels, characters do not. Factors are useful for some advanced statistical operations. Once you reach that level, by all means, go ahead and start using them. Right now, factors will only get in the way. They will mess up your code. I am pretty sure; you’ll be hating them just like I do. Whatever factors are accomplishing with their levels can be accomplished by grouping regular characters without the worries of a messed-up code. Again, we will be avoiding factors as much as possible, but at least you are aware of them. 0.7.5 Dates &amp; Times This one is a big topic by itself, and we will spend good time diving deeper into it later in this book. Dates are important. One of the best things about R is how well it handles dates and how much flexibility it offers when dealing with them. That flexibility, though, does not come without cost. The cost is complexity. You will be dealing with dates and times a lot, and it will become a big source of frustration for you. However, once you master R and start looking into some other languages, you will appreciate how many options and how much flexibility R gives you. There are so many packages that deal with dates that if I start going over all of them, you will close this book. Therefore, I will show you just the one that I found to be the most universal. It is called ‘lubridate’. Let me show you a few examples of dates and what we can do with them. First thing we need to do is to install the package. install.packages(&#39;lubridate&#39;) Now, load it. You are doing great! Just messing with you, you have not really done shit yet! Lets first create a date: date &lt;- &#39;2019-01-01&#39; We just stored a character string that looks like date inside of the date variable. Let’s double check: class(date) ## [1] &quot;character&quot; Just a character right now. Let’s convert using the function ymd() from the package ‘lubridate’: # Converting and storing. date1 &lt;- ymd(date) Ymd here stands for year month and day. Lubridate has other variations as well. class(date1) ## [1] &quot;Date&quot; You would ask, ‘How is it different from having a date as a character?’ Sometimes it isn’t, but, at some point, you’ll want to do some math with your dates. For example, adding a day to a date. It’s impossible to do with a character, unless you want to manually retype shit every time. Let’s see how it works with dates: # Adding a day to our date. newDate &lt;- date1 + 1 # Printing. print(newDate) ## [1] &quot;2019-01-02&quot; This was just a short introduction to the topic of dates. I only showed you one function of one package. Dates are perfect for working with charts and graphs, projections and other calculations involving time. We are going to dive deeper into dates later in this book, but not untill we really need that knowledge. 0.7.6 Type Conversions You are going to encounter many instances when you will be trying to match one dataset with another and it just won’t match. You look at your data, and it seems fine and clean. You check the column names, and they seem good for matching. What is going on? In many cases, it is just your data types are different. For example, a column where you have dates got converted to a character type, or some column where you had colors stored as character got converted to a factor type. It’s super annoying and it happens more often than you think. You need to be able to deal with that shit. Besides fixing types when they are causing you problems, there are going to be even more cases when you’re going to want to convert types for your analysis or something, so, don’t worry, it is not all bad. Let’s see how it works: ::: {.infobox .caution data-latex=“{caution}”} Luckily, conversions are quite simple and very uniform across different types, meaning that the functions are kind of similar. Number to Character. # Storing. number &lt;- 60 # Checking class. class(number) ## [1] &quot;numeric&quot; # Converting character &lt;- as.character(number) # Checking class. class(character) ## [1] &quot;character&quot; Character back to Number. # Storing. number &lt;- as.numeric(character) # Checking class. class(number) ## [1] &quot;numeric&quot; Stupid Factor to Character and Numbers (will be doing this a lot). # Storing. factor &lt;- factor(5) # Checking class. class(factor) ## [1] &quot;factor&quot; # Converting. character &lt;- as.character(factor) # Checking class. class(character) ## [1] &quot;character&quot; I want you to pay attention here: # Converting factor to numeric. number &lt;- as.numeric(factor) # Printing. print(number) ## [1] 1 The number that we stored in the factor was 5, so why is it printing 1 now? Because it’s a fucking factor. It will mess you up! I’ll tell you why. Instead of printing the number that we stored, it printed the level associated with that number. The only thing that you need to remember, besides not using factors is the following: # Converting factor to character first and then to number. number &lt;- as.numeric(as.character(factor)) # Printing print(number) ## [1] 5 # Checking class. class(number) ## [1] &quot;numeric&quot; If you are converting a number that is a factor back into a number, you must first convert it into a character! Dates to Characters and Back # This function gives us today&#39;s date (handy) date &lt;- Sys.Date() # Printing print(date) ## [1] &quot;2020-02-20&quot; # Checking class. class(date) ## [1] &quot;Date&quot; # Converting to character. characterDate &lt;- as.character(date) # Printing. print(characterDate) ## [1] &quot;2020-02-20&quot; # Checking class. class(characterDate) ## [1] &quot;character&quot; I want to show you two ways to convert it back to a date. The first one is the one that we used before - ymd() form the ‘lubridate’ package. It is the most intuitive so I will insist on using it. The second is from the base R, meaning that you do not need any external packages to use it. # Converting. dateFirst &lt;- ymd(characterDate) # Printing. print(dateFirst) ## [1] &quot;2020-02-20&quot; # Checking class. class(dateFirst) ## [1] &quot;Date&quot; # Converting using base R. dateSecond &lt;- as.Date(characterDate) # Printing. print(dateSecond) ## [1] &quot;2020-02-20&quot; # Checking class. class(dateSecond) ## [1] &quot;Date&quot; As you can see, they do the same shit. However, as we progress, we will be doing more sophisticated date and time operations, and you’ll see why I am insisting on lubridate. These conversions were basic, but even this basic stuff will cover 95% of what you will ever need when dealing with data type conversions. The only part that we will need to spend more time on in the next chapters is the dates and times part. Other than that, your data type conversion foundation is built. This, sort of, concludes the introduction to the basic data types that I want to cover. So far, you got to play with characters, numbers, booleans, stupid factors, and dates. These are the building blocks for the next part where we are going to look at the more complex data structures like vectors, lists, and data tables. You have already seen some of them, so it will not be anything special or complicated, but still, something that we just can’t skip. Strap in. 0.7.7 Vectors If you are new to programming, vectors will be hard to wrap your head around right away. They are quite simple, though. However, because you are not used to working with data in that format, it will take some time to get used to. At least it was for me. I don’t know, maybe, I am so good of a teacher that you will get it right away. We will see. Anyway, we have already seen a few vectors so far. Now, I think, the easiest way to understand vectors right away is like this: step 1: imagine a table with some data; step 2: each column in that table is a vector; step 3: that is it! If you ever worked with excel tables, you should be able to picture one. Every column with data in that table is a separate vector, where headers are just names for those vectors. It doesn’t matter what type of data are in those columns. If it just numbers, it is a numeric vector; if it’s characters, a character vector; it can even be mixed. Let’s quickly take a look. Lets create three vectors. To create a vector you need to use the following syntax: c(…). With characters: # Storing a vector. charVector &lt;- c(&#39;blue&#39;, &#39;yellow&#39;, &#39;green&#39;,&#39;red&#39;) # Printing. print(charVector) ## [1] &quot;blue&quot; &quot;yellow&quot; &quot;green&quot; &quot;red&quot; With Numbers: # Storing a vector. numVector &lt;- c(1,2,3,4) # Printing. print(numVector) ## [1] 1 2 3 4 Mixed: # Storing a vector. mixVector &lt;- c(1,&#39;dog&#39;,55,&#39;tree&#39;) # Printing. print(mixVector) ## [1] &quot;1&quot; &quot;dog&quot; &quot;55&quot; &quot;tree&quot; That’s it. You are basically just storing your data in bigger data structure. If you want, you can also apply functions to them. As an example, lets convert a numeric vector to a character vector. # Converting. numCharVector &lt;- as.character(numVector) # Printing. print(numCharVector) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; # Checking class. class(numCharVector) ## [1] &quot;character&quot; Whatever we did to a single number before, we are doing to every number in that vector. Now, do you remember that comparison to the columns of a data table that I brought up? Let me show you. Let’s create a table out these vectors: # Creating a table. table &lt;- data.frame(charVector,numVector,mixVector,numCharVector) # Printing. print(table) ## charVector numVector mixVector numCharVector ## 1 blue 1 1 1 ## 2 yellow 2 dog 2 ## 3 green 3 55 3 ## 4 red 4 tree 4 We were able to create this table because the number of records in all these vectors is the same (4). Don’t worry about it now, we will cover data tables soon. Another note though, data tables and data frames in R are used interchangeably. This is about all you need to know about vectors at the moment. I don’t know about you, but for me, it took quite some time to get them. Anyway, we will not be doing anything crazy with vectors anytime soon. I showed you that we can apply functions to them, but won’t be doing that either. We kind of will, but it will be in the context of applying them to columns of a dataframe and not just separate vectors. I think, this is enough for now. 0.7.8 Lists Lists are similar to vectors in that they also store data inside. They are more complicated and are harder to understand right away. Lists store data hierarchically and apart from storing things like characters and numbers, they can also store vectors, data tables, as well as even other lists. They become very useful when you start working with loops. To give you an example, if you had fifty data tables and you wanted to do the same operation to all of them (something like converting all headers to upper case), instead of doing that shit fifty times, you would store all these data tables in a list, loop over it and apply that operation not just once, but to all elements of the list. It is an intermediate technic, so I don’t expect you to follow too much right now. Let me show you a few examples instead, so you could see how lists are different: Now, do me a favor and create the same four vectors that we did in the previous section. Also, create a table with those four vectors, just like we did. Name it ‘table’. Now that you have prepared everything, lets create some lists. Just with simple data types: # Creating a list. list1 &lt;- list(&#39;a&#39;, 1, &#39;b&#39;,55,&#39;100&#39;) # Checking class. class(list1) ## [1] &quot;list&quot; # Printing print(list1) ## [[1]] ## [1] &quot;a&quot; ## ## [[2]] ## [1] 1 ## ## [[3]] ## [1] &quot;b&quot; ## ## [[4]] ## [1] 55 ## ## [[5]] ## [1] &quot;100&quot; The following structure is a bit more complex compared to the ones we looked at so far. Double square brackets there indicate the number of the item in the list. It lets us access that element for example for looping. On top of that, you can go even deeper and access the variables inside of the list’s item. To access ‘a’ we need to do the following: # Printing. print(list1[[1]][1]) ## [1] &quot;a&quot; Double beackets access the fist element of the list and the single brackets give us the first element inside, which is ‘a’. It will only get more complex from now, so I will stop printing the results to save space. You should still poke around and see what the following lists are all about: List of vectors: list2 &lt;- list(charVector,numVector,mixVector,numCharVector) List of vectors + data tables: list3 &lt;- list(charVector,numVector,mixVector,numCharVector, table) List of tables: list4 &lt;- list(table,table,table) List of lists: list5 &lt;- list(list1,list2,list3,list4) As you can see, lists can get quite complex very quickly. They can be very useful when you are ready to use them. We aren’t ready and won’t using them any time soon. The only reason I showed them to you is for your overall understanding of the R data types. We’ll definitely come back to lists in time. For now, let’s move on to the topic of data tables. That is the one we will be using right away and a lot. 0.7.9 Data Tables (Data Frames) Remember, a few topics ago, I told you to think of vectors as just columns inside data tables? Well, now, hear my (not only) definition of data frames (or data tables, as you might have noticed, we are using them interchangeably). Data frame is a collection of vectors of the same lengths. That’s it. Why the same number of rows? Because, imagine a table, it is a rectangle, right? Even if some rows are empty, you, still, have the same number of them. One of the best things about working with R, if not the best, is its handling of data tables. If you have ever worked with Excel or some other tabular data handler, then R’s way of dealing with such data will be very intuitive for you as well. We will be working with tables a lot. We will use them for everything, even for things that we don’t really need them for. For example, sometimes, it is much faster and efficient to do things with vectors, instead, we will be converting vectors into tables and then doing things to them. But why? Because tables are intuitive and vectors are confusing. I am trying to explain things to you the way I wish they were explained to me. If you are a genius who gets everything right away, then you don’t need this book. Get out of here. For the rest of us tabular analysis is key to understanding everything. Through working with tables, you will eventually get the rest of the data structures and will decide when and what to use on your own. Let’s look at the tables that we have already created. We already have a data frame. Lets use it: # Storing &#39;table&#39; in &#39;newTable&#39;. newTable &lt;- table # Printing. print(newTable) ## charVector numVector mixVector numCharVector ## 1 blue 1 1 1 ## 2 yellow 2 dog 2 ## 3 green 3 55 3 ## 4 red 4 tree 4 When you use the function print(), it prints everything in the console (view 3). You can review your outputs like that, but it is not very practical. The better way is to use the Environment (view 2). Select the ‘newTable’ in your Environment. You should see the same table, but as a separate full screen tab. Point at the column names and hold your pointer there for a second, you should see the data type of that column. There isn’t much more that you can do with this view, but that’s why it’s great. It does not have a ton of options to confuse you. Close it. Let’s do a couple of things to our new table. Removing first row and fourth column: newTable &lt;- newTable[-1,-4] It’s confusing in the beginning, but this syntax: ‘table[rows , columns]’ is standard and the most intuitive for dealing with tables. Within square brackets: the left side of the comma deals with rows and the right side with columns. So, if we wanted to eliminate the second row and the second column we would write: ‘newTable[-2,-2]’ and if we wanted to eliminate the first and the second rows and the first column, we would write: ‘newTable[-c(1,2),-2]’. You get the idea. Now, let’s rename the columns: # Renaming. colnames(newTable) &lt;- c(&#39;col1&#39;,&#39;col2&#39;,&#39;col3&#39;) If you just want to rename just one column: # Renaming. colnames(newTable)[2] &lt;- &#39;Sherman&#39; # Printing. print(newTable) ## col1 Sherman col3 ## 2 yellow 2 dog ## 3 green 3 55 ## 4 red 4 tree Lets also count the number of rows and columns: # Counting rows. nrow(newTable) ## [1] 3 # Counting cols. ncol(newTable) ## [1] 3 These were some of the basics of data frames. It’s all you need to know for now. If I start to show you more shit now, I will lose your attention, because you’ll stop following at some point. I am telling you; we are going to be working with data frames so much that it will be the first thing that you master. Let’s summarize what we have looked at, and hopefully learned, in this section. First, we looked at R’s basic data types, which are characters, numbers, booleans, factors, as well as dates. We also applied a few functions to them and saw how we can convert one type to another. Then, we looked at the main data structures. These are vectors, lists, and data frames (also known as data tables). We created them, used one as a part of the other, and saw how we can modify them at will. You might have found some of that boring as fuck, but you need to know this stuff to proceed. In the next section, we’re going to talk about functions (not the ones that you write for yourself, but the existing ones), libraries (packages), file formats, loops, and SQL queries. 0.8 Coding Tools We are done talking about the data types and structures. In this section, I would like to cover some ground on coding tools. I wasn’t sure what to name this section so I picked coding tools. Things like functions, libraries, loops, file formats, and SQL queries aren’t really data types or structures, nor are they coding, strictly speaking. Whatever, just fucking stick with coding tools. 0.8.1 Functions We are going to split functions in two types: ones that you wrote, and ones that were written for you. Forget about writing your own functions for now. Here, we will be covering the second type. R has tons of functions. One of the best things about R is that it’s open source. Anybody can write a function, package it, and release. Because of that, there are functions almost for anything. The flip side of that, is that there is a bunch of functions that do same shit. This makes it almost impossible to have one guiding rule for language usage - there is no one right way to do things. It also creates a lot of competition between package creators, as each tries to be the shit who created the best tool for the job. I personally enjoy to know more than one way to skin a cat (This is a joke!!! I do not support animal cruelty!!! I am serious!!!), but you might be different. There are distinct schools of thought in R, though. It’s not complete chaos so don’t worry. We will be following the two biggest ones. Anyway, there are also two types of functions (out of those that are written for you): built-in and from the outside. The built-in (also known as base) are the functions that come pre-installed with R. You can do a lot with just them. You can do all the math and stats operations, dates, basic plots, and more. That would be fucking stupid though. I am sure, there are purists who do that. Fuck them. R is powerful and amazing because of the wealth of third-party functions that are available for free to everyone. There are functions for everything. I, obviously, can’t show you all the functions, and there is no need to dive into them now, but I will show you a few as an example. We already installed and loaded the libraries that we will be using. But, in case you started a new session or something, lets load them again. We have already applied a few functions here and there before: print(), substr(), trimws(), ymd(), as.Date, colnames(), and others are all functions. Let’s use a few more. First, let’s create a table with three columns. One with numbers, second with characters, and third with numeric dates. # Creating a table. data &lt;- data.frame(a &lt;- letters[1:4], b &lt;- seq(1.345,4.345), c &lt;- seq(20190101, 20190104)) # Printing. print(data) ## a....letters.1.4. b....seq.1.345..4.345. c....seq.20190101..20190104. ## 1 a 1.345 20190101 ## 2 b 2.345 20190102 ## 3 c 3.345 20190103 ## 4 d 4.345 20190104 We used four functions here: # Creates tables (rarely used) data.frame() # Converts sequence of numbers to letters (rarely used) letters[] # Creates a sequence of numbers (often used) seq() # Prints whatever (used all the time) print() Ok, two things right away. Column names are messed up, and I also want to show you how to access columns of data tables in R. Fixing column names: # Renaming. colnames(data) &lt;- c(&#39;letters&#39;,&#39;numbers&#39;,&#39;dates&#39;) To access a column of a dataframe, you will use the $ operator between the dataframe’s name and the column’s name. Like this: # Accessing the column &#39;letters&#39; data$letters Working with numbers. Rounding all numbers in that column to two decimals: # Rounding. data$numbers &lt;- round(data$numbers,2) This section is a good place to talk about arguments in functions. Arguments are the things that you pass to a function. There can be any number of arguments in a function, it depends on the person who wrote the function. For example, the function round() that we just used, accepts two arguments: Number 1: a number or a vector of numbers Number 2: the number of decimal points to round to. In this function, if you do not specify the second argument it defaults to 0. That is called a default argument. The first argument here is, of course, mandatory. Without it, R will kick an error. Functions can have different number of arguments. Some are more important than others. Every time you’re about to use a new function, google it first to see its main arguments and avoid unintended results. Let’s go back to the examples. Creating another column and rounding all numbers down to the whole number using the function floor(). # Rounding down. data$roundDown &lt;- floor(data$numbers) Same, but rounded up. Using the function ceiling(). # Rounding up. data$roundUp &lt;- ceiling(data$numbers) # Printing. print(data) ## letters numbers dates roundDown roundUp ## 1 a 1.34 20190101 1 2 ## 2 b 2.34 20190102 2 3 ## 3 c 3.34 20190103 3 4 ## 4 d 4.34 20190104 4 5 Here, we are using the function mean() to print the mean of the column ‘numbers’. We are not storing the result anywhere. Instead, we printing it right away. # Printing mean. mean(data$numbers) ## [1] 2.84 Using the function sum() to print the sum without storing. # Printing sum. sum(data$numbers) ## [1] 11.36 Printing min/max without storing. # Printing min. min(data$numbers) ## [1] 1.34 # Printing max. max(data$numbers) ## [1] 4.34 Now, let’s do something to the character column. Using the function toupper(), we are changing the column ‘letters’ to upper case. # Upper case. data$letters &lt;- toupper(data$letters) # Printing. print(data) ## letters numbers dates roundDown roundUp ## 1 A 1.34 20190101 1 2 ## 2 B 2.34 20190102 2 3 ## 3 C 3.34 20190103 3 4 ## 4 D 4.34 20190104 4 5 Switching back by using the function tolower(). # Lower case. data$letters &lt;- tolower(data$letters) Lets add the string ’ test’ to our letters by using the function paste0(). # Pasting data$letters &lt;- paste0(data$letters,&#39; test&#39;) # Printing. print(data) ## letters numbers dates roundDown roundUp ## 1 a test 1.34 20190101 1 2 ## 2 b test 2.34 20190102 2 3 ## 3 c test 3.34 20190103 3 4 ## 4 d test 4.34 20190104 4 5 Splitting one column into two with an empty space in the middle (little advanced). # Piping data into the function separate() and stroting the result # inside of data. data &lt;- data %&gt;% separate(letters, into = c(&quot;columnA&quot;, &quot;columnB&quot;), by = &#39; &#39;) # Printing. print(data) ## columnA columnB numbers dates roundDown roundUp ## 1 a test 1.34 20190101 1 2 ## 2 b test 2.34 20190102 2 3 ## 3 c test 3.34 20190103 3 4 ## 4 d test 4.34 20190104 4 5 This is a good time to introduce the ‘%&gt;%’ (pipe operator). A pipe operator will be very important for us. We will be using it in this book a lot and will continue using it all the way through the last book where we will be doing some very advanced asynchronous programming. This glues all that. Very important. Now, here is what it means. Think of %&gt;% (pipe) operator as the word ‘THEN’. Let’s look at the operation we executed above: STEP 2) data &lt;- STEP 1) data %&gt;% separate(letters, into = c(“columnA”, “columnB”), by = ’ ’) STEP 3) print(data). Step by step: take data, then, separate the column ‘letters’ into the columns ‘columnA’ and ‘columnB’ by emply space. store the result in data. print data. Apart from the ordering being not from left to right, it is pretty fucking straightforward. Now, on top of being somewhat easy to understand, this type of syntax is also very efficient. You can chain lots of operations like that. I know that you don’t give a shit about efficiency at the moment, you are just trying to get this to work. Therefore, here is a very simple scheme: dataframe &lt;- dataframe %&gt;% function(column) %&gt;% function(column) %&gt;% …. You can basically chain as many as you want. We will see that in action later. Finally, lets convert a numeric date column into an actual date: # Converting. data$dates &lt;- ymd(data$dates) # Printing. print(data) ## columnA columnB numbers dates roundDown roundUp ## 1 a test 1.34 2019-01-01 1 2 ## 2 b test 2.34 2019-01-02 2 3 ## 3 c test 3.34 2019-01-03 3 4 ## 4 d test 4.34 2019-01-04 4 5 I just showed you a fraction of what I usually use, and what we are going to be using in this book. Some of these functions were from the base R and some from the external packages like lubridate, tidyr, and diplyr. The concept is simple: you need to do something, you look up a function for that, you install and load the package, you use the function like this: ‘result &lt;- function(arguments)’. Next, we will look into packages. 0.8.2 Packages (Libraries) Packages or Libraries are just containers for functions. There are tons of libraries out there, and that is great. We pretty much covered this whole topic of how packages and functions are amazing and how they do all these different things. So, in this part, I am just going to give you a list of libraries that you are going to install and drag with you every time you launch a new project. You will see some people who will be like “Bro, it is wrong to have so many packages loaded all the time.” Do not listen, they do not know what they are talking about. Dragging a bunch of packages, even if you will not use some of them, will save you a lot of time. So, here: library(lubridate) # for working with dates/times library(data.table) # ecosystem for working with tables # and averall data manipulation library(dplyr) # another ecosystem for working with tables # and averall data manipulation (will be our primary) library(openxlsx) # to load data from excel library(tidyr) # for data manipulation library(fst) # for loading fst files library(stringi) # for manipulating character strings library(zoo) # for working with dates/times library(ggplot2) # for nice graphs library(scales) # combines with ggplot2 for scaling library(tibble) # for working with data and tables library(RMySQL) # for sql queries using mysql database There are many more libraries we will use. I will be introducing them gradually, rather than all at once. For now, just install all of these and start dragging them from script to script when you start a new project. You don’t need to look into them now. 0.8.3 Data Formats If you have ever seen a computer, then data formats shouldn’t be anything new to you. You don’t have to be a programmer to know the term. There are a bunch of different formats out there. Formats like pdf, xlsx, txt, csv, doc, docx, and others are a day to day thing that you see anyway. Why do we care? You will be saving a lot of your analysis using some sort of files, right? Also, you need to get your data from somewhere, because you almost never generate your own. Here, I will show you the formats that we are going to be using the most. First, let’s create a table. Same one we did before. # Creating a table. data &lt;- data.frame(a &lt;- letters[1:4], b &lt;- seq(1.345,4.345), c &lt;- seq(20190101, 20190104)) 0.8.4 CSV In my experience, CSV is, by far, the most used format to store data in R. It’s compact, fast, supported by excel and other similar editors, and well supported by R. The fact that it is accessible by an Excel kind of software is very important. A lot of times you will be doing some analysis for your superiors. They might not know R, but they will know Excel. You should be able to send them your data in the format that they can consume. This is how you save your table as a CSV: 1.Get the path of where you want to store the file. If you do not know how - on windows go to that folder and on top you will see the path, copy it. 2.Use that path as the second argument to the function. Like this: fwrite(data, ‘path’). 3.When you paste the path you will see that you have single forward slashed separating the folders. Like this : /a/b/c. You must change this to //a//b//c or \\a\\b\\c for it to work. Here is my example: # Saving. fwrite(data, &#39;//home//nkta//Desktop//book//bookData//data.csv&#39;) Lets read it back. # Reading. data1 &lt;- fread(&#39;//home//nkta//Desktop//book//bookData//data.csv&#39;) # Printing. print(data1) ## a....letters.1.4. b....seq.1.345..4.345. c....seq.20190101..20190104. ## 1: a 1.345 20190101 ## 2: b 2.345 20190102 ## 3: c 3.345 20190103 ## 4: d 4.345 20190104 0.8.5 XLSX (EXCEL) Similar to csv but can have multiple tables. Basically, an excel spreadsheet. We won’t be writing this format, but, sometimes, you have to work with this format and you need to know how to read it in. # Saving. write.xlsx(data1,&#39;//home//nkta//Desktop//book//bookData//data1.xlsx&#39;) ## Note: zip::zip() is deprecated, please use zip::zipr() instead # Reading. data2 &lt;- read.xlsx(&#39;//home//nkta//Desktop//book//bookData//data1.xlsx&#39;) 0.8.6 FST This one is extremely fast. I think it was developed by Facebook to store huge data fast. We will be using it down the line in the next books. # Saving. write.fst(data2,&#39;//home//nkta//Desktop//book//bookData//data2.fst&#39;) # Reading. data3 &lt;- read.fst(&#39;//home//nkta//Desktop//book//bookData//data2.fst&#39;) There are also other popular formats that we will not be working with. They are RDS, JSON, and XML. You can look them up yourself. As you can see, reading and writing these formats is easy. On top of that, all these functions are pretty much the same. CSV will be our number one, fst will be the distant second. You get the idea. All these file types are good for saving and sharing your data on small and local scale. You’ll use these to save some data for a future analysis, or to send to your boss, something like that. The way big boys work with data is through databases. In the next and final introductory section, I will show you how some of that is done. 0.8.7 SQL Queries SQL is extremely important. You won’t go far without it. I won’t teach you the language itself in this book, but I’ll show you the most used commands and how to execute them. Here, I want to show you how to connect to a database and retrieve some data. I’ve set up a practice MySQL database, and, from now on, we will be interacting with it a lot. Let’s connect to it and retrieve some data. Before we do though, I want to say a few things about databases. This is how I think about the types of databases out there. There are old piece of shit databases that, if you’re unlucky, you will be forced to work with at work. That would happen if your organization has old infrastructure and isn’t planning to change it. There won’t be a difference in SQL language between fast and slow databases so it doesn’t matter. You won’t be wasting time learning it, you will just struggle a lot with speed. If you are lucky, your database will be extremely fast, so fast that you will start to think that all databases are that fast. Such databases are not the most popular, because they are usually designed for some specific tasks and speed. They DO look like regular databases at first, but at some point, you will encounter their limitations - something small, something that you will need to do but it just will not be able to do. They might also be not free to use. I will show you such databases in the future and even teach you to set them up. Not now, though. First, let’s connect to our database. For this, we will use a function from the library ‘DBI’. Even though, we never loaded this package, it got automatically added when we loaded RMySQL. This happens all the time. When you try to install a package, R checks if that package relies on some other packages to work. If it does, but they are not installed, R will automatically install them. # Connecting. connection = # specifying database type. dbConnect(drv = MySQL(), # username user = &quot;xxx&quot;, # password password = &#39;xxx&#39;, # address host = &#39;mybookdatabase.cgac79lt7rx0.us-east-2.rds.amazonaws.com&#39;, # port port = 3306, # name of the database dbname = &#39;nikita99&#39;) Without the confusing comments and spaces, it looks like this: connection = dbConnect(drv = MySQL(), user = &quot;xxx&quot;, password = &#39;xxx&#39;, host = &#39;mybookdatabase.cgac79lt7rx0.us-east-2.rds.amazonaws.com&#39;, port = 3306, dbname = &#39;nikita99&#39;) I am not going to explain each argument, because you do not need that at the moment. This setup will work for now. At work, this will be provided for you by a database administrator or something. We WILL be setting up our own databases in the future books, but it is too advanced right now. So, when you execute the connection, it gets stored in your environment. It kind of just sits there until you disconnect. But now, you can use it to get the data from the database. First, lets look at the list of tables inside: # Listing tables. tables &lt;- dbListTables(connection) Now, lets take the table ‘book_table’ and check the first 5 rows in there. # Checking first five rows. data &lt;- dbGetQuery(connection,&quot;SELECT * FROM book_table limit 5&quot;) I want to spend some time here and take a look at what we just did. The overall syntax should be more or less clear to you now: we are applying some function on the right side of the arrow ( dbGetQuery(connection,“SELECT * FROM book_table limit 5”) ) and storing the result inside of the variable on the left side (data). The function that we are using is ‘dbGetQuery’. It has two arguments: the database connection, and the actual SQL command. The connection should be clear to you: we connected to the database with the credentials and stored that connection in the variable connection. That’s it. Now, about the actual SQL command - “SELECT * FROM book_table limit 5”. This is actual SQL language. Basically, we just used another programming language inside of R. This is how SQL works: there are key commands, and there are inputs. In our case, key commands are SELECT, FROM, LIMIT. The inputs are: *, book_table, 5. Lets go line by line: ‘SELECT’ - every sql query will start with SELECT ’*’ - means all or everything ‘FROM’ - will also be there every time ‘book_table’ - specifying the table ‘LIMIT’ - lets us set the number of rows to pull ‘5’ - the number for the limit The key commands let us filter the database to only extract what we need. the usual pattern is like this: SELECT something FROM datatable WHERE something GROUP BY something. If you got that, perfect. If not, does not matter. It took me a while to even be able to execute a query. I am not even talking about understanding commands. For now, we will only be using SQL to pull the entire tables from it, without filtering anything. Later, we will gradually start adding key commands to our queries. Let’s pull the whole table: # Pulling everything. data &lt;- dbGetQuery(connection,&quot;SELECT * FROM book_table&quot;) If we can just pull the entire table like that, why did I show you the limit thing, and why do we need SQL filtering and all that extra shit? Even with 100,000 rows, the table that we just pulled is considered tiny by the world of big data standards. This table took a second to pull and about 20mb of your RAM. Imagine you are working with a table that stores daily porn searches. It probably has billions of rows added every day. Pulling big tables like that will crash your computer every time in minutes. To avoid that, you must be able to pre-aggregate your pulls using SQL. There you go. We are not doing any porn aggregation yet so we are going to be ok with pulling the entire thing. Let me show you a few more pulls just for fun. Pulling just vin, year, and record date. I will be surrounding the name of the columns in ticks. Ticks are used when columns have spaces. Something like ‘vehicle_year’ would be ok without ticks. Generally, avoid using spaces when naming things in programming. # Pulling. data &lt;- dbGetQuery(connection,&quot;SELECT `vehicle vin number`, `vehicle year`, `last date updated` FROM book_table&quot;) Remember! There is no comma before FROM! Let’s see the first few rows. head() lets you select the first n rows. # Printing the first three. print(head(data,3)) ## vehicle vin number vehicle year last date updated ## 1 4T1BK1EB5FU154526 2015 10/24/2019 ## 2 2LMHJ5AT3ABJ10630 2010 10/24/2019 ## 3 5TDZK3EH0DS100457 2013 10/24/2019 Let’s count the number of VIN numbers by vehicles’ year. # Pulling and counting. data &lt;- dbGetQuery(connection,&quot;SELECT COUNT(`vehicle vin number`), `vehicle year` FROM book_table GROUP BY `vehicle year`&quot;) You should have noticed that some years are messed up. This is called ‘dirty data’. These data are not super ‘dirty’, but it still needs cleaning. You should always disconnect from the database after you are done using it, because if you and hundreds of parasites like you do not, the database will freeze at some point. # Disconnecting. dbDisconnect(connection) ## [1] TRUE This was a basic introduction to SQL. If you did not get all of it, it is fine. SQL is not hard but the number of new functions, signs, and characters can be overwhelming considering that you are also trying to memorize the rest of the stuff. When I was learning this, all these queries had layers of other functions attached to them. Very confusing. Remember me writing this: print(head(something,5))? Well, that is a chained function. When it is short like this, you still can decipher it. You are like: ‘Ok, maybe head takes first five rows and then we print it’. But now, imagine something like this: setDT(dbGetQuery(connection, paste0(&quot;SELECT COUNT(`vehicle vin number`), `vehicle year` FROM book_table GROUP BY `vehicle year`&quot;)),as.is = T). The funny thing is that this query is exactly the same as the last one that we wrote, but it has all that extra shit on top of it. Misplace one comma or parenthesis and your whole code is fucked. I would be sitting for hours getting bombarded by fucking errors because of some stupid shit like that. When you are new, you just do not know what each dot or whatever means and that is natural. We will practice with it much more in this book. You are done with the basics of R. Whatever was in this section is enough to get you started. We have looked at data types, structures, type conversions, functions, libraries, file formats, and SQL queries. That is a lot and boring, but absolutely necessary slush. There is a couple more things that I should have covered here but decided to leave them for later, loops and writing your own functions. We will not be using them any time soon. I will still talk about them later in this book, because you do need to know about them eventually. We are going back to the story. Tomorrow is Monday, you are going back to work. You have covered a lot of R ground and you think that whatever your boss throws at you tomorrow will be a piece of cake. R, Not the Best Practices by Nikita Voevodin is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. "],
["big-assignment.html", "Big Assignment 0.9 Code Run-Through 0.10 Figuring It Out 0.11 Tutorial Purgatory 0.12 Going line by line 0.13 Working with dates 0.14 Rewriting our code 0.15 Adding MPG 0.16 Charts &amp; Reports 0.17 Bonus 0.18 You are not an R maggot anymore", " Big Assignment You are back at the office. It is Monday, your second week. You are excited. You are learning things that you want to be learning. Before your boss left for whatever last week, he told you that your first assignment will involve cleaning his code and doing some vehicle data work. Up until now, you have been learning non-stop. Not because they told you to, but because you think it is the right thing to do. You want to get ahead and you genuanly enjoy doing it. You have made some great progress with some basics of the language. Now, you are ready to gradually take on the assignments. 0.9 Code Run-Through Well, it does not always happen as you picture it in your head. Your boss sits with you and says, ‘Here is the code that I had been working on for some time a while ago. It does some things that we want, but it can be improved. I am going to run you through it and then explain what I want you to do to it and what to add.’ We have two tables that hold vehicles’ information in our database. The first table holds vin numbers of all our vehicles. This table is updated daily, because we have new vehicles coming in every day. The second table holds detailed information about those vehicles (columns are: vin, date_added, expiration_date, make, model, year, type, engine_type). The code that creates this table is the one that you will be taking over. You will be updating it a few times a month. Here is how it works: You will pull the new vin numbers that got added today; Make sure that they have not been processed yet; Add all the required fields by pushing new vin numbers through thr API and code that I am providing for you; Add the finished dataset for that day to the one that we already have in the database. You will be running this every day for now; Every month, we will be sending completed monthly files to IT. They will be taking it from there. Once you are done and comfortable with that, I will explain the changes to the code that I want you to implememt. You watched the lips of your boss moving, but were not understanding 75% of what was being said. You nodded like a dumb smiling puppy, but your eyes displayed zero intelligence. At that point, your heart picked up the pace and you felt the urge to urinate in your pants. All your cockiness was gone and what was left was one question: ‘How long until I am fired for being an incompetent degenerate that I am?’ It was not even the end. Next came the code. 0.9.1 Step 1 First, we are going to load some libraries. You will not need all of them, but it will save you some time to have all of them loaded anyway. We are also going to connect to our database. You will be using multiple tables from that database, so you better learn how to join different tables together. Loading the libraries. # Lubraries. library(lubridate) library(data.table) library(dplyr) library(openxlsx) library(tidyr) library(fst) library(stringi) library(zoo) library(ggplot2) library(scales) library(tibble) library(RMySQL) library(pbapply) Connecting to the database # Connecting. connection = dbConnect( drv = MySQL(), user = &quot;xxx&quot;, password = &#39;xxx&#39;, host = &#39;mybookdatabase.cgac79lt7rx0.us-east-2.rds.amazonaws.com&#39;, port = 3306, dbname = &#39;nikita99&#39; ) 0.9.2 Step 2 Note: Obviously, the data in not updated live in this book. We will be simulating that part. Today is January 1st 2018. The second table in the database holds complete vehicles’ records up to the last day of 2017. Lets see how many new vehicles we got today. We will assign today’s date to a variable and then pull the vin numbers from the first table only for that date. # Creating today. today &lt;- &#39;2018-01-02&#39; # Pulling. lastVins &lt;- dbGetQuery(connection, paste(&quot;SELECT `expiration date`, `base type`, `vehicle vin number` as vin, first_seen as date FROM book_table where first_seen = &#39;&quot;, today,&quot;&#39;&quot;, sep = &quot;&quot;)) 0.9.3 Step 3 We need to make sure that there are no white spaces around the vin numbers. After that, we will store the vin numbers in a vector so we could push it through the API. # Eliminating white spaces. lastVins$vin &lt;- trimws(lastVins$vin) # Creating vector of vins. vinVector &lt;- lastVins$vin 0.9.4 Step 4 Time to retreve the vehicles’ data that we want. For that, we will be using the API provided by the National Highway Traffic Safety Administration (NHTSA). The API needs a vector of VIN numbers and returns a table with many many fields, from which we will only select the ones that we want. Writing a function to call the api: # Function. return_vins &lt;- function(my_vin){ vinme &lt;- paste0( &#39;https://vpic.nhtsa.dot.gov/api/vehicles/DecodeVinValues/&#39;,my_vin,&#39;?format=json&#39; ) vinme = httr::GET(vinme) result = jsonlite::fromJSON(httr::content(vinme, as = &quot;text&quot;)) result = as.data.table(result) } Calling the function and making sure that if there is an error or an empty vin number, the code does not stop and moves to the next one instead. Files are written one by one into the data folder. # Loop. vin_results &lt;- pblapply(vinVector,function(empty_vin){ tricatch_result= tryCatch({ return_vins(empty_vin) }, error=function(e){cat(&quot;ERROR :&quot;,conditionMessage(e), &quot;\\n&quot;)}) tryCatch({ fwrite( tricatch_result,paste0(&quot;data/vin&quot;,tricatch_result$`Results.VIN`,&quot;.csv&quot;) ) }, error=function(e){cat(&quot;ERROR :&quot;,conditionMessage(e), &quot;\\n&quot;)}) Sys.sleep(.001) tricatch_result }) Binding all the files from the data folder into a data frame. # Binding. NHTSAtable &lt;- list.files(&#39;data/&#39;, pattern = &#39;.csv&#39;) %&gt;% pblapply(function(x){ read.csv(paste0(&#39;data/&#39;,x),stringsAsFactors=FALSE)[, c(&#39;Results.VIN&#39;, &#39;Results.Make&#39;, &#39;Results.Model&#39;, &#39;Results.ModelYear&#39;, &#39;Results.FuelTypePrimary&#39;, &#39;Results.FuelTypeSecondary&#39;)] }) %&gt;% rbindlist() # Eliminating extra files. unlink(&quot;data/*&quot;) 0.9.5 Step 5 Finally, we are going to pull the second table from the database and combine it with the data that we just got. # Renaming. colnames(NHTSAtable) &lt;- c(&#39;vin&#39;,&#39;make&#39;,&#39;model&#39;,&#39;year&#39;,&#39;gas1&#39;,&#39;gas2&#39;) # Joining. lastVins &lt;- left_join(lastVins,NHTSAtable) ## Joining, by = &quot;vin&quot; # Pulling the complete vehicles&#39; data old &lt;- dbGetQuery(connection,&quot;SELECT * FROM fin_book_table&quot;) # Eliminating the first column old &lt;- old[,-1] # Renaming to match columns in &#39;lastVins&#39;. colnames(old) &lt;- c(&#39;expiration date&#39;,&#39;vin&#39;,&#39;year&#39;,&#39;base type&#39;,&#39;date&#39;, &#39;make&#39;,&#39;model&#39;,&#39;gas1&#39;,&#39;gas2&#39;) # Binding complete old data with new. final &lt;- rbind(old, lastVins) 0.9.6 Step 6 Lets write this out as a separate CSV file with today’s date. # Saving. fwrite(final, paste0(&#39;vehiclesComplete_&#39;,Sys.Date(),&#39;.csv&#39;)) This is it for now! Your boss says: ’I know this is complicated and I do not expect you to get it right away. I am giving you a generous amount of time to get familiar with this code. I expect you to be able to reproduce this within six weeks on your own. I will want you to add quite a few things to this. Before I explain, lets give it a week or two for you to practice with this code. Feel free to stop by and ask me any questions about this. Good luck, see ya later.&quot; 0.10 Figuring It Out Well, what do you think? Piece of cake? Or piece of shit? I can tell you, when I first saw this, I thought to myself: ‘I am fucked!’ I honestly, did not understand anything from that. I sat there for an hour or two just mindlessly staring at the screen afraid to touch the keyboard. This code was shown to me in the morning. During the lunch break, I literally called my mom and said that I do not know what the fuck I am doing. That code was just that to my eyes: a code. I did not see the difference between variable names and functions; I did not know why the commas were where they were; I did not know why some brackets are square and others are round; I did now know anything; and I did not know where to start. In this book, I tried to lead you to this moment so you would be more or less prepared. Still, I do expect you to be lost right now, because the code in this section is very advanced for any beginner. Code like this, takes you out of you comfort zone and makes you think. In other words, it makes you pee your pants. What are we going to do about it? How are we going to understand that code? Simple, we are going to go line by line to understand what each piece of code does. After that, we are going to try to rewrite some of the code to realize that a lot of things in R can be accomplished by different functions. That, in particular, helped me make that code mine. By rewriting it using different functions I fully understood it and ultimatelly made it mine. Before we dive into that, I think it is a good opportunity to talk about a very important topic. It is called ‘Tutorial Purgatory’. 0.11 Tutorial Purgatory What is the tutorial purgatory? Even if you do not know what it is already, you have probably experienced it in your life at some point. Be it while learning to code or learning something else, symptoms are the same. In the programming world, tutorial purgatory is the state when you walk through a bunch of tutorials without putting what you are learning to actual use, and without retaining much of it. You are not quite confident in your abilities to start your own project, because you think that you need to know close to a 100% of what, you believe, is necessary to finish it. You feel like you do not know enough and, therefore, you must watch a tutorial or go through a whole course. You finish the course and finally sit down to work on something, only to realize that you still do not know what to do. You ask yourself: ‘Maybe I missed something? or maybe there is a better tutorial?’. And instead of starting the project, you go back to youtube or worse, drop the idea. Similarly to procrastination, you push the responsibility of hard work as far away as possible until it bites you in the ass. This is what the ‘Tutorial purgatory’ is, in my words. There are a few things that make the situation worse. There are so many nice tutorials out there today. Both, paid and free. Every other homeless guy, now, has a youtube channel along with a udemy course where he teaches you to do something in just 3 days. Most of the tutorials are a ‘follow along’ type. This is where the devil hides. In the ‘follow along’ tutorial, you are, basically, just copying and pasting somebody else’s code. The illusion of learning comes from not just copying and pasting the code, but from retyping it instead. The code will be perfect and will run flawlessly. The problem with that is that you will not learn anything from it. You will copy the code, the app or site or whatever will work, but you will not be able to replicate it yourself. Also, in most cases, the author will teach you the best practices from the start and will not show you how he actually got to it. That type of code is good for display, but is bad for learning from, and a lot of times you will find yourself frustrated, because you can not follow it, because you never actually went through the ‘ugly’ code first. If you are persistent, you might struggle through it and finish copying his code, but it will not lead to you understanding it. The second problem and, in my opinion, by far the worst, is platooing and jumping from technology to technology. I place ‘jumping from one technology to another’ in the same bucket with the tutorial purgatory, because they both have the same root and outcome. The root would be a lack of motivation and persistence as well as the sheer number of talking heads telling you that learning something else is hotter now. This is how it works. You sit down to learn R, for example. You go through a few tutorials and everything seems fine. You are making some quick progress and are very exited about this new technology that you are learning. Good for you! After a while you get less and less exited about the progress that you are making. You are platooing. Or else, you reached a topic that takes more than a few minutes to understand. At that moment, the thought that this is either boring or too hard starts creeping into your head. You open youtube and are faced by all the jesters telling you that they will teach you something else, something more exiting, in no time. You watch a few more videos about what technology is the hottest right now and how the one that you picked stacks up against it. The best case scenario here is you just wasted a whole bunch of time and sat back down and keept on going. The worst - you installed that other hot language and went on making that quick and exiting initial progress. That exitement runs out eventually and you are at square one, again, having wasted so much more time. These were the roots. Very similar to the tutorial purgarory, right? Be it boredome or self-doubt preventing you from sticking it out. You going in circles and not making any substancial progress that would set you apart. The outcomes are the same as well. In both cases, you are unable to get to the level where you can put your skills into practice. You either watch others or swayed into doing something else. This is it on this topic. I am quite confident that you can relate to this. There might be better, more thorough explanations of this phenomena, however, my aim here is, in simple terms, to explain to you that 99% of us went through these things and that you should not. Just keep going with one thing, untill you made some substantial progress, which you can put to use. Ok, lets keep going. 0.12 Going line by line There is no reason why you should be able to understand what is going on in the code that your manager just walked you through. The only way for you to understand it is to run each line time an time again and see what is happening. From my experience, attempting to understand the code that someone else gives you is the best practice if your goal is to actually learn something. Too many times I saw people copy and paste somebody elses code only to find themselves stuck later once that code breaks or needs modification. Ultimatelly, we want to, first, go line by line to see what each function does. Once we understood how it works and how it arrives to the final result, we can, then, see if it can be simplified or rewritten in some other way. These two steps will result in us mastering that particular code. This, in turn, will allow us to build on top of that code if we choose to. For example, if you completely understand the code, it will be much easier to modify it to do something else. Imagine that you do not understand the code that somebody else gave you, at all. It produces the result that you want just fine, and all you need to do is to run it once a month. Now, a database name that your code is pulling data from changes, and your code does not do anything anymore. Since you never put time into understanding the code, you do not even know where to begin looking for the problem. Unless the result of that code is very important for your team or company, there is a very big chance that you will just stop using it as ‘not working’. If only you knew where to look, it would have taken you two minutes to see what is wrong and you would go to see a database admin to check the new database name. That was one simple example of not owning your code. Another would be when you need to pivot your code to do something else. If you do not understand how your code works, you will not be able to tweak it to do something else. Instead, you would probably opt to write something from scratch if you can. Worse, something that would take you a few hours of tweaking will become a whole big thing with timelines and delays, because you do not know where to start. These things are just common sence, but you will be surprised how many people opt to just copy and paste without looking into things. Do not be like that, you will just shoot yourself in the leg. Before we can master our manager’s code though, we need to go line by line and see what is going on there. The code was in steps, and, I think, it would be right to explain it in steps as well. 0.12.1 Step 1 Here, we loaded the libraries that we will and will not be using, and connected to our database. I personally found it to be a major time saver to drag all the libraries that I will on will not be using along from one project to the next. You might find a much better technique, but for now just drag them. It is very annoying when your code is not working because you forgot to load a library. We have already covered libraries in the basics chapter, so I will not spend much time on it here. I will, still, leave some pointers of what each library generally does. # Loading the libraries library(lubridate) # for working with dates/times library(data.table) # ecosystem for working with tables # and averall data manipulation library(dplyr) # another ecosystem for working with tables # and averall data manipulation (will be our primary) library(openxlsx) # to load data from excel library(tidyr) # for data manipulation library(fst) # for loading fst files library(stringi) # for manipulating character strings library(zoo) # for working with dates/times library(ggplot2) # for nice graphs library(scales) # combines with ggplot2 for scaling library(tibble) # for working with data and tables library(RMySQL) # for sql queries using mysql database library(pbapply) # looping function with progress bar Then, we connected to our database. I have also gone through this part in the basics. We are using the MySQL database, which is the most popular free database today. At work you might have something different. In most cases, You are going to have someone setting this part for you, so there is not much to explain to a begginer here. You will be given all your credentials to access the type of database that you will be using, and the connection code will be very similar every time. Here, we are storing the connection (result of the function dbConnect() inside the variable ‘connection’. We will be using that variable inside our SQL queries to excecute them. You will see in a bit. # Connecting. connection = #specifying database type. dbConnect(drv = MySQL(), # username user = &quot;xxx&quot;, # password password = &#39;xxx&#39;, # address host = &#39;mybookdatabase.cgac79lt7rx0.us-east-2.rds.amazonaws.com&#39;, # port port = 3306, # name of the database dbname = &#39;nikita99&#39;) 0.12.2 Step 2 In this step, we used the connection to the database that we just established to extract one day of new vehicles from it. Storing the date that we are interested in in the variable ‘today’. # Getting today. today &lt;- &#39;2018-01-02&#39; The function dbGetQuery() here, takes two inputs: connection and the actual SQL command. Connection is what we created in the first step. We just called it ‘connection’, but you can call it anything. The second input is the actual SQL command (“SELECT ….”). Here, it is also wraped in the function paste(). This is done so we can paste the variable ‘today’ into the SQL language. When we will be rewriting this code, I will show you how it can be simplified. We are selecting four columns. As you can see, some of them are surrounded with ticks (``). This is done because you can not have spaces in column names in SQL. Ticks is a way around that limitation, but generally, you should avoid using spaces when naming columns in your databases, and everywhere else as well. Also, notice that one of the columns is renamed ‘as vin’. Renaming columns like this makes it easier to work with the data later. You can rename any of them if you want. # Pulling. lastVins &lt;- dbGetQuery(connection, paste(&quot;SELECT `expiration date`, `base type`, `vehicle vin number` as vin, first_seen as date FROM book_table where first_seen = &#39;&quot;, today,&quot;&#39;&quot;, sep = &quot;&quot;)) In the end, you can see the variable ‘today’ wrapped in a lot of punctiation. That punctuation allows us to paste a predetermined date (2018-01-02) as a variable from outside of the SQL pull. It is quite confusing in the beginning, but as you use SQL inside of R more and more it will definitely make more sense. the sep = &quot;&quot; input tells the function paste() to eliminate spaces when it pastes SQL language with the content of the ‘today’ variable (‘2018-01-02’). As I mentioned before, the same could be done with using function paste0(). 0.12.3 Step 3 We need to make sure that there are no white spaces around the vin numbers. After that, we will store the vin numbers in a vector so we could push it through the API. Here, we are taking the column ‘vin’ of the table ‘lastVins’ and applying the function trimws() to it. The function trimws() eliminates the spaces from the front and back of every entry in the column. Imagine a vin number like this: &quot; VIN095GHFHGF &quot;. Someone might have mistakenly left two spaces in front and one in the back. R will treat those spaces as characters and you will not be able to match that vin to the same vin in another table if they are not identical. Sage Tip: There might be no spaces to begin with, but it is a good practice to do it anyway just to be sure. That will save you time it a long run. # Trimming white spaces. lastVins$vin &lt;- trimws(lastVins$vin) Here, we are storing the column ‘vin’ of the table ‘lastVins’ inside of the vector ‘vinVector’ We are doing that because the API that we are going to be using wants a single vin number as an input. We will write a function that will be retreiving a single vin number at a time and pasting it into the API. But that is later. Right now, we are storing the column ‘vin’ into its own vector. # Creating a vector of vins. vinVector &lt;- lastVins$vin # Lets see the first few. head(vinVector) ## [1] &quot;2LNBL8CVXBX751564&quot; &quot;5N1AR2MM5GC610354&quot; &quot;5FRYD4H44FB017401&quot; ## [4] &quot;4T3ZA3BB0AU031928&quot; &quot;4T1BD1FK7GU197727&quot; &quot;JTDKN3DU6F1930271&quot; 0.12.4 Step 4 Time to retreve the vehicles’ data that we want. For that, we will be using the API provided by the National Highway Traffic Safety Administration (NHTSA). The API needs a vector of VIN numbers and returns a table with many many fields, from which we will only select the ones that we want. This will be, by far, the hardest step for you to understand and for me to explain. I am trying to look at this code through your eyes and also remembering how I saw it when I did not know shit. You are definitely are not ready yet to understand how this part works, so, for now, just observe how it works. I will explain every part though. We will also rewrite it later in the book to make it much much simpler looking. However, it is still important for you to understand how this code, even so complex written, works. In my estimation, you will probably be able to replicate it from scratch for some other project in about nine months of learning and using R daily. So, DO come back to this section after some time and see if you get it better. Step 4.1. Writing a function to call the api. We will place this function inside of a loop that will feed one vin number at a time to it. So, as the loop goes from the vin number one to number two and so on, this function will kick in for every vin and produce something. We are calling this function ‘return_vins’. It takes one input, we are calling it ‘my_vin’. We can call it anything, it is just a name. Usually, I use ‘x’ or ‘i’ to name inputs. Step 4.2. The NHTSA API gives us the address to paste our vins into to get the information back. You do not need to look into that address. Those addresses always look complicated. You just need to follow the API’s instructions on how to use them and where to paste your stuff. In our case, we just need to paste our vin numbers where you see ‘my_vin’ variable in the line below. The reason why we are not pasting an actual vin is because we are not retreaving the information on just one vin but for the whole vector of vins. So, we need a variable that will be changing every time a new vin is fed into the function. Here, we are storing the address with the pasted variable into the variable ‘vinme’ Step 4.3. We then applying the function GET() to that address and in return receiving the response. That response is not yet the data that we want. It is sort of a description of that data. Step 4.4. In order to get the actual data from that response, we are applying the function fromJSON() that takes the contents of the response as an input. At this point, we have our data in the table called ‘result’. Step 4.5. Just to make sure that we are dealing with a data table format, we are converting it again. # Step 4.1. return_vins &lt;- function(my_vin){ # Step 4.2. vinme &lt;- paste0( &#39;https://vpic.nhtsa.dot.gov/api/vehicles/DecodeVinValues/&#39;,my_vin,&#39;?format=json&#39; ) # Step 4.3. vinme = httr::GET(vinme) # Step 4.4. result = jsonlite::fromJSON(httr::content(vinme, as = &quot;text&quot;)) # Step 4.5. result = as.data.table(result) } Next, we are calling the function that we just wrote and making sure that if there is an error or an empty vin number, the code does not stop but moves to the next vin instead. Step 4.6. Here, the function pblapply() creates a loop that takes the vector of vins that we created in the step 3 (vinVector) and feeds one vector a time (empty_vin) into the fuction return_vins() that we just created. The function tryCatch() is a very usefull function for loops like this. Imagine we are feeding one vin after another to the API. We are on the vin number fifty thousand and one, and that vin number is empty or just messed up in some way. The API will probably reject it and throw an error. That will probably stop the loop and cost you hours of lost progress. What you want is the code to ignore such cases and just keep going. tryCatch() does just that. Step 4.7. Here, the result of the function retur_vins() with the imput ‘empty_vin’ (which is one vin at a time) is stored in the variable ‘trycatch_result’. If it encounters an error, it will print it in the console and will keep going. Step 4.8. After we got the information and stored it in the ‘tricatch_result’ we are saving each vin with all the data in it in a separate file. Just so you understand it, if we had two hundred vins, we will write two hundred files. Each file is a table with just one row (one vehicle). We will later combine all those files into one. In terms of using tryCatch here, it is the same concept. If, while we are writing files, something goes wrong, the tryCatch() will ignore it and will move on. Step 4.9. Function fwrite() takes two inputs: the data that we are saving as first, and the name along with the extention. So, here is what the following means: save the contents of the variable ‘trycatch_result’ to the folder data/vin/, name it as a current vin number taken from the column named ‘Results.VIN’ of the table ‘tricatch_result’ and give the extention ‘csv’. The reason why we have to use the function paste0() to paste the column as a name is because the name of the saved file must be different every time. If we wrote something like: fwrite(tricatch_result, “data/vin/VIN#.csv” ) it would overwrite that same file two hundred times instead of generation a new one. Step 4.10. Before the loop finishes each round, it falls asleep for a fraction of a second to make sure that the NHTSA API does not kick us out for overusage. Step 4.11. After that we print the result of the current round just to see that the data are OK. # Step 4.6. vin_results &lt;- pblapply(vinVector,function(empty_vin){ # Step 4.7. tricatch_result= tryCatch({ return_vins(empty_vin) }, error=function(e){cat(&quot;ERROR :&quot;,conditionMessage(e), &quot;\\n&quot;)}) # Step 4.8. tryCatch({ # Step 4.9. fwrite( tricatch_result,paste0(&quot;data/vin&quot;,tricatch_result$`Results.VIN`,&quot;.csv&quot;) ) }, error=function(e){cat(&quot;ERROR :&quot;,conditionMessage(e), &quot;\\n&quot;)}) # Step 4.10. Sys.sleep(.001) # Step 4.11. tricatch_result }) At this point, the loop is at its end. Now it will go back to the beginning to see if there is another vin in the vector. If there is, it will iterate again and again until it goes through every vin. Finally, we need to put all the files that we just wrote together to create one table out of them. Once we done, the table will be inside of the variable ‘NHTSAtable’ Step 4.12. First thing we need to do is list all the files that we wrote, much like in a vector so we can read them one by one just like we wrote them one by one. The function list.files() does that. We just need to specify the path and a pattern. We know the path and the one thing that every file in that path has in common is the extention, so we will use that as pattern. Step 4.13. Now, each filename is fed into the pblapply() loop as ‘x’. Step 4.14. This step says the following: read the file ‘data/x (where x is the file’s name that is fed to the function read.csv() by the loop)’, then do not convert anything to factors, and only keep the columns specified. In this case, the code is written so that column filtering is happening on the same line. It is called chaining. It does save time and makes code cleaner, but when you are learning it makes thing look more complex than they are. The reason why we are picking these six columns is because the data that we got back have many many useless, to us, columns. Step 4.15. Finally, the function rbindlist() puts all the files that we are reading together as one table. So, if there are fifty files in that data folder, there are going to be fifty iterations of our loop and each time the loop finishes its round the rbindlist() will stack the next read table on top of the previous one. Step 4.16. At this point we got our final table. Now, we do not need all those files that contain one vehicle each. The following function will delete all files from the specified path. # Step 4.12. NHTSAtable &lt;- list.files(&#39;data/&#39;, pattern = &#39;.csv&#39;) %&gt;% # Step 4.13. pblapply(function(x){ # Step 4.14. read.csv(paste0(&#39;data/&#39;,x), stringsAsFactors = FALSE)[,c(&#39;Results.VIN&#39;, &#39;Results.Make&#39;, &#39;Results.Model&#39;, &#39;Results.ModelYear&#39;, &#39;Results.FuelTypePrimary&#39;, &#39;Results.FuelTypeSecondary&#39;)] # Step 4.15. }) %&gt;% rbindlist() # Step 4.16. unlink(&quot;data/*&quot;) 0.12.5 Step 5 Again, you should not be able to understand what just happened there. My advice here is to just run this code again and again until you get comfortable with each part. I will tell you now though, that we will be simplifying that code and receiving the same outcome in the next sections. So, do not worry too much if the API part is too confusing right now. The final two steps will be a breeze compared to the step four. We are going to pull the table with all vehicles from the database and combine it with the data that we just got. Here, we are renaming the columns so they will match our old columns. # Renaming. colnames(NHTSAtable) &lt;- c(&#39;vin&#39;,&#39;make&#39;,&#39;model&#39;,&#39;year&#39;,&#39;gas1&#39;,&#39;gas2&#39;) Here, we are joining the data that we just got from the API with the data that we initially pulled from the database in the step 2. We are placing the initial table on the left and the one we want to join on the right. We already know that both have the column ‘vin’ so we do not need to specify what we are joining on. You can though. # Joining. lastVins &lt;- left_join(lastVins,NHTSAtable) Here, we are pulling all of our vehicles so we can stack the ones that we just got on top. We are still using the same connection variable ‘connection’. We are passing it as the first input to the dbGetQuery() function. The second argument is the actual SQL language wrapped in quotation marks. SELECT * FROM … means select everything from… # Pulling. old &lt;- dbGetQuery(connection,&quot;SELECT * FROM fin_book_table&quot;) As we pulled the data we noticed that the pull added the index column that we do not need. We will eliminate it with the following code: # Removing first column. old &lt;- old[,-1] It says: take the table ‘old’ and eliminate the first column from it. Remember, the left side of the comma there corresponds to rows, the right to columns. Renaming the columns form the table ‘old’ so they match ‘lastVins’. # Renaming. colnames(old) &lt;- c(&#39;expiration date&#39;, &#39;vin&#39;, &#39;year&#39;, &#39;base type&#39;, &#39;date&#39;, &#39;make&#39;, &#39;model&#39;, &#39;gas1&#39;, &#39;gas2&#39;) Here, we are binding (stacking) these two tables together. For this to work we must make sure that the columns are named and formatted the same. # Binding. final &lt;- rbind(old, lastVins) 0.12.6 Step 6 Lets write this out as a separate CSV file with today’s date. Finally, we are saving that final table. We are pasting the function Sys.Date() into the name of the file so if we repeat this tomorrow it wont override the file. Sys.Date() generates today’s date as you might have guessed. # Saving. fwrite(final, paste0(&#39;vehiclesComplete_&#39;,Sys.Date(),&#39;.csv&#39;)) We just went line by line over the whole assignment. The only tricky part that anyone new will have problems with is the step number four. At the same time, that step is the most exiting one, because you get to interact with some remote server and retrieve some valuable information from it. Although, I said that I do not expect you to understand that step, it is absolutely essential that you completely understand the rest. When I say the rest, I do not only mean the code in each chunk but also the whole workflow. This kind of workflow when you are loading libraries, connecting to databases, pulling data from them or somewhere else, aggregating, reshaping, joining and rejoining it, and then writing it out is the work pattern that you will be dealing in 95 percent cases at work. So, take that code and go through it many many times, try to take some parts out and see what changes, try to modify the step four, be ready to make it yours. In the next section I would like to dive deeper into working with dates, but after that, we will be rewriting this code again, simplifying it, and making it really ours. 0.13 Working with dates R is beautiful and one of the best languages, if not the best, for dealing with dates and times. Since R was the first programming language that I learned, I expected every language to be able to deal with dates, times, and, honestly, with other stuff as seamlessly as R. Transitioning to JavaScript, I quckly learned that it does not have anything that comes close to the packages that deal with dates and times on R level. Things that take a few seconds and a few characters of code in R, will literally take lines of code plus, maybe, a custom function to make them run. You will definitely experience that in the future when you, too, will start experimenting with other languages. In this section, I want to show you the most useful libraries and their functions for dealing with dates and times. Working with them will be a part of your daily routine, so you must become comfortable with it. This section will be more advanced than our intro to data types, however, I am still keeping in mind that you are just starting to learn and, therefore, will not do anything complicated here. Besides, dates and times are not hard at all, if you know which packages to use to deal with them. 0.13.1 as.Date(), Sys.Date() &amp; Sys.time() These three are not, usually, grouped together when talking about dates and times, but these are the three functions related to the topic that you will, probably, use the most. as.Date(), Sys.Date &amp; Sys.time() do not belong to any external library, they are part of base R. As we saw in the intro, the function as.Date() can create dates as well as convert existing character strings stat look like dates to dates. The Sys.Date() generates current date and Sys.time() generates current time. As you might recall, we have already used Sys.Date() and Sys.time() to save files so they will not overwrite each other with each loop iteration. That is a good technic to remember. Lets practice with these a bit more. Lets generate the current timestamp. # Timestamp. timeStamp &lt;- Sys.time() If we print it, we will see that it prints as a character string. # Printing. print(timeStamp) ## [1] &quot;2020-02-20 00:20:31 EST&quot; It is not though. How can we check? One would be to use the function class(), but those classifications might be confusing for you now. Lets experiment with it. Generate a new stamp. # Timestamp. newTimeStamp &lt;- Sys.time() Now, lets see how many seconds passed between these two. Just deduct the timeStamp from the newTimeStamp. # Calculating timediff. print(newTimeStamp - timeStamp) ## Time difference of 0.01477456 secs It should print ‘time difference of … mins (or seconds)’. We just performed a mathematical operation on characters. Right? Not really. Although it printed the timeStamps as characters, under the hood they are still in the time format. Lets see what happens when we explicitly generate a character string that only looks like a timestamp. For this just copy and paste the strings that we generated in the terminal. # Character time 1. charTimeStamp &lt;- &quot;2020-01-04 14:21:45 EST&quot; # Character time 2. charNewTimeStamp &lt;- &quot;2020-01-04 14:32:00 EST&quot; If they are real timestamps we will get the same result. Lets see if they are. # Printing timediff. print(charNewTimeStamp - charTimeStamp) ## Error in charNewTimeStamp - charTimeStamp: non-numeric argument to binary operator We got an error. It basically says that you are trying to perform a math operation on a non-math object. We can not perform mathematical operations with characters, unless we are counting. What if we start with a character string that looks like a date and we want to calculate something with it. We just need to convert them to the correct format. This is where functions like as.Date() and as.POSIXct() come into play. Lets see how they work. We got our timestamps saved as strings inside the charTimeStamp and charNewTimeStamp variables. Lets see if we can convert them back into the correct format so we could calculate the time difference between them. Lets, first, see what we can do with the as.Date() function. Using as.Date() we will need to specify what the string that we are trying to convert looks like. In our case, it looks like so: ‘%Y-%m-%d %H:%M:%S’. At first, this looks weird and complicated, but, this is a standard way of specifying what you timestamp looks like or what you want it to look like once converted (I will show you an example later). The percent signs will always be there, but, the characters after each percent sigh will differ based on what your string looks like. Lets, first, convert our date and then check out what else those formats can look like. Here, we are passing our character timestamps to the as.Date() function and specifying the format they are in. # Converting 1. backToDateTimeStamp &lt;- as.Date(charTimeStamp, format = &#39;%Y-%m-%d %H:%M:%S&#39;) # Converting 2. backToDateNewTimeStamp &lt;- as.Date(charNewTimeStamp, format = &#39;%Y-%m-%d %H:%M:%S&#39;) # Printing 1 print(backToDateTimeStamp) ## [1] &quot;2020-01-04&quot; # Printing 2. print(backToDateNewTimeStamp) ## [1] &quot;2020-01-04&quot; The converted timestamp is in the date format but the time part of it in now gone. This is not what we want. The as.Date() function will always return only the date part without time. In a lot of cases, this is what you will want, because you will not be dealing with times, only with dates. But what about the format that we specified? Since, we specidied that long format with both dates and times, why the result is different? It is different because as.Date() only asks us what the string that we are passing to it looks like and not what we want it to look like. Let me, now, give you an example of when we using this strange formating to specify what we want the date to look like. For that, we will use the function format(). We will take our backToDateTimeStamp variable that now looks like this: ‘%Y-%m-%d’ and will add the time part to it. # Formatting. addedTimeBack &lt;- format(backToDateTimeStamp, &#39;%Y-%m-%d %H:%M:%S&#39;) # Printing. print(addedTimeBack) ## [1] &quot;2020-01-04 00:00:00&quot; Now, there are a couple of problems here. The time that got added is ‘00:00:00’ and the whole thing is a character string again. # Checking class. class(addedTimeBack) ## [1] &quot;character&quot; This is not usefull to at all right now. I showed format() to you to point out how we can use the time formating to specify what we want our string to look like and not just what it looks like at the moment. Another reason is so you do not rely on format() and expect the datetime format out of it. I made this mistake a few times and it is very frustrating. So, how do we get an actual datetime out of the datetime-looking string? as.POSIXct() does that. What da fuck is as.POSIXct()? A function to manipulate objects of class “POSIXct” representing calendar dates and times. I hated this function for a long time, because it sounded to me like some nonsense. Do not worry about it at the moment, it will come to you. Just think of it as equvalent of as.Date() for both date and time format. Before I demonstrate it to you, I want to, first, go over some of the format examples so that ‘%blabla-%blabla-%bla’ crap makes more sence to you. First, lets get today’s date # Today&#39;s date. today &lt;- Sys.Date() # Printing. print(today) ## [1] &quot;2020-02-20&quot; The format right now is ‘%Y-%m-%d’. Lets change it to ‘%Y/%m/%d’. # Formatting. todaySlash &lt;- format(today, format = &#39;%Y/%m/%d&#39;) # Printing. print(todaySlash) ## [1] &quot;2020/02/20&quot; Lets do something different. Like this: January 05, 2020. # Formatting. todayBigDate &lt;- format(today, format = &quot;%B %d, %Y&quot;) # Printing. print(todayBigDate) ## [1] &quot;February 20, 2020&quot; This would be a nice lable, but because we are using format() it is just a character. Lets format it back to date. # Converting. dateAgain &lt;- as.Date(todayBigDate, format = &quot;%B %d, %Y&quot;) # Printing. print(dateAgain) ## [1] &quot;2020-02-20&quot; # Class. class(dateAgain) ## [1] &quot;Date&quot; We came back to it being a date. Hopefully, these few examples gave you an idea of how this whole formating works. I showed you only a couple of examples. There are many more formats, but they all use the same % pattern. You should go and check them out. One more thing before we move on. Lets first see what happens if we do not specify the format at all. # Converting 1. backToDateTimeStamp &lt;- as.Date(charTimeStamp) # Converting 2. backToDateNewTimeStamp &lt;- as.Date(charNewTimeStamp) # Printing. print(backToDateTimeStamp) ## [1] &quot;2020-01-04&quot; # Printing. print(backToDateNewTimeStamp) ## [1] &quot;2020-01-04&quot; It worked just like before. The reason it worked is because the strings are in %Y-%m-%d %H:%M:%S format. as.Date() can automatically guess that format and does a proper conversion without any errors. On your own, try to change the charTimeStamp variable to something like this: %Y%m%d %H-%M-%S and see if as.Date() guesses it right then. In many cases it will not. That is why it is better to specify the format regardless. Now, lets go back and finally use that as.POSIXct() function to convert our datetime-looking strings to actual timestamps. # Converting. backToDateTimeStampPOSIXt &lt;- as.POSIXct(charTimeStamp, format = &#39;%Y-%m-%d %H:%M:%S&#39;) # Converting. backToDateNewTimeStampPOSIXt &lt;- as.POSIXct(charNewTimeStamp, format = &#39;%Y-%m-%d %H:%M:%S&#39;) # Printing. print(backToDateTimeStampPOSIXt) ## [1] &quot;2020-01-04 14:21:45 EST&quot; # Printing. print(backToDateNewTimeStampPOSIXt) ## [1] &quot;2020-01-04 14:32:00 EST&quot; The time parts are there and the format is datetime. Lets confirm by subtracting one from the other. # Printing timediff. print(backToDateNewTimeStampPOSIXt - backToDateTimeStampPOSIXt) ## Time difference of 10.25 mins It worked. This was a deeper dive into the most used built-in R functions designed for dealing with dates and times. There are many more built-in (base) functions provided by R for dealing with different situations involving dates and times. However, when you starting to learn R and generally overwhelmed by the number of functions solving exactly the same problems, you just want something that works. The most intuitive library for dealing with dates that I have found is called ‘lubridate’. It just works, and I can recommend it for dealing with dates and times without hesitation. Believe me, it will save you a lot of time and headache. 0.13.2 Lubridate The following description is taken staight from lubridate’s reference: “R commands for date-times are generally unintuitive and change depending on the type of date-time object being used. Moreover, the methods we use with date-times must be robust to time zones, leap days, daylight savings times, and other time related quirks, and R lacks these capabilities in some situations. Lubridate makes it easier to do the things R does with date-times and possible to do the things R does not.” Having said that lubridate is much easier to work with, I want to be true to my word and will just show you on the same examples how much more intuitive it is. We still have our datetime-looking strings that we were fighting with in the previous section. Lets see how lubridate will convert them. Sage Tip: Before we do that though, I would like to show you a couple of useful functions. Usually, you will just click the broom icon to clean it, but sometimes it is more preactical to code it in. Our global environment (upper right corner) is pretty full and getting confusing to navigate. I want to clean it. # Cleaning the environment. rm(list = ls(all.names = TRUE)) The function rm() will clear all objects includes hidden objects. You could also just remove a single variable or table by writing rm(nameOfTheVariable). Personally, I almost never used it, but it might be useful for you. The second one is the garbage collection function (gc()). It will free up memrory and report the memory usage. gc() ## used (Mb) gc trigger (Mb) max used (Mb) ## Ncells 1097159 58.6 2070325 110.6 2070325 110.6 ## Vcells 2393137 18.3 10146329 77.5 10083381 77.0 This function is extremely useful when you are working with large objects or optimizing you code and applications. Now, lets recreate our dates and see how lubridate will handle conversions. # Char time 1. charTimeStamp &lt;- &quot;2020-01-04 14:21:45 EST&quot; # Char time 2. charNewTimeStamp &lt;- &quot;2020-01-04 14:32:00 EST&quot; # Converting 1. backToDateTimeStamp &lt;- ymd_hms(charTimeStamp) # Converting 2. backToDateNewTimeStamp &lt;- ymd_hms(charNewTimeStamp) # Printing 1. print(backToDateTimeStamp) ## [1] &quot;2020-01-04 14:21:45 UTC&quot; # Printing 2. print(backToDateNewTimeStamp) ## [1] &quot;2020-01-04 14:32:00 UTC&quot; It worked. But it also worked with as.Date() before. Lets see what happens if we change the format and also, for example, reverse the date making it %D/%M/%Y instead of %Y-%M-%D. # Char time 1. charTimeStamp &lt;- &quot;04/01/2020 14:21:45 EST&quot; # Char time 2. charNewTimeStamp &lt;- &quot;04/01/2020 14:32:00 EST&quot; # Converting 1. backToDateTimeStamp &lt;- mdy_hms(charTimeStamp) # Converting 2. backToDateNewTimeStamp &lt;- mdy_hms(charNewTimeStamp) # Printing 1. print(backToDateTimeStamp) ## [1] &quot;2020-04-01 14:21:45 UTC&quot; # Printing 2. print(backToDateNewTimeStamp) ## [1] &quot;2020-04-01 14:32:00 UTC&quot; We did have to use a different function but we did not have to specify that we are using forward slashes instead of dashes. If we did not specify that in as.Date(), it would probably kick an error. Lubridate does not have all the combinations for the order of years months days etc, but it does have most of them. Just to double check that we got timestamps in return, lets subtract one form the other once again. # Calculating difftime, print(backToDateNewTimeStamp - backToDateTimeStamp) ## Time difference of 10.25 mins Perfect. As I mentioned before, the number of options that R community offers you to deal with the same problem can be blessing as well as curse. It can definitely be a curse when you are just srarting and can get confused by a smallest thing. That is axactly why I do insist that you only use lubridate for now for dealing with dates. Lets see some other useful functions from lubridate. # Datetime. now &lt;- now() # Printing. print(now) ## [1] &quot;2020-02-20 00:20:31 EST&quot; # Date. today &lt;- today() # Printing. print(today) ## [1] &quot;2020-02-20&quot; These two are just lubridate’s substitutes for Sys.Date() &amp; Sys.time() functions. From now on lets stick with the datetime that we just generated with the function now(). The following two function are extremely important and useful. You will be using them a lot. # Floor to seconds. flooredToSecond &lt;- floor_date(now, &#39;second&#39;) # Printing. print(flooredToSecond) ## [1] &quot;2020-02-20 00:20:31 EST&quot; # Floor to minutes. flooredToMinite &lt;- floor_date(now, &#39;minute&#39;) # Printing. print(flooredToMinite) ## [1] &quot;2020-02-20 00:20:00 EST&quot; # Floor to every 15 minutes. flooredTo15Minites &lt;- floor_date(now, &#39;15 minutes&#39;) # Printing. print(flooredTo15Minites) ## [1] &quot;2020-02-20 00:15:00 EST&quot; # Floor to an hour. flooredToHour &lt;- floor_date(now, &#39;hour&#39;) # Printing. print(flooredToHour) ## [1] &quot;2020-02-20 EST&quot; # Floor to a day. flooredToDay &lt;- floor_date(now, &#39;day&#39;) # Printing. print(flooredToDay) ## [1] &quot;2020-02-20 EST&quot; # Floor to a month. flooredToMonth &lt;- floor_date(now, &#39;month&#39;) # Printing. print(flooredToMonth) ## [1] &quot;2020-02-01 EST&quot; # Floor to a year. flooredToYear &lt;- floor_date(now, &#39;year&#39;) # Printing. print(flooredToYear) ## [1] &quot;2020-01-01 EST&quot; The function floor_date() rounds down the timestamp that you pass into it to the time point that you specified as a second input. Notice that apart from rounding to a second or day or whatever, we can also round to 15 minutes. Same works for other time points as well. The second function is round_date(). It works exactly the same as floor_date(), you need to pay attention which way it will round. It can go up or down depending on what it is closer to. Try to experiment with it yourself. There two functions are extremely useful. Personally, I mostly use floor_date(). You will see its use case in the end of this chapter when we will be working with dates in the context of a whole dataframe. Now, lets extract sime time points from our variable ‘now’. # Extracting year. year &lt;- lubridate::year(now) # Printing. print(year) ## [1] 2020 The unction year() overlaps with the same function from other packages. We need to specify the package to avoid confusion and unintended results. Hence lubridate::. # Extracting month. month &lt;- lubridate::month(now) # Printing. print(month) ## [1] 2 # Extracting day. day &lt;- day(now) # Printing. print(day) ## [1] 20 # Extracting hour. hour &lt;- lubridate::hour(now) # Printing. print(hour) ## [1] 0 # Extracting minute. minute &lt;- lubridate::minute(now) # Printing. print(minute) ## [1] 20 # Extracting second. second &lt;- lubridate::second(now) # Printing. print(second) ## [1] 31.65593 Finally, lets see how lubridate handles mathematical operations with dates and times. # Adding five years. nowPlus5Years &lt;- now + years(5) # Printing. print(nowPlus5Years) ## [1] &quot;2025-02-20 00:20:31 EST&quot; # Adding five months. nowPlus5Months &lt;- now + months(5) # Printing. print(nowPlus5Months) ## [1] &quot;2020-07-20 00:20:31 EDT&quot; # Adding five days. nowPlus5Days &lt;- now + days(5) # Printing. print(nowPlus5Days) ## [1] &quot;2020-02-25 00:20:31 EST&quot; # Adding five hours. nowPlus5Hours &lt;- now + hours(5) # Printing. print(nowPlus5Hours) ## [1] &quot;2020-02-20 05:20:31 EST&quot; # Adding five minutes. nowPlus5Minutes &lt;- now + minutes(5) # Printing. print(nowPlus5Minutes) ## [1] &quot;2020-02-20 00:25:31 EST&quot; # Adding five seconds. nowPlus5Seconds &lt;- now + seconds(5) # Printing. print(nowPlus5Seconds) ## [1] &quot;2020-02-20 00:20:36 EST&quot; I hope, you can see how intuitive lubridate is. These were just some functions that lubridate provides for us. However, this is more than enough for you to start with. You do not really need to see the benefit of using lubridate over other datetime packages in R, and I do not expect you too. After all, you do not have anything to compare it to at the moment. When I started, I experimented with bunch of differnt libraries designed to work with dates. A lot of times, I just got stuck due to the sheer number of them. Sometimes function names were the same and I did not understand why I was getting different results all the time. Sometimes, I would get a character string instead of a datetime and did not know why. I would spend hours figuring things out. I came to realization that, at least, for your first months, you should focus on lubridate for datetimes and then branch out once you are comfortable. For the final part of this section, lets pull our vehicles data from the database and see how we can use lubridate to play with it. # Connecting. connection = dbConnect( drv = MySQL(), user = &quot;xxx&quot;, password = &#39;xxx&#39;, host = &#39;mybookdatabase.cgac79lt7rx0.us-east-2.rds.amazonaws.com&#39;, port = 3306, dbname = &#39;nikita99&#39;) Lets pull the whole table with the vehicles. # Pulling. vehicles &lt;- dbGetQuery(connection,&quot;SELECT * FROM fin_book_table&quot;) Show me first five rows. # Printing. print(head(vehicles,5)) ## row_names Expiration Date vin Vehicle Year Base Type ## 1 1 03/14/2020 2LMHJ5AT3ABJ10630 2010 BLACK-CAR ## 2 2 03/18/2020 5FNYF4H57FB070534 2015 BLACK-CAR ## 3 3 03/18/2020 2G1WB58K479242872 2007 LIVERY ## 4 4 03/21/2020 2G61M5S31H9120231 2017 LUXURY ## 5 5 03/13/2020 JTMRFREV5GJ102333 2016 LIVERY ## first_seen make model Results.FuelTypePrimary ## 1 2017-03-14 LINCOLN MKT Gasoline ## 2 2017-03-18 HONDA Pilot Gasoline ## 3 2017-03-18 CHEVROLET Impala &lt;NA&gt; ## 4 2017-03-21 CADILLAC XTS Gasoline ## 5 2017-03-13 TOYOTA RAV4 Gasoline ## Results.FuelTypeSecondary ## 1 &lt;NA&gt; ## 2 &lt;NA&gt; ## 3 &lt;NA&gt; ## 4 &lt;NA&gt; ## 5 &lt;NA&gt; I suspect that both ‘expiration date’ and ‘first_seen’ columns are characters. Lets check if we can do math with them anyway. I want add a column what will calculate the time difference for each vehicle between when it was first seen and when it will expire. # Deducting first seen from experation. vehicles$timeDifferende &lt;- vehicles$`Expiration Date` - vehicles$first_seen ## Error in vehicles$`Expiration Date` - vehicles$first_seen: non-numeric argument to binary operator Same error as before. The columns are characters. Lets convert them. By the way, do you remember why `Expiration Date` is surrounded in ticks? It is because it has space in between, not a good practice. Notice how date formats are differnt for these two columns. We well have to use different lubridate functions. # mdy() vehicles$`Expiration Date` &lt;- mdy(vehicles$`Expiration Date`) # ymd() vehicles$first_seen &lt;- ymd(vehicles$first_seen) Lets see if we can do math now. # Deducting first seen from experation. vehicles$timeDifferende &lt;- vehicles$`Expiration Date` - vehicles$first_seen # Printing. print(head(vehicles,5)) ## row_names Expiration Date vin Vehicle Year Base Type ## 1 1 2020-03-14 2LMHJ5AT3ABJ10630 2010 BLACK-CAR ## 2 2 2020-03-18 5FNYF4H57FB070534 2015 BLACK-CAR ## 3 3 2020-03-18 2G1WB58K479242872 2007 LIVERY ## 4 4 2020-03-21 2G61M5S31H9120231 2017 LUXURY ## 5 5 2020-03-13 JTMRFREV5GJ102333 2016 LIVERY ## first_seen make model Results.FuelTypePrimary ## 1 2017-03-14 LINCOLN MKT Gasoline ## 2 2017-03-18 HONDA Pilot Gasoline ## 3 2017-03-18 CHEVROLET Impala &lt;NA&gt; ## 4 2017-03-21 CADILLAC XTS Gasoline ## 5 2017-03-13 TOYOTA RAV4 Gasoline ## Results.FuelTypeSecondary timeDifferende ## 1 &lt;NA&gt; 1096 days ## 2 &lt;NA&gt; 1096 days ## 3 &lt;NA&gt; 1096 days ## 4 &lt;NA&gt; 1096 days ## 5 &lt;NA&gt; 1096 days Great, we got, in most cases 1096 days. Now, I want to see how many vehicles were first seen by month. firstSeenByMonth &lt;- vehicles %&gt;% dplyr::group_by(floor_date(first_seen, &#39;month&#39;)) %&gt;% count() This is what the code above just did: takes the dataframe vehicles, groups everything inside by the column first_seen (which we floored to month) and counts how many entries we have for each month. Stores the result inside ‘firstSeenByMonth’. Lets rename the columns for presentability. # Renaming. colnames(firstSeenByMonth) &lt;- c(&#39;month&#39;, &#39;count&#39;) # Printing. print(firstSeenByMonth) ## # A tibble: 15 x 2 ## # Groups: floor_date(first_seen, &quot;month&quot;) [15] ## month count ## &lt;date&gt; &lt;int&gt; ## 1 2016-10-01 378 ## 2 2016-11-01 2258 ## 3 2016-12-01 4178 ## 4 2017-01-01 4338 ## 5 2017-02-01 4031 ## 6 2017-03-01 5341 ## 7 2017-04-01 5539 ## 8 2017-05-01 5336 ## 9 2017-06-01 4943 ## 10 2017-07-01 4496 ## 11 2017-08-01 5504 ## 12 2017-09-01 4897 ## 13 2017-10-01 5669 ## 14 2017-11-01 5297 ## 15 2017-12-01 6132 This is it for this exercise. Whatever we just did is 90% of your usual workflow when when dealing with dates. It can be more complex or less complex, but the structure and general steps are the same. # Disconnecting. dbDisconnect(connection) ## [1] TRUE You have accomplished alot in this section. For now, focus on learning lubridate for dealing with dates, use base R from time to time, and keep in mind that there are other packages as well. Once you are completely comfortable with lubridate, start looking into zoo and chron. In reality, there are whole courses out there dedicated to dealing with dates and times in R. I really gave you just enough for you to get going while, hopefully, not getting confused. 0.13.3 Bonus Before we move on, I would like to show you something cool. It is a simple loop that prints current time second by second, like a clock. I want to show it to you, because when I was learning, cool things like this keept me going. Lets create a sequence of numbers that the loop will iterate over. # Sequence 1:10. sequenceOfTrumps &lt;- seq(1,10) Now, lets write a ‘for’ loop that will print the current time each time it makes its round. We also need to tell the loop to go to sleep for one second on each round so it does not print ten timestamps at once. # for each number in the sequence for (Trump in sequenceOfTrumps) { # print the current timestamp lubridate::now() print(now()) # fall asleep for 1 second Sys.sleep(1) } ## [1] &quot;2020-02-20 00:20:33 EST&quot; ## [1] &quot;2020-02-20 00:20:34 EST&quot; ## [1] &quot;2020-02-20 00:20:35 EST&quot; ## [1] &quot;2020-02-20 00:20:36 EST&quot; ## [1] &quot;2020-02-20 00:20:37 EST&quot; ## [1] &quot;2020-02-20 00:20:38 EST&quot; ## [1] &quot;2020-02-20 00:20:39 EST&quot; ## [1] &quot;2020-02-20 00:20:40 EST&quot; ## [1] &quot;2020-02-20 00:20:41 EST&quot; ## [1] &quot;2020-02-20 00:20:42 EST&quot; In my opinion, it is a cool excercise. You can change 10 to a higher number and it will print for longer. You can make it sleep longer and intervals will be longer. You can change now() to ‘Trump’ and it will print ‘Trump’ many times. If you want it to print infinitely, you should look into the ‘while loops’ instead of ‘for loops’. Good luck. 0.14 Rewriting our code It has been some time and we have been writing and rewriting our code trying to understand each line. Our manager gave us a couple of months to really get it. It has been only a couple of weeks, but we mostly understand what each code chunk does. Before running to brag about our progress to the manager, we really want to make that code ours by rewriting it in simpler and more concise way. That will definitely cement our knowledge and really show that we know what the hell we are doing. Before we jump ahead, if you think that you are ready, you should be able to solve the following test. If you can not, go back, because you missed something. I will only give you a couple of pointers and the final value that I expect to get from you. Connect to the database Pull columns ‘first_seen’ and ‘make’ from the table ‘book_table’ The column ‘first_seen’ must be less than ‘2017-09-02’. Change ‘=’ to ‘&lt;’ for it. Store the result in a variable ‘tableTest’ Make sure the first_seen is in the right format Floor the first_seen column to 15 days Tell me how many vehicles were first seen on 2017-05-16. Your result should be: 2252 If you could not pass the test, do not proceed, because you do not know what the hell you are doing yet. This is not a sprint that you can just get over with. If you do not want the time that you put into reading so far be a waste, go back and solve the test first. If you solved the task, good for you, you get a star and a rainbow and can now proceed to the next section where we will be rewriting our complex code in order to trully make it ours. I will keep the ‘step’ structure in tact so it is easier for you to navigate and compare the code to the one we wrote initially. Do not expect some tremendous changes to the existing code. I just want to point out a few things here and there that, maybe, were unnecessary and could be simplified. 0.14.1 Step 1 Here, we need to add one more library. It is called ‘jsonlite’. Install it first though. Other than that, nothing to change here. #installing install.packages(&#39;jsonlite&#39;) # Loading the libraries library(lubridate) library(data.table) library(dplyr) library(openxlsx) library(tidyr) library(fst) library(stringi) library(zoo) library(ggplot2) library(scales) library(tibble) library(RMySQL) library(pbapply) library(jsonlite) # Connecting to the database connection = dbConnect( drv = MySQL(), user = &quot;xxx&quot;, password = &#39;xxx&#39;, host = &#39;mybookdatabase.cgac79lt7rx0.us-east-2.rds.amazonaws.com&#39;, port = 3306, dbname = &#39;nikita99&#39;) 0.14.2 Step 2 The step two is not wrong and it might be even better for somewhat experienced programmer. However, when you are new, every extra comma, sign, variable, etc is a big deal and a cause of panic. Lets see how we can change this to make it easier to look at and understand. Get rid of this: today &lt;- ‘2018-01-02’. Storing dates inside of variables to later paste them into SQL queries or anywhere else is useful when you are automating your scripts or if your query is inside of a loop and that date that you are pasting has to be different on every iteration. You are not doing that anytime soon so no need to complicate things. Since we are not storing the date inside of the ‘today’ variable, we are not pasting that variable into the query. Therefore, we can get rid of the function paste() along with its command ‘sep = &quot;&quot;’ and the variable ‘today’ with all that confusing punctuation around it. We do need to change ‘today’ to an actual date though. After we done with that, we can also change the column names just like we did in ‘vehicle vin number’. Our goal is to have column names without spaces. That would be it. Lets see what we got: # Pulling. lastVins &lt;- dbGetQuery(connection, &quot;SELECT `expiration date` as expirationDate, `base type` as baseType, `vehicle vin number` as vin, first_seen as date FROM book_table WHERE first_seen = &#39;2018-01-02&#39;&quot;) It is also good to capitalize the key words in SQL (SELECT, FROM, WHERE, ect). It will make you see the difference between key words and inputs. I do not do that though. As you can see, it was not a dramatic change, but it eliminated some extra code. And it still runs just the same. 0.14.3 Step 3 This step is straightforward. Nothing to see here. # Trimming. lastVins$vin &lt;- trimws(lastVins$vin) # Creating a vector. vinVector &lt;- lastVins$vin 0.14.4 Step 4 This is the step where you will notice the greatest transformation. In this step, we were connecting to the NHTSA api, feeding our vin numbers into it and retreiving vehicles’ information for each vin. It was, by far, the hardest part, and if you understood it, congradulations, you are a genious. I did want you to understand the general flow of that code and what each part did, but do not worry if you did not. For me personally, that chunk of code was an enigma for quite a while. I accepted that I could not understand the first thing about it and was just glad that it worked. However, I made a note for myself that once I understood how it works with being able to replicate it from scratch and improve it, I will then know R. It took me a year and three months to do that. Obviously, I was not trying to do exactly that. It just happened that after that time I needed that code and when I opened it and looked at it, I said: ‘Ohh, I can improve it!’. Honestly, I was surprised how much simpler I was able to make it. That not only speaks for the progress that I have made during that year, but also, for the unnecessary complexity of the code that I got handed over. It would be so much easier for me to understand what was going on if that chunk looked something like the one below. But again, It became my montain to climb and I am better for it. Hopefully, for you, this simplification will serve as a boost in your learning process. Last time, we created a function that connected us to the api. Then we created a loop. That loop went over every vin number in our list of vin numbers and applied that function to each vin. Each time the loop made its round, it returned a dataframe containing one vehicle information. That table got saved as a csv file. Once the whole thing finished running, we had a bunch of files each holding one vehicle. We then wrote another loop that went over each file, opened it and bound all of them together one by one. On top of that, we had a tryCatch() function checking for errors, which made the whole thing look even more ugly. Here is what I did instead. I creatd an empty variable ‘finalData’. Creating an empty variable or a list before a loop is a usual practice if you want to stack the return of that loop in one table. After that, I wrote a simple ‘for loop’ that goes over each vin in our list of vins that we created in the previous step (vinVector). Each vin is pasted into the api address that NHTSA provides for us. That returns a json file with all the information about that vehicle. If you do not understand how that particular step works, paste any vin number into the NHTSA provided link.instead of the ‘vin’ variable use an actual vin number. Like this: ‘https://vpic.nhtsa.dot.gov/api/vehicles/DecodeVinValues/4T1BD1FK7GU197727?format=json’ and insert that link into your browser. You should see a json file with the information for that particular vehicle. The function fromJSON() reads that json file into R and lets us see it as a list. After that, we are converting that list into a data table format using the function as.data.table(). Now, we just need to keep only the columns that we want and bind that single row table with the empty variable (finalData) that we created. When we bind our data table to the empty variable, our data table basically becomes the first row of that ‘finalData’ table. On the next turn of the loop, the ‘finalData’ is not empty anymore as it holds that first row from the previous iteration, and when we bind for the second time, the second row is added, and so on and so forth for each vin number. Finally, I printed the first few rows of the result just to check if everything is fine. #1 finalData = NULL #2 for (vin in vinVector){ #3 listWithResult &lt;- fromJSON(paste0(&#39;https://vpic.nhtsa.dot.gov/api/vehicles/DecodeVinValues/&#39;,vin,&#39;?format=json&#39;)) #4 ourData = as.data.table(listWithResult) #5 ourData &lt;- ourData[, c(&#39;Results.VIN&#39;, &#39;Results.Make&#39;, &#39;Results.Model&#39;, &#39;Results.ModelYear&#39;, &#39;Results.FuelTypePrimary&#39;, &#39;Results.FuelTypeSecondary&#39;)] #6 finalData &lt;- rbind(finalData, ourData) } #7 print(head(finalData)) ## Results.VIN Results.Make Results.Model Results.ModelYear ## 1: 2LNBL8CVXBX751564 LINCOLN Town Car 2011 ## 2: 5N1AR2MM5GC610354 NISSAN Pathfinder 2016 ## 3: 5FRYD4H44FB017401 ACURA MDX 2015 ## 4: 4T3ZA3BB0AU031928 TOYOTA Venza 2010 ## 5: 4T1BD1FK7GU197727 TOYOTA Camry 2016 ## 6: JTDKN3DU6F1930271 TOYOTA PRIUS 2015 ## Results.FuelTypePrimary Results.FuelTypeSecondary ## 1: Flexible Fuel Vehicle (FFV) Gasoline ## 2: Gasoline ## 3: Gasoline ## 4: Gasoline ## 5: Gasoline Electric ## 6: Gasoline Electric I think, it is pretty cool how we were able to change that monstrosity into just seven steps in one shot. A big part of this simplification is, of course, the elimination of the tryCatch() function. After experimenting with the api for some time, I figured that it does not produce any arrors and when it does, it automatically skips them. Also, it does not time out if you feed vin numbers one at a time, so we do not need sys.sleep() function. Obviously, I did not arrive to this code in an hour. The same tedious process that made this code better is the same process that made me better. Righ now, you are just copying my code and it is not very good. Maybe, knowing how to use apis like this will give you a boost, but it is really through a struggle that you improve. If you want to do that, try to simulate an error using that api. Go into the list of our vins in excel or figure out how to do it in R and mess up one or two vins in that list. Run the list through the api again and see if it kicks an error. If it does, reintroduce the tryCatch() function into the simplified code. I think, it is much better to start with simpler code so you can gradually layer on top of it. Good luck. 0.14.5 Step 5 There is nothing in the steps 5 and 6 that we should improve at the moment. If you do not remember what the commands below do, return to the previous section where I go over each line in detail. # Renaming. colnames(finalData) &lt;- c(&#39;vin&#39;,&#39;make&#39;,&#39;model&#39;,&#39;year&#39;,&#39;gas1&#39;,&#39;gas2&#39;) # Joining lastVins &lt;- left_join(lastVins,finalData) # Pulling. old &lt;- dbGetQuery(connection,&quot;SELECT * FROM fin_book_table&quot;) # Deleting first column old &lt;- old[,-1] # Renaming. colnames(old) &lt;- c(&#39;expirationDate&#39;,&#39;vin&#39;,&#39;year&#39;,&#39;baseType&#39;,&#39;date&#39;,&#39;make&#39;,&#39;model&#39;,&#39;gas1&#39;,&#39;gas2&#39;) # Binding. final &lt;- rbind(old, lastVins) 0.14.6 Step 6 # Saving the combined dataset. fwrite(final, paste0(&#39;vehiclesComplete_&#39;,Sys.Date(),&#39;.csv&#39;)) # Disconnecting from the database. dbDisconnect(connection) ## [1] TRUE Lets also save the daily data that we worked on: # Saving. fwrite(lastVins, &#39;lastVins.csv&#39;) 0.15 Adding MPG We have spent weeks now writing and rewriting running and rerunning that piece of code that our manager handed over to us. We have, finally, mastered it and completed the initial task well ahead of time. We presented the running code to our superiors and they were very impressed. We demonstrated that we can tackle such a complicated task in a short period of time. The most important part is that we did not just take the code and mindlessly ran it every n period, but, actually, rewrote and improved it. We have positioned ourself as a serious analyst, developer, or engineer ready to take on more important tasks. The following week, our manager sits down with us and says that everybody is very impressed with our progress and that the code that we put together will be very useful for the IT team. He also asks us to look into adding mpg (miles per gallon) data for each vehicle. Nobody really attempted to do that so far, but having that would be extremely useful. Seeing how well you have done on your first big assignment, he feels that it would be logical to build on that momentum. He gives you a pointer though. He says, check out fueleconomy.gov, they might have the data that we need. Try to add mpgs as a column to the vehicles that you have, start with the one day that you worked on, we will use it as a proof of concept. He said that there was no time limit on the assignment. He wished you good luck and left. You are extremely exited, because you know that having a reputation of a reliable and self-sufficient professional is very important, and it seems that you are moving in the right direction. You are definitely not wasting any time and jumping straight to it. Install the package stringr and load it. install.packages(&#39;stringr&#39;) library(stringr) The file vehiclesfuel.csv contains multiple years of fuel data from fueleconomy.gov. Lets load it in to see what is inside. # Reading data in. fuel &lt;- fread(&quot;vehiclesfuel.csv&quot;) The data table has too many useless to us columns. At first, we should identify potentially useful columns, keep only them, and go from there. Few thing for certain, we need make, model, year, gas type, and mpg itself. We identified a few more potentially useful columns. Lets keep only them. # Selecting columns. fuel &lt;- fuel[, c(&quot;make&quot;, &quot;model&quot;, &quot;year&quot;, &quot;VClass&quot;, &quot;fuelType&quot;, &quot;fuelType1&quot;, &quot;fuelType2&quot;, &quot;city08&quot;, &quot;cityA08&quot;, &quot;cityE&quot;, &quot;fuelCost08&quot;, &quot;fuelCostA08&quot;, &quot;charge120&quot;, &quot;charge240&quot;)] You can definetely go through these to check what they do or mean. Also, there is a legend on the fueleconomy.gov. Our ultimate goal here is to end up with the data table that has whatever it had before plus mpg for each vehicle. Upon the initial inspection, I noticed a huge problem. There is no unique identifier for the gas data. A unique identifier is something we could easily connect our data with the fuel data. The unique identifier in our data, for example, is a vin number. The left joins that we performed so far we all based on us joining one table to another on the vin number column. We do not have that with the fuel data, which is a big problem for us. We are going to need to created that identifier on our own. The only way that I could think of at the moment was to combine make, model, year, and fuel type into a single string in both tables and join them. It is a good and, I think, the best approach for us given the data. However, it is very challenging at the same time. There is one big problem that makes it so. Makes, models, and fuel types are not uniform across the tables, meaning that even if we join them into single strings they will not merge because they are just a litte different. I will give you an example, ‘mercedes-benz’ is different from ‘Mercedes benz’, ‘wolkswagen golf gti’ is different from ‘wolkswagen golf/gti’. Even a smallest discrepancy will cause a no-merge. Our task is to make these two tables as uniform as possible. It is challenging, but that is how you learn. I will purposly use the code that I used when I did this task. It is not the most elegant and maybe I would do it differently now. But, if it was good enough for me then, it is good enough for you now. There is no point in showing you the most sophisticated code right away, because you will definitely get confused. Sage Tip: The only thing that matters is that your code does the job. Do the job however you can, and then see if you can make it look nice as well. First, we are going to work with the fuel data. Although, you can go row by row to see what you should eliminate in each, it is not practical. It is much better to apply the same standardization to everything and then see if some individual cases need adjustments. Lets eliminate all kinds if punctuation from make and model. # Eliminating punctuation 1. fuel$make &lt;- gsub(&quot;[[:punct:]]&quot;,&quot; &quot;,fuel$make) # Eliminating punctuation 2. fuel$model &lt;- gsub(&quot;[[:punct:]]&quot;,&quot; &quot;,fuel$model) The function gsub() does exactrly what we need. It takes three inputs: what you want to change; what you changing it to; which column are you targeting. In our case, “[[:punct:]]” means ‘all punctuation’, It is a special command and you will have to google to see if there are more like that. Usually, you do something like this: gsub(“.”,&quot; &quot;,fuel$make) this will change all dots to spaces in the column ‘make’ of the table ‘fuel’. Next, lets eliminate the spaces that can be around our makes and model. You already know the function. # Eliminating white spaces 1. fuel$make &lt;- trimws(fuel$make) # Eliminating white spaces 2. fuel$model &lt;- trimws(fuel$model) The next thing I noticed is that, sometimes, both, makes and model can be stored as two words in our data and as three or more in the fuel data. You can see it more often with models than with makes but I noticed it in both. Again, the unique identifiers must be the same to merge. We might need to sacrafice precision a bit for that. For example, the ‘model’ in our data might say ‘Golf’, but the ‘fuel’ table will have both ‘Golf’ and ‘Gold GTI’. We will have to eliminate the ‘GTI’ part and average their mgs. That will scew mpg higher, but that is the price for not doing everything manually. First. lets split the column ‘make’ into ten columns. This will create ten columns out of one with each word occupying one column. Because the majority of our makes consists of one or two words, most of the columns will be empty. Do not worry, we will get rid of them. Making sure that ‘fuel’ is in the data table format. # Converting to data table. setDT(fuel) Splitting the column into ten. # Splitting. fuel &lt;- fuel[, paste0(&quot;make&quot;, 1:10) := tstrsplit(make, &quot; &quot;)] The code above follows the data.table package code pattern. That pattern reads as follows: data table[work with rows , work with columns]. Our code says: in the data table fuel, create ten columns named make1, make2 … make10, and populate these columns with the contents of the column ‘make’ that we are splitting (the splitting point is &quot; &quot;). It is better if you just take a look at the resulting data table. We end up with ten extra columns. Most of them are empty. We will be keeping only the first two. Lets put these ten columns back into one. First, we eliminate the column ‘make’. We will be replacing it with the result of or splitting stuff. # Eliminating first column. fuel &lt;- fuel[, -1] Second, we are pasting make1 and make2 together to recreate the column ‘make’. # Pasting. fuel$make &lt;- paste(fuel$make1, fuel$make2) Third, because not every make consisted of two words, when we pasted them back together we got, for example, “Audi NA”. We do not need that NA. # Removing nas. fuel$make &lt;- str_remove_all(fuel$make, &quot;NA&quot;) Fourth, we eliminated the NA, but there was a spece between “Audi” and “NA”. We do not need it. # Eliminating spaces. fuel$make &lt;- trimws(fuel$make) Finally, we can eliminate the columns that we do not need and put the ones that we do need in the right order by using the function select(). # Selecting columns. fuel &lt;- fuel %&gt;% dplyr::select(&quot;make&quot;, &quot;model&quot;, &quot;year&quot;, &quot;VClass&quot;, &quot;fuelType&quot;, &quot;fuelType1&quot;, &quot;fuelType2&quot;, &quot;city08&quot;, &quot;cityA08&quot;, &quot;cityE&quot;, &quot;fuelCost08&quot;, &quot;fuelCostA08&quot;, &quot;charge120&quot;, &quot;charge240&quot;) Now, we need to do the same thing to the ‘model’ column. # Splitting. fuel &lt;- setDT(fuel)[, paste0(&quot;model&quot;, 1:10) := tstrsplit(model, &quot; &quot;)] In model, we just want one word. # Pasting. fuel$model &lt;- paste(fuel$model1) # Removing nas. fuel$model &lt;- str_remove_all(fuel$model, &quot;NA&quot;) # Eliminating spaces. fuel$model &lt;- trimws(fuel$model) # Selecting columns. fuel &lt;- fuel %&gt;% dplyr::select(&quot;make&quot;, &quot;model&quot;, &quot;year&quot;, &quot;VClass&quot;, &quot;fuelType&quot;, &quot;fuelType1&quot;, &quot;fuelType2&quot;, &quot;city08&quot;, &quot;cityA08&quot;, &quot;cityE&quot;, &quot;fuelCost08&quot;, &quot;fuelCostA08&quot;, &quot;charge120&quot;, &quot;charge240&quot;) We are only interested in the newer vehicles. Lets filter out some old junk. # Filtering. fuel &lt;- fuel %&gt;% dplyr::filter(year &gt; 2008) The ‘%&gt;%’ might still confuse you. I will explain again. ‘%&gt;%’ is called ‘pipe’ operator. It sends that data table into the function without actually writing it there. This same function can be written like this: fuel &lt;- dplyr::filter(fuel$year &gt; 2008). Imagine you wanted to do multiple operation in a row with different columns of ‘fuel’. You would have to write multiple functions. With the pipe, you can do it all in one shot. If it is not clear, do not worry, it will come with practice. So far we got make, model and year. We need to standardize our fuel types. Gasoline alone is listed under ‘Premium’, ‘Midgrade’ and ‘Regular’. We need to standardize it. Gas is ‘g’, Diesel is ‘d’, etc. We will later apply the same logic to our initial data. # Creating a new column based on existing one. setDT(fuel)[fuelType==&quot;Premium&quot;, fuel:=&quot;g&quot;] This says: if fuelType is ‘Premium’, create a column named ‘fuel’ where corresponding cells will be populated with ‘g’. Check out how your table changed and it will become clear. Lets do the same to the rest. # Abbreviating fuel types. fuel[fuelType==&quot;Regular&quot;, fuel:=&quot;g&quot;] fuel[fuelType==&quot;Midgrade&quot;, fuel:=&quot;g&quot;] fuel[fuelType==&quot;Gasoline or natural gas&quot;, fuel:=&quot;h&quot;] fuel[fuelType==&quot;CNG&quot;, fuel:=&quot;cng&quot;] fuel[fuelType==&quot;Gasoline or E85&quot;, fuel:=&quot;h&quot;] fuel[fuelType==&quot;Gasoline or propane&quot;, fuel:=&quot;h&quot;] fuel[fuelType==&quot;Electricity&quot;, fuel:=&quot;e&quot;] fuel[fuelType==&quot;Premium or E85&quot;, fuel:=&quot;h&quot;] fuel[fuelType==&quot;Premium Gas or Electricity&quot;, fuel:=&quot;h&quot;] fuel[fuelType==&quot;Regular Gas and Electricity&quot;, fuel:=&quot;h&quot;] fuel[fuelType==&quot;Premium and Electricity&quot;, fuel:=&quot;h&quot;] fuel[fuelType==&quot;Regular Gas or Electricity&quot;, fuel:=&quot;h&quot;] fuel[fuelType==&quot;Diesel&quot;, fuel:=&quot;d&quot;] If you are wondering how I found out all fuel types in the fuel data table, here is how: # Printing. print(unique(fuel$fuelType)) ## [1] &quot;Premium&quot; &quot;Regular&quot; ## [3] &quot;Diesel&quot; &quot;Gasoline or E85&quot; ## [5] &quot;CNG&quot; &quot;Premium or E85&quot; ## [7] &quot;Midgrade&quot; &quot;Electricity&quot; ## [9] &quot;Premium Gas or Electricity&quot; &quot;Regular Gas and Electricity&quot; ## [11] &quot;Premium and Electricity&quot; &quot;Gasoline or natural gas&quot; ## [13] &quot;Regular Gas or Electricity&quot; We do not really need all these columns. The only ones that we need are make, model, year, fuel, and city08. # Selecting columns. fuel &lt;- fuel %&gt;% dplyr::select(make,model,year,fuel,city08) We want to end up with a single string (unique identifier). Something like: “audia42010g”. We need to get rid of spaces in make and model again. Lets do it in one shot this time. # Eliminating spaces 1. fuel$make &lt;- trimws(gsub(&quot; &quot;,&quot;&quot;,fuel$make)) # Eliminating spaces 2. fuel$model &lt;- trimws(gsub(&quot; &quot;,&quot;&quot;,fuel$model)) The gsub() is excecuted first. trimws() is applied to the result of it. It is the same as 1. fuel$make &lt;- gsub(&quot; “,”&quot;,fuel$make) then 2. fuel$make &lt;- trimws(fuel$make) We can now create our unique identifier. # Pasting together. fuel$identifier &lt;- paste0(fuel$make, fuel$model, fuel$year, fuel$fuel) We do not need these columns anymore. # Selecting. fuel &lt;- fuel %&gt;% dplyr::select(identifier, city08) Now, we need to find the mean mpg per vehicle make/model/year/fuel. # Grouping and summarising. fuel &lt;- fuel %&gt;% dplyr::group_by(identifier) %&gt;% dplyr::summarize(mpg = mean(city08)) Here you can see the piping again and how it saves us time. Lets make our identifier completely lower case. # Switching to lower case. fuel$identifier &lt;- tolower(fuel$identifier) There might be duplicates left. It is smart to always remove them just in case. # Keeping uniques. fuel &lt;- unique(fuel) I think this should be enough. We created an identifier for each time of vehicle, but we are not done yet. We need to do the same for our data. It will not be too hard though as we will mostly be repeating the same steps. Reading in the file with one day of vehicles that we saved before. # Reading data in. data &lt;- fread(&#39;lastVins.csv&#39;) Lets split out the columns that we will be working with. # Selecting columns. finalData &lt;- data %&gt;% dplyr::select(vin,make,model,year,gas1,gas2) Before we start working on the unique identifier, we need to abbreviate our fuel types just like we did before. There are more combinations here and it was more tedious. You do not need to go through the table and do it, I have done it for you, but just keep in mind that programming often involves a bunch of dirty work. The method is the same as before though. Get the unique types and go from there. # Renaming empty cells. finalData &lt;- finalData[gas2 == &#39;&#39;, gas2:=NA] # Conditionally abbriviating the fuel types. finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Gasoline&#39; &amp; is.na(finalData$gas2),Type:=&#39;g&#39;] finalData&lt;- setDT(finalData)[finalData$gas1 == &#39;Gasoline&#39; &amp; finalData$gas2 == &#39;Electric&#39;,Type:=&#39;h&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Gasoline&#39; &amp; finalData$gas2 == &#39;Ethanol (E85)&#39;,Type:=&#39;h&#39;] finalData &lt;- setDT(finalData)[is.na(finalData$gas1) &amp; is.na(finalData$gas2),Type:=&#39;Unknown&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Flexible Fuel Vehicle (FFV)&#39; &amp; finalData$gas2 == &#39;Gasoline&#39;,Type:=&#39;h&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Flexible Fuel Vehicle (FFV)&#39; &amp; is.na(finalData$gas2),Type:=&#39;h&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Electric&#39; &amp; finalData$gas2 == &#39;Gasoline&#39;,Type:=&#39;h&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Diesel&#39; &amp; is.na(finalData$gas2),Type:=&#39;d&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Gasoline&#39; &amp; finalData$gas2 == &#39;Flexible Fuel Vehicle (FFV)&#39;,Type:=&#39;h&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Flexible Fuel Vehicle (FFV), Gasoline&#39; &amp; finalData$gas2 == &#39;Ethanol (E85)&#39;,Type:=&#39;h&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Gasoline, Flexible Fuel Vehicle (FFV)&#39; &amp; finalData$gas2 == &#39;Ethanol (E85)&#39;,Type:=&#39;h&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Electric&#39; &amp; is.na(finalData$gas2),Type:=&#39;e&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Gasoline, Electric&#39; &amp; finalData$gas2 == &#39;Electric, Gasoline&#39;,Type:=&#39;h&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Gasoline&#39; &amp; finalData$gas2 == &#39;Compressed Natural Gas (CNG)&#39;,Type:=&#39;h&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Electric, Gasoline&#39; &amp; finalData$gas2 == &#39;Gasoline, Electric&#39;,Type:=&#39;h&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Gasoline, Flexible Fuel Vehicle (FFV)&#39; &amp; finalData$gas2 == &#39;Gasoline&#39;,Type:=&#39;h&#39;] finalData &lt;- setDT(finalData)[is.na(finalData$gas1) &amp; finalData$gas2 == &#39;Gasoline&#39;,Type:=&#39;g&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Compressed Natural Gas (CNG)&#39; &amp; is.na(finalData$gas2),Type:=&#39;cng&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Ethanol (E85)&#39; &amp; is.na(finalData$gas2),Type:=&#39;ethnl&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Flexible Fuel Vehicle (FFV)&#39; &amp; finalData$gas2 == &#39;Electric&#39;,Type:=&#39;h&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Flexible Fuel Vehicle (FFV), Gasoline&#39; &amp; finalData$gas2 == &#39;Gasoline&#39;,Type:=&#39;h&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Electric, Gasoline&#39; &amp; is.na(finalData$gas2),Type:=&#39;h&#39;] finalData &lt;- setDT(finalData)[finalData$gas1 == &#39;Liquefied Petroleum Gas (propane or LPG)&#39; &amp; is.na(finalData$gas2),Type:=&#39;lpg&#39;] Lets get our identifier now. # Eliminating punctuation and spaces 1. finalData$make &lt;- trimws(gsub(&quot;[[:punct:]]&quot;,&quot; &quot;,finalData$make)) # Eliminating punctuation and spaces 2. finalData$model &lt;- trimws(gsub(&quot;[[:punct:]]&quot;,&quot; &quot;,finalData$model)) Our ‘makes’ do not need splitting, we just need to eliminate spaces. # Eliminating punctuation and spaces finalData$make &lt;- trimws(gsub(&quot; &quot;,&quot;&quot;,finalData$make)) Splitting the models. # Splitting. setDT(finalData)[, paste0(&quot;model&quot;, 1:2) := tstrsplit(model, &quot; &quot;)] Keeping only the first word and inserting it back into the ‘model’. # Pasting the column model1 into model. finalData$model &lt;- finalData$model1 # Removing NAs finalData$model &lt;- str_remove_all(finalData$model, &quot;NA&quot;) # Eliminating spaces around the models. finalData$model &lt;- trimws(finalData$model) Lets only keep the columns that we need. # Selecting columns. finalData &lt;- finalData %&gt;% dplyr::select(vin, make,model,year,Type) Now, lets create a unique identifier so we can join our date with the mpg data. # Pasting four columns together. finalData$identifier &lt;- paste0(finalData$make, finalData$model, finalData$year, finalData$Type) Lets make the identifier all lower case. # Lowercasing. finalData$identifier &lt;- tolower(finalData$identifier) Keeping only the neccessary columns. # Selecting columns. finalData &lt;- finalData %&gt;% dplyr::select(vin, identifier) Done. I think, we are ready to try to join our data with the mpg data. We created unique identifiers for each vehicle type and most of them should join fine. Some vehicles will require manual adjustments of their names. Lets see. # Joining. testJoin &lt;- left_join(finalData, fuel) # Printing. print(head(testJoin)) ## vin identifier mpg ## 1 2LNBL8CVXBX751564 lincolntown2011h 16.00000 ## 2 5N1AR2MM5GC610354 nissanpathfinder2016g 19.33333 ## 3 5FRYD4H44FB017401 acuramdx2015g 19.00000 ## 4 4T3ZA3BB0AU031928 toyotavenza2010g 19.50000 ## 5 4T1BD1FK7GU197727 toyotacamry2016h NA ## 6 JTDKN3DU6F1930271 toyotaprius2015h 51.00000 I will not be manually fixing the discrepancies here. It worked as a prove of concept and that is good enough. We could notice that a lot of toyota camries are missing there. It would be a good starting point for fixing the missing vehicles. Obviously, in real life, I did manually fix 90% of the missing vehicles and joined them again and again until I felt comfortable to present the result. Before we move on, lets join this back to our main data and write it out again. We are joining the table that we split above to the testJoin table that now contains the mpg info by vin number. # Joining. data &lt;- left_join(data, testJoin) # Printing. print(head(data)) ## expirationDate baseType vin date make model ## 1 01/02/2021 BLACK-CAR 2LNBL8CVXBX751564 2018-01-02 LINCOLN Town Car ## 2 01/02/2021 BLACK-CAR 5N1AR2MM5GC610354 2018-01-02 NISSAN Pathfinder ## 3 01/02/2021 BLACK-CAR 5FRYD4H44FB017401 2018-01-02 ACURA MDX ## 4 01/02/2021 LIVERY 4T3ZA3BB0AU031928 2018-01-02 TOYOTA Venza ## 5 01/02/2021 BLACK-CAR 4T1BD1FK7GU197727 2018-01-02 TOYOTA Camry ## 6 01/02/2021 LIVERY JTDKN3DU6F1930271 2018-01-02 TOYOTA PRIUS ## year gas1 gas2 identifier mpg ## 1 2011 Flexible Fuel Vehicle (FFV) Gasoline lincolntown2011h 16.00000 ## 2 2016 Gasoline &lt;NA&gt; nissanpathfinder2016g 19.33333 ## 3 2015 Gasoline &lt;NA&gt; acuramdx2015g 19.00000 ## 4 2010 Gasoline &lt;NA&gt; toyotavenza2010g 19.50000 ## 5 2016 Gasoline Electric toyotacamry2016h NA ## 6 2015 Gasoline Electric toyotaprius2015h 51.00000 # Saving. fwrite(data,&#39;dataWithMpg.csv&#39;) We are done with the analytics part of this book. The grind work is over. This is pretty good so far. Just for your reference, this is what you need to know to be able to work on your own without someone else constantly holding your hand. Obviously, there are better ways to solve some of the things that we covered, but they are much harder to grasp. Understanding the stuff that we coverd so far, should give you a good foundation to solve simple to medium level tasks and figure out more complicated stuff on your own. As I mentioned before, beautiful code will come later, first you must learn how to get stuff done. We are done with analytics, but we are not done with our task yet. We must be able to generate some graphs and chart to present to our boss. In the next section we will be doing just that. For now, pat yourself on the back, you have done a lot, especially if you understood most of it. If not, try to go over the stuff that was not clear again, it will go a long way for you. 0.16 Charts &amp; Reports R is great at graphing and reporting your findings. In fact, when it is compared to Python, it gets one of its plusses for its better graphing and reporting capabilities. This topic is not an introductory topic and we will not be diving deep into it in this book. There are books dedicated specifically to this topic out there. What I want to do is to give you just enough so you can create your first report. Having said that, you will probably not need more than I will show you in this section. Our goal for the first part of this section is to generate two plots, one will be a bar plot about the age of our vehicles, and the other will be a line plot about the number of new vehicles by year. The library that we will be using is the extremely popular ‘ggplot2’ library. According to statmethods.net, “the ggplot2 package, created by Hadley Wickham, offers a powerful graphics language for creating elegant and complex plots. Its popularity in the R community has exploded in recent years. Origianlly based on Leland Wilkinson’s The Grammar of Graphics, ggplot2 allows you to create graphs that represent both univariate and multivariate numerical and categorical data in a straightforward manner.” All this mambo-jambo is nice to hear, but all you need to know is that it is the best in R. 0.16.1 The setup First thing we need to do is to install a few new packages. The first one is ‘ggplot2’ itself, the second one is ‘scales’, and the third is ‘ggthemes’. The ggplot2 is the library that we will be using to create all those nice plots. The ggthemes library will help use style our plots. The scales package will help us format the labels and other components on our plots. # Libraries. library(ggplot2) library(ggthemes) library(scales) Then we need to prepare our data to be plotted. ggplot2 is not super easy to master, but it is pretty good at how it guesses what you want it to do. Still, we will probably have to make small adjustments to our data here and there for different types of charts. Lets load the lates ‘vehiclesComplete’ file. # Reading data in. data &lt;- fread(&#39;vehiclesComplete_2020-01-10.csv&#39;) # Printing. print(head(data)) ## expirationDate vin year baseType date make ## 1: 03/14/2020 2LMHJ5AT3ABJ10630 2010 BLACK-CAR 2017-03-14 LINCOLN ## 2: 03/18/2020 5FNYF4H57FB070534 2015 BLACK-CAR 2017-03-18 HONDA ## 3: 03/18/2020 2G1WB58K479242872 2007 LIVERY 2017-03-18 CHEVROLET ## 4: 03/21/2020 2G61M5S31H9120231 2017 LUXURY 2017-03-21 CADILLAC ## 5: 03/13/2020 JTMRFREV5GJ102333 2016 LIVERY 2017-03-13 TOYOTA ## 6: 03/29/2020 4T1BF1FK2CU150061 2012 LIVERY 2017-03-29 TOYOTA ## model gas1 gas2 ## 1: MKT Gasoline ## 2: Pilot Gasoline ## 3: Impala ## 4: XTS Gasoline ## 5: RAV4 Gasoline ## 6: Camry Gasoline Right away, I can see that we will need to rename our gas1 and gas2 into the abbreviations that we used before. It will be easy. We will just copy and paste the code from before. We will do it later. The first plot that I want to build is the number of new vehicles by month. It will be a simple line plot. We will layer some fancy stuff on it once we got the basics. We will isolate the two columns that we will be using for our first plot. These columns are ‘vin’ and ‘date’. We probable do not even need ‘vin’ here, but the table will just look weird with just one column. Vin will give us a good visual reference for what each date means. # Selecting columns. dataForLine &lt;- data %&gt;% dplyr::select(vin, date) We are interested in seeing how many vehicles came in every month. But, the column ‘date’ contains dates that have years, months, and days. We do not need days. We are going to foor the date column using the library lubridate. After that, we will need to actually calculate how many. # Converting the date column from character to date format. dataForLine$date &lt;- lubridate::ymd(dataForLine$date) # Flooring to a month. dataForLine$date &lt;- lubridate::floor_date(dataForLine$date, &#39;month&#39;) #Printing. print(head(dataForLine)) ## vin date ## 1: 2LMHJ5AT3ABJ10630 2017-03-01 ## 2: 5FNYF4H57FB070534 2017-03-01 ## 3: 2G1WB58K479242872 2017-03-01 ## 4: 2G61M5S31H9120231 2017-03-01 ## 5: JTMRFREV5GJ102333 2017-03-01 ## 6: 4T1BF1FK2CU150061 2017-03-01 # Calculating dataForLine &lt;- dataForLine %&gt;% dplyr::group_by(date) %&gt;% dplyr::count() The data are now ready. Lets build our first plot. First, I would like to go over some sintax. The main function that creats the plot is ggplot(). ggplot() takes two inputs: the data table that we are feeding it and aes(), which is short for estetics, which nobody knows what the fuck that means. aes() will basically include the main parameters of your plot (x-axis, y-axis, color, and group) - do not worry, you will see. It all looks like this: ggplot(data, aes(x = blabla, y = blabla, color = &#39;blabla&#39;, group = &#39;blabla&#39;)) The color and group are optional but really are not, meaning that your plot will render without them but it will look like shit. That gives us the base for our plot. At this stage it is empty. To add a line you need to add ‘+’ at the end and add geom_line(). That will look like this: ggplot(data, aes(...)) + geom_line() That is it. Since we already specified the aes() inside of the ggplot(), the geom_line() will adopt those parameters and will draw the line accordingly. That will give us what we need in the basic form. It will look ok regardless, but we will add more bells and whistles to it. To do that you just need to keep adding ‘+’. The ‘+’ sign is just like a pipe (%&gt;%) operator for dplyr package. Lets do this: # Plot. ggplot(dataForLine, aes(date, n)) + geom_line() This is pretty good as it is. The better way of doing it is by storing the whole thing in a variable first and then calling that variable. That gives you more flexibility, for example, if you want to later do something to that plot. I will show you later what kind of things you can do to a plot stored in a variable. Lets store it first. # Storing the plot. ourLinePlot &lt;- ggplot(dataForLine, aes(date, n)) + geom_line() Now that our line plot is stored in the variable ‘ourLinePlot’, to show it, we need to just call the variable like this: # Rendering. ourLinePlot As you can see, storing and calling a plot from a variable produces the same result as just calling the ggplot() function straigh away. Lets see if we can layer a few things on top of our chart to make it look better. I want to add a title and change the color to red and make the line wider. Lets do it. ourLinePlot &lt;- ggplot(dataForLine, aes(date, n)) + # Adding size and color params to the line geom_line(size = 1.5, color = &#39;red&#39;) + # &#39;labs&#39; can add a title and rename the x and y labels labs(title=&quot;Incoming Cars (by month)&quot;) ourLinePlot This is nicer. Y aixis says ‘n’ and we only see three dates. That just looks weird. Lets change the x and y labels and make the x axis show us every month break instead of just three. Also, I want to change the date format to something like this: ‘2020-Jan’. ourLinePlot &lt;- ggplot(dataForLine, aes(date, n)) + geom_line(size = 1.5, color = &#39;red&#39;) + # &#39;labs&#39; can add a title and rename the x and y labels labs(title=&quot;Incoming Cars (by month)&quot;, x=&quot;Date (month)&quot;, y=&quot;New Cars&quot;) + # the scale+x_date() lets us work with the x axis more closely. # We can change the date format, and specify the breaks. We # can also specify the date borders. I will show you that later. scale_x_date(labels = date_format(&quot;%Y-%b&quot;), breaks = date_breaks(&quot;1 months&quot;)) ourLinePlot We are close. The first thing we need to fix is overlapping dates. We can tilt them 45 degrees and they should look better. The second thing I do not like is that ugly backgroud. We can apply one of the themes from the package ggthemes. ourLinePlot &lt;- ggplot(dataForLine, aes(date, n)) + geom_line(size = 1.5, color = &#39;red&#39;) + labs(title=&quot;Incoming Cars (by month)&quot;, x=&quot;Date (month)&quot;, y=&quot;New Cars&quot;) + scale_x_date(labels = date_format(&quot;%Y-%b&quot;), breaks = date_breaks(&quot;1 months&quot;)) + # The function theme() lets us move the text around. theme(axis.text.x = element_text(angle = 45)) + # The function below is the ggthemes function. You should check # out their themes. We are using the &#39;hc&#39; theme_hc() ourLinePlot This looks really nice. There are two last things that I want to change before we move on though. The date labels are a bit too high, and the first and the last data points are outliers that we should get rid of (just not good from the presentation standpoint). The first we can remedy by adding the hjust input into the theme() function. The second, by adding the limits into the scale_x_date() function. ourLinePlot &lt;- ggplot(dataForLine, aes(date, n)) + geom_line(size = 1.5, color = &#39;red&#39;) + labs(title=&quot;Incoming Cars (by month)&quot;, x=&quot;Date (month)&quot;, y=&quot;New Cars&quot;) + scale_x_date(labels = date_format(&quot;%Y-%b&quot;), breaks = date_breaks(&quot;1 months&quot;), limits = as.Date(c(&#39;2016-12-01&#39;,&#39;2017-12-01&#39;))) + # The hjust = 1 will move the tick labels down just enough. # You should definitely play with some of these params theme(axis.text.x = element_text(angle = 45, hjust = 1)) + theme_hc() ourLinePlot ## Warning: Removed 3 rows containing missing values (geom_path). We are done here. This looks very professional now. One thing to change here would be the scale of the y axis. See if you can change it to ‘2000 to 7000’ by yourself. That will be a good practice for you. If you look at the final code that we have, you will see that it was not hard at all. It might be a bit time consumng at the beginning, because you have to get just the right balance for your plot. You might be wondering why am I not going deep into each parameter of every function anymore. First of all, this topic and the next few are quite big and deserve books of their own. In fact, they do have books of their own. Secondly, by now you should be able to understand how functions and parameters of those functions work, at least on a basic level. At this point, I just want to show you how the things can and should look and how to achive that. You should be able to look deeper into them and tweak them on your own. You should be able to chew your own food from now on. I am still feeding you from a spoon though. For the rest of this section, I want to show you different ways we can plot our data. Lets see what our line plot would look like if we had a grouping variable there. Lets add the fuel type as a grouping varible. The data aggregation for that will be very similar to what we did for the basic line plot. The extra stuff that we need to do here is selecting the gas1 and gas2 and renaming them just like we did when we were creating our unique identifier. We will just copy it from there. # Selecting the columns. dataForFuelLine &lt;- data %&gt;% dplyr::select(vin, date, gas1, gas2) # Renaming empty spaces into nas. dataForFuelLine &lt;- dataForFuelLine[gas2 == &#39;&#39;, gas2:=NA] dataForFuelLine &lt;- dataForFuelLine[gas1 == &#39;&#39;, gas1:=NA] # Conditionally abbriviating the fuel types. dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Gasoline&#39; &amp; is.na(dataForFuelLine$gas2),Type:=&#39;g&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Gasoline&#39; &amp; dataForFuelLine$gas2 == &#39;Electric&#39;,Type:=&#39;h&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Gasoline&#39; &amp; dataForFuelLine$gas2 == &#39;Ethanol (E85)&#39;,Type:=&#39;h&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[is.na(dataForFuelLine$gas1) &amp; is.na(dataForFuelLine$gas2),Type:=&#39;Unknown&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Flexible Fuel Vehicle (FFV)&#39; &amp; dataForFuelLine$gas2 == &#39;Gasoline&#39;,Type:=&#39;h&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Flexible Fuel Vehicle (FFV)&#39; &amp; is.na(dataForFuelLine$gas2),Type:=&#39;h&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Electric&#39; &amp; dataForFuelLine$gas2 == &#39;Gasoline&#39;,Type:=&#39;h&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Diesel&#39; &amp; is.na(dataForFuelLine$gas2),Type:=&#39;d&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Gasoline&#39; &amp; dataForFuelLine$gas2 == &#39;Flexible Fuel Vehicle (FFV)&#39;,Type:=&#39;h&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Flexible Fuel Vehicle (FFV), Gasoline&#39; &amp; dataForFuelLine$gas2 == &#39;Ethanol (E85)&#39;,Type:=&#39;h&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Gasoline, Flexible Fuel Vehicle (FFV)&#39; &amp; dataForFuelLine$gas2 == &#39;Ethanol (E85)&#39;,Type:=&#39;h&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Electric&#39; &amp; is.na(dataForFuelLine$gas2),Type:=&#39;e&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Gasoline, Electric&#39; &amp; dataForFuelLine$gas2 == &#39;Electric, Gasoline&#39;,Type:=&#39;h&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Gasoline&#39; &amp; dataForFuelLine$gas2 == &#39;Compressed Natural Gas (CNG)&#39;,Type:=&#39;h&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Electric, Gasoline&#39; &amp; dataForFuelLine$gas2 == &#39;Gasoline, Electric&#39;,Type:=&#39;h&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Gasoline, Flexible Fuel Vehicle (FFV)&#39; &amp; dataForFuelLine$gas2 == &#39;Gasoline&#39;,Type:=&#39;h&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[is.na(dataForFuelLine$gas1) &amp; dataForFuelLine$gas2 == &#39;Gasoline&#39;,Type:=&#39;g&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Compressed Natural Gas (CNG)&#39; &amp; is.na(dataForFuelLine$gas2),Type:=&#39;cng&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Ethanol (E85)&#39; &amp; is.na(dataForFuelLine$gas2),Type:=&#39;ethnl&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Flexible Fuel Vehicle (FFV)&#39; &amp; dataForFuelLine$gas2 == &#39;Electric&#39;,Type:=&#39;h&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Flexible Fuel Vehicle (FFV), Gasoline&#39; &amp; dataForFuelLine$gas2 == &#39;Gasoline&#39;,Type:=&#39;h&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Electric, Gasoline&#39; &amp; is.na(dataForFuelLine$gas2),Type:=&#39;h&#39;] dataForFuelLine &lt;- setDT(dataForFuelLine)[dataForFuelLine$gas1 == &#39;Liquefied Petroleum Gas (propane or LPG)&#39; &amp; is.na(dataForFuelLine$gas2),Type:=&#39;lpg&#39;] We are interested in seeing how many vehicles came in every month, by fuel type this time. We will do here exactly what we did for the first line plot, plus add the ‘Type’ as another grouping variable. Converting the date column from character to date format. # Converting. dataForFuelLine$date &lt;- lubridate::ymd(dataForFuelLine$date) Flooring to a month. # Flooring. dataForFuelLine$date &lt;- lubridate::floor_date(dataForFuelLine$date, &#39;month&#39;) Calculating. # Grouping and counting. dataForFuelLine &lt;- dataForFuelLine %&gt;% dplyr::group_by(date, Type) %&gt;% dplyr::count() Lets see what it looks like. # Printing. print(head(dataForFuelLine)) ## # A tibble: 6 x 3 ## # Groups: date, Type [6] ## date Type n ## &lt;date&gt; &lt;chr&gt; &lt;int&gt; ## 1 2016-10-01 g 278 ## 2 2016-10-01 h 76 ## 3 2016-10-01 Unknown 24 ## 4 2016-11-01 d 5 ## 5 2016-11-01 g 1701 ## 6 2016-11-01 h 439 Perfect. We aggregated the data just the way we needed. Lets take the final plot code and see how it changes when we add fuel as the grouping variable. We need to add the ‘color’ input. It will serve as a grouping parameter. # Plot. ourLineFuelPlot &lt;- ggplot(dataForFuelLine, aes(date, n, color = Type)) + # We need to eliminate the color parameter from the geom_line(), # because we already specified it in the aes() above. geom_line(size = 1.5) + labs(title=&quot;Incoming Cars (by fuel type)&quot;, x=&quot;Date (month)&quot;, y=&quot;New Cars&quot;) + scale_x_date(labels = date_format(&quot;%Y-%b&quot;), breaks = date_breaks(&quot;1 months&quot;), limits = as.Date(c(&#39;2016-12-01&#39;,&#39;2017-12-01&#39;))) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + theme_hc() ourLineFuelPlot We almost did not to do anything here. We basically, just recylced the same code we wrote before. We just tweaked two small things. This is what it is all about, get the code that works well for you and recycle it with some tweaking. I do not only mean plotting, but the same concept works across programming as a whole. There is one thing I do not like about this plot though. The diesel (d) and electric (e) are on the bottom of the plot and there is no way to tell how many there actually are. There are a few ways to solve this problem. My favorite is to make this plot interactive. I will show you this way later. The second is to create multiple views where each view will represent a singel group. Lets do this now. Again, we are just recycling the same code with minor tweaking. # Plot. ourLineFuelPlotFacet &lt;- ggplot(dataForFuelLine, aes(date, n, color = Type)) + geom_line(size = 1.5) + # The function facet_wrap() will split our plot into multiple plots # by the specified parameter, which is our grouping parameter in this # case. facet_wrap(~Type) + labs(title=&quot;Incoming Cars (by fuel type)&quot;, x=&quot;Date (month)&quot;, y=&quot;New Cars&quot;) + # I suspect that &#39;1 months&#39; break will be too dense for small charts we # are creating. Lets change it to &#39;2 months&#39; scale_x_date(labels = date_format(&quot;%Y-%b&quot;), breaks = date_breaks(&quot;2 months&quot;), limits = as.Date(c(&#39;2016-12-01&#39;,&#39;2017-12-01&#39;))) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + theme_hc() ourLineFuelPlotFacet This did not really solve our problem. The scales are still the same, and, therefore, d and e are still on the bottom. There are ways to fix it in ggplot() but, I think, I know a better way. Soon, we will be making these charts interactive and that will solve our issue. At least, you now know how to create a multiview with the facet_wrap() function. Before we do interactive charts, I want to show you my favorite type of plot, the bar plot. There will be not much different to what we have been doing so far. I like bar plots better, because I feel that they are just more informative. It is just a matter of preference. Lets create a bar plot where we will demonstrate average ages of incoming vehicles by month. Similarly to the line plots, we first need to prepare the data. First, we need to isolate the columns that we need. # Selecting. dataForBarPlot &lt;- data %&gt;% dplyr::select(vin, date, year) Lets calculte age of our vehicles. We are just deducting the year of a vehicle from the current year. Change ‘2020’ to your year if it is different. # Calculating ages. dataForBarPlot$year &lt;- 2020 - dataForBarPlot$year # Printing. print(head(dataForBarPlot$year)) ## [1] 10 5 13 3 4 8 Nice. We got the ages. Lets again floor our date column to a month. # Flooring. dataForBarPlot$date &lt;- lubridate::floor_date(ymd(dataForBarPlot$date), &#39;months&#39;) Now, we can find the average age of our vehicles by month. # Grouping and summarising. dataForBarPlot &lt;- dataForBarPlot %&gt;% dplyr::group_by(date) %&gt;% dplyr::summarise(age = mean(year)) Lets round the age to one decimal as well. # Rounding. dataForBarPlot$age &lt;- round(dataForBarPlot$age, 1) # Printing. print(head(dataForBarPlot)) ## # A tibble: 6 x 2 ## date age ## &lt;date&gt; &lt;dbl&gt; ## 1 2016-10-01 5.3 ## 2 2016-11-01 5.1 ## 3 2016-12-01 4.7 ## 4 2017-01-01 3.8 ## 5 2017-02-01 4.5 ## 6 2017-03-01 4.9 Beautiful. Now that our data are ready, we can just reuse our line plot code and tweak it a little bit to make it a bar plot. Lets do this. Very similar to the line plot. # Bar plot. ourBarPlot &lt;- ggplot(dataForBarPlot, aes(date, age)) + geom_bar(stat = &quot;identity&quot;) + labs(title=&quot;Incoming Cars (by age)&quot;, x=&quot;Date (month)&quot;, y=&quot;Age&quot;) + scale_x_date(labels = date_format(&quot;%Y-%b&quot;), breaks = date_breaks(&quot;1 months&quot;)) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + theme_hc() ourBarPlot Great! This concludes our introduction to the basics of ggplot2(). When you done and comfortable with your plots, it is time to export them. The simpliest way to do this is to go to the plots tab in the lower left corner of Rstudio, selext Export and save it as an image, for example (see Image export demo pic below). The next step is to open a Word Document, write a narrative and paste the images in there. I hope I do not need to show you how to do that. If I do, you are really in the wrong place. Image export demo. 0.16.2 R Markdown Although, Word is not a bad solution for reporting our findings, R has a much more convenient tool that takes a regular Word report and injects it with steroids. Again, I am not going to go deep on this topic, because it is too big. I will show you the basics to get you started. The first thing you need to do is to install r markdown. Run: install.packages(&quot;rmarkdown&quot;). Sage Tip: You do not need to write ‘library(rmarkdown)’ in this case, Rstudio knows. Before we start, install another package - ‘stringi’. This package provides some tools for working with text, but we will need it to generate random text for our markdown report. install.packages(&quot;stringi&quot;). Before we proceed, lets save the final tables that we used to generate our plots. We could copy and paste the code that we used to get to these tables, but why do that if we already got what we need. # Saving. fwrite(dataForLine, &#39;dataForLine.csv&#39;) fwrite(dataForFuelLine, &#39;dataForFuelLine.csv&#39;) fwrite(dataForBarPlot, &#39;dataForBarPlot.csv&#39;) First, create a folder inside of the folder with the current project. Name it ‘markdown’ or something. Now, open a completely new Rstudio session. Your screen should look like the illustration below. Click on ‘File’ -&gt; ‘New File’ -&gt; ‘R Markdown…’. RMarkdown. You will see a new markdown file window like below. A markdown project can result in different final formats, but we are only exporing HTML now. Name your markdown something and specify the author. Click ‘OK’. RMarkdown. Another great thing about Rsudio is that it provides templates for many different things. When we will be discussing APIs, Web Apps, and other things, you will see how useful it is to have a code tepmlate to get you started. Markdown is not different. Below, Rstudio gives you a working template of how a markdown document should look like. Lets go through the template to see what it consists of. There are five parts that I can identify: The first is a ‘hat’. This is where the information and parameters of the markdown go. It is surrounded by the tripple dashes. The second is the general space where you can specify titles, write text, and in-line code. The third is a ‘chunk’. Chunks are bulding block of a markdown document. Any code that we wrote and ran so far in this book, we can run inside a chunk. To created a chunk, you need to write two sets of tripple ticks. The space between them will be your chunk. The fourth element comes after the first set of tripple ticks and is surrounded by curly braces. This is where you specify chunks parameters. There are many different parameters that you can specify there. You will see all that for yourself when you will start experimenting with markdowns, however, I will just give you a few most freqient parameters and what they do. When you press ‘knit’, the code that you write in those chunks gets executed line by line just like in regular R file. In most cases, you will not want the reader of your report to see the code behind your findings. The parameter ‘echo = False’ takes care of that. Also, as you might have noticed, any code can produce a bunch of warnings or messages. There are parameters for that too. There are parameters for width and height of your charts or illustrations, and a bunch of other crap as well. If I start to list all of them here, you will not remember. It is better if you just google them on case by case base when you need them. The fifth part is the actual code that you include in a chunk. As I mentioned before, the code in the chunks runs just the same as the one that you have been practicing with so far. The difference here is that it is sectioned by chunks and you can apply different rules (parameters) to each chunk. These are the main five parts of a markdown. There are, obviously, more sub-parts, but you do not need to worry about them right now. RMarkdown. Although, it is just a template, since we have already specified the title and author, we can see them in the ‘hat’ of the markdown. The hat of the markdown is where you specify different parameters for the final document. The parameters can be font, spacing, color, themes, and more. Although, it is just four lines now, it can get much much bigger. Everything else is generic now. Click the ‘Knit’ button above the ‘hat’ to see what the final document will look like. RMarkdown. Pretty cool, right? R and Rstudio makes it extremely easy to go from doing research and writing code to presenting it in a widely accessible format. If you have not noticed yet, the document that you just produced is an html. This means that any browser can open your report. It might not seem like a big thing, but presenting your stuff from outside of your own computer can be a really big fucking problem. Many tools that are popular now are very close-ended and will not let you do shit from ouside, unless you give them your kidney. Anyway, your template report should look like mine. Go through it, compare side by side with the template’s code, see what corresponds to what. RMarkdown. Lets use our plots to create a markdown report. First, eliminate everyhing except the ‘hat’. The first chunk will only hold the libraries that we will be using for the code to generate the report. Just copy the ones that we used so far. Use the illustration below for reference. If not sure, just copy and paste all the libraries that we have been using so far. One thing about markdowns is that it will not render if something is missing or broken, and it will not tell you why in most cases. So, even if one library is missing, it will not work. It is actually better to include more libraries than you need than less because of that. Then, create a chunk with two sets of tripple ticks. Inside of the curly braces you want to specify three things: Engine (r) - mandatory, Chunk name (libraries) - optional and must be different for each chunk, Include = False - optional. Sage Tip: The ‘include = false’ parameter will run the code but will not print or display it in any way, so our libraries will be loaded but we will not see all those garbage messages that come with them. Press ‘knit’ and you will see an empty report with the hat information. RMarkdown. Ok, lets start simulating a real report. You can write any text outside of your chunks. On top of that, you can specifiy headers and write in-line code there. There are three types of header in markdown. The main header has to prefixed with the single ‘hash’ (#) sign. The middle one has two hashes. The smallest has three. In order to write in-line code, you have to surround it with a set of single ticks. Inside goes the engine (r) and the code. Check out the illustration below to see the examples of both. The function stri_rand_lipsum() generates a paragraph of random text for us. Knit it to see what it looks like. RMarkdown. At this point, we have covered the core of the shit that we need to know about markdowns. From now on, we will be just copying an pasting our plots code and filling the voids with some generic text. Lets create a new paragraph with a middle-size header called ‘Line Plot’ and random text. After that, create a chunk with the following parameters: {r, echo = False, error = False, message = False, message = False, fig.aling = ’center}. Lets go over the parameters. The first one is the engine, in other words, the language that we are using, which is ‘r’. The next one is ‘echo = False’. Echo works just like the ‘include’ that we used in the first chunk. The difference is that ‘echo’ will render the result of the code but not the code itself, and ‘include’ will not display anything if set to ‘false’. The next three parameters are ‘error’, ‘message’, and ‘warning’. These three are very similar as they block the display of errors, messages, and warnings. We do not need any, so we are setting them to ‘false’. The final parameter is ‘fig.align’. We want our plots at the center of the screen, so we are setting it to ‘center’. Again, you can include more parameters here, but we do not need to now. Now, we are ready to render our first plot. As you should remember, we saved the result of our aggregations for the line plot as ‘dataForLine.csv’. Lets read it back to this chunk. Type: dataForLine &lt;- fread(&#39;dataForLine.csv&#39;) We need to convert the date to the date format as it flipped to the character type in transitions. I hope, you remember how to do that. If not, go back. If can not, reference the illustration below. Finally, just copy and paste the code we used to generate and output the line plot (see the illustration below for reference). RMarkdown. Knit the file and your report should look like the illustration below: RMarkdown. So far, we got the hat, introduction, and the first plot. The rest of the report will be the same. After the second chunk create another mid-size header ‘Line Plot (by fuel)’. Add another random text paragraph under it and create another chunk with the same parameters as in the previous one. Load the ‘dataForFuelLine.csv’ to this chunk, fix the date column, and copy and paste the second plot code in here. Reference the illustration below if stuck. RMarkdown. Repeat the same steps for the bar plot this time. You can name things as you see fit. Refer to the illustration below if confused. After the final chunk, create another mid-size header ‘Conclusion’ and add another paragraph with generic text to complete the report. RMarkdown. Finally, I want to show you how to add a table of contents (toc) to our report. The toc will be linked to the headers that we created. A markdown’s ‘hat’ is very particular about formatting. If you want things to work as intended, you must make sure that punctuation and indentations are correct. To add the toc, change the hat exactly like I have it in the illustration below. RMarkdown. Knit the report and the toc will look like the illustration below. You can now click on any entry and you will be navigated to it. Give it a go. RMarkdown. We are done with our report. You final document should look like this. Pretty fucking awesome. RMarkdown. Now you have some basic understanding of Rmarkdown. You know how to generate it and how to properly structure your reports. On top of that, this section leaves you with not a bad template for some basic reporting. Obviously, there are many more things that you can do with a markdown, but we are not covering that in the introduction to everything in R. However, what you know now should be a good foundation to start exploring other capabilities of Rmarkdown. Personally, I never had the need to do with markdown more than I just showed you. So, whatever we have covered will be already enough for the most of you. Having said that, Rmarkdown is important to at least be familiar with. 0.17 Bonus Remember I said that I will show you how to make your plots more informative. Now is the time. The trick that I am about to show you was a gateway for me into the topic of interactive visualization. It would be cool if we could just take the ggplot that we created and start interacting with it. We would not need to dance around looking for adhoc solutions to improve the informativeness. Meet the package ‘plotly’. Plotly is a JavaScript library that is heavily adopted and used in R to create interactive visualizations. First thing you need to do is to install the package. Type: install.packages(&#39;plotly&#39;) Once it is done installing, I want you to change the first chunk of your markdown according to the following illustration: RMarkdown. There are two additions: knitr::opts_chunk$set() specifies the global parameters for all chunks. In this case, the plot dimensions. library(plotly) - I should not explain this one. Now, to the trick itself. Plotly is just like ggplot2. We can use plotly to create any interactive chart from scratch just like we did in ggplot2. That is the whole topic and we will not be doing that. The reason I am refering to this part as a ‘trick’ is because we can just take out plots that we created in ggplot2 and wrap them with the plotly function ggplotly(). That function will take all the parameters, bells, and whissles, and will generate a plotly plot with them. Lets do it. Take every chunk that generates a plot and wrap the final variable with the ggplotly() function like so: ggplotly(ourLinePlot). Do it for all three of them. RMarkdown. Knit the report again and you should end up with the report that is very interactive. You can zoom in, take a snapshot, hover to see the numbers, select and deselect data, etc. It is really fucking awesome for basically no effort. Most importanly, it makes your report stand out. 0.18 You are not an R maggot anymore Congradulations, you are not an R maggot anymore. This is the end of your big assignment. You went far beyond what was expected of you. You will present this report to your supperiours and they will be very impressed with your progress while you are in front of them. They will definitely forget about you the next minute, but that is not the most important part. The most important is that you have proven to them and to yourself that you can take something really complex and completely new to you and master it in a short period of time with minimum or no supervision. Let me remind you what you were tasked to do. You were given the code that your superviser has been working on for months. That code already worked and you just needed to tweak it a bit more. I got to tell you that the majority of people would just run the code, encounter an issue or two, and run for help as soon as things got tough. Forget about improving the code and building things on top of it. Best case scenario, they would just run it from time to time and periodically lean on you to do their job. You will encounter that kind of attitude a lot and it is important that you yourself do not fall into the trap of relying on others for something that you must do. That is particularly important in programming. Nobody is going to do the learning for you. If there is one thing that I wanted you to take from this book, that would be the steps and attitude we took to solve our big assignment. Applying the strategy that I showed you for the next year, combined with hunger, will make you an expert in R and will take you to the level where you will be able to teach others, just like I am teaching you now. With this settled, lets see what we have actually done in this section and what it means for us. First, we were given a very complex, for us back then and for most now, code and got tasked with understanding it and running it periodically. We were given two to three months for that. We had no idea what the code was doing and what any of it meant. We ran it line by line to see what each piece of it did. We learned how to connect to a database, pull data that we need from it, aggregate that data using various R function, and save the result. In the programming world, this is called ‘ETL’ (Extract, Transform, Load). Although, we went over the code many many times and understood the outcomes of each line, some parts of it were still very hard or impossible to understand without deeper understanding of R. Here, I mean the NHTSA API call. Along the way, we learned about a thing called ‘Tutorial Purgatory’ and how to avoid getting sucked into it. We dove deeper into working with dates and times and learned the one library that we will be sticking with for a while (lubridate) Second, we decided to see if we could rewrite the same code in a more staighforward way. The biggest improvement that we were able to make was to the API call. I, still, do not expect you to fully understand that thing, but at least it became much easier to, compared to the monstrosity that it was before. After we rewrote the code, we should have gotten a better grasp of it. At that point we were doing things that we will be doing ninty percent of a time from now on, give or take a few things. We presented our progress and were ready to start building on top of it. We impressed our supervisor and were given our addon assignment. Third, we got tasked with adding ‘Miles per Gallon’ (mpg) information for each vehicle from now on. There was no clear procedure for that. We had to be creative and more importantly knowledgeable in R to get something like that done. The fact that we got an assignment like that showed that we demonstrated our capacity to independently do something like that. The problem with that task was the lack of unique identifier that we could use to join the fuel dataset with our vehicles dataset. That particular problem taught us how to write ugly but working code. We are no longer intimidated by the majority of tasks, because we know that they will probably not be much harder than this one. And if they are, we will be able to dissect, understand, and complete them. The most important thing that we took from that part was confidence. Finally, we dicided that it would be proper to present our efforts in a nicely formatted report. We learned a lot about ggplot2 library and generated a few plots. From experience, in ninety percent cases, you will not need more ggplot2 than we have covered here. After covering plots, we leaped forward and covered a lot of ground on Rmarkdown. That will be extremely useful for you if your job requires a bunch of reports. Markdown is the standard for that kind of stuff and, again, we covered just enough so you can tackle the most of the tasks thrown at you. Obviously, you might requre different parameters for your chunks, but you got the template and knowledge that you can work with already. Finally, as a bonus, we converted our static ggplot2 plots into dynamic plotly plots, which made our report more impressive and informative. More importantly, it took our skills to the next level and opened the doors to the topic of dynamic visializations. The big assignment is over, the topics that will follow are important but are not core. Pat yourself on the back, you are not useless anymore! R, Not the Best Practices by Nikita Voevodin is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. "],
["maps.html", "Maps 0.19 Maps, Different Libraries 0.20 Leaflet, Deeper Dive 0.21 Leaflet with Real Data", " Maps At the end of the last chapter, we opened the doors to the topic of dynamic visialization with converting our static ggplot2 plots to dynamic plotly plots. We will continue moving in that direction from now on. One thing that fucking facinated me at the beginning was mapping. I did not understand how it was done and it seemed extremely complicated. I honestly thought that you had to write code to display every single element of a map. Well, you do need to write code to display things, but it is way easier than I thought. I would walk around the office drooling over the people who could do mapping thinking that it was out of reach for me at the moment. Until I reached that topic and saw that it is not as complicated as the stuff that we have covered so far. Maps are extremely important though. If you decide to continue with the rest of the series, you will see that we will be building a huge chunk of our progress around mapping. Obviously, there are things in maps that are very complex. For those things, you will have to get a dedicated book or a course. But, as usual, whatever we will cover here will be more than enough for your day to day work and will definitelly take you to the next level. 0.19 Maps, Different Libraries There are a few libraries that can draw you a map. I will mention three of them and will show you how to use only one. Only one, but the best one and the only one that you will need. I will explain why here. Just like with plots, maps can be static (just a picture) and dynamic (interactive). They can even be 3D, but we do not need that. You have already seen the limitations of the static plots. My question is then: why the fuck do we even need static maps? Someone who knew what they were talking about could say: they are easier to save and overall lighter than dynamic maps. The first one is bullshit, because if you want a png of a dynamic map, you can just focus on the area of interest and take a snapshot. That inconvenience is nothing for the flexibility that a dynamic map can provide. The argument about the size difference is valid. If you have a heavy (cpu or ram demanding) web application or script, then downgrading to a static map is one of the options for optimizing performance. However, as I mentioned before, first we will learn to get things done no matter what. If you at the point where you need to start optimizing things, then congradulations, you do not need my books anymore. Trust me, at that point, you will be able to use both static and dynamic maps. Here, I will show you the most useful and exciting way to work with maps. If you get interested in the topic, please, go ahead and start looking deeper into it elsewhere. 0.19.1 ggplot2 The library ggplot2 can also draw static maps. For the reasons outlined above, I will not go deep into generating maps using ggplot2. However, I do want to show you an example of how easy it is to create a map and what a static map looks like. Lets draw an empty map of the US. Before we begin, open a new R file and type: install.packages(&#39;maps&#39;) We will not need to load it though. First, we need to get the data that ggplot2 will use to draw the map. The ggplot2 library comes with the function map_data(). This function turns on outline of a shapefile into a dataframe where latitudes and longitudes of each point become columns. We can then use that dataframe to plot those points using standard ggplot2 sintax from before. Getting the data to create a map of USA. Open it to see what the columns that I just talked about look like. # Getting the map. usa &lt;- map_data(&quot;usa&quot;) Standard ggplot2() sintax: # Map. ourMap &lt;- ggplot(data = usa, aes(x=long, y = lat, group = group)) + geom_polygon() # Calling the map ourMap Just like with the line and bar plots that we generated in the previous chapter, we are using the ggplot() function, the ‘+’ sign and, then, specifying the ‘geom_…’ command. The difference here is that we used the geom_polygon() to draw a map instead of the geom_line() or geom_bar() to draw plots. As you can see it is not too complicated. In total, we wrote five lines of code and got a map. There is not doubt, if you master the ggplot2 you can draw some amazing plots and maps with it. Mastering ggplot2 is not our goal here, which is why we are going to move on. 0.19.2 ggmap The ggmap library is very similar to the ggplot2. The syntax is very similar and the whole process of gradually layering things on top of each other is the same. The output is static as well. The difference is that ggmap allows you to work with basemaps (background). A basemap is like an atlas. When we generated the shape of the United States, there was nothing behind the shape, just a blank canvas. If we did the same using ggmap, we would see the water, states, and many other things depending on the basemap we selected. It is better if I demonstrate. Before we proceed, type: install.packages(&#39;ggmap&#39;) Than, load the library. It is pretty much the same as with the ggplot(), even easier. Instead of five lines, we will do it in four. # Getting the basemap ourBasemap &lt;- get_stamenmap() # storing the map inside of a variable ourGgmap &lt;- ggmap(ourBasemap) # rendering the map ourGgmap Figure 1: Here is a nice figure! Nice. Not really though. It is the same shitty static map. It can be useful here and there, but for the reasons that I talked about in the beginning of this section, we will not be using ggmap either. Nevertheless, now you are familiar with both main libraries for generating static maps. I, actually, wanted to skip ggmap library demonstration altogether, because Google now requres us to create an account with them in order to use their basemaps. That is a big annoyance, especially when you are just learning and do not really know how to use ‘api keys’ and other shit that they want you to do. When you are learning, you just want shit to work. Adding that extra layer of complexity is just not worth it, considering that, in my opinion, ggmap is not even that great. Lets move on to what we came here for. 0.19.3 Leaflet Taken from the leaflet’s docummentation page on GitHub: “Leaflet is one of the most popular open-source JavaScript libraries for interactive maps. It’s used by websites ranging from The New York Times and The Washington Post to GitHub and Flickr, as well as GIS specialists like OpenStreetMap, Mapbox, and CartoDB.” Leaflet is extremely popular. It is a JavaScript library, but it is adopted by R so well that it is actually much easier to use it in R than in JavaScript. I did both. I do not want you to think that I am bullshitting you right now, so let me shock you with how awesome and simple it is righ away. Type: install.packages(&#39;leaflet&#39;) After it is installed, lets load the library and render our first leaflet. # Loading the library. library(leaflet) Just one line this time. # rendering the map leaflet() %&gt;% addTiles() Figure 2: Here is a nice figure! How cool is this? With just two lines of code you got a fully dynamic map that you can interact with. Go ahead and be amazed of how much better it is compared to that static crap, and how much easier it was to render it. The first time I saw it, I knew that, unless there is a major compromise associated with using it, I will not be going back to static maps. Now that you stoped drooling over that map, lets talk about leaflet a bit more. After that, I will show you a lot of cool stuff that you can do with it. As always, not too much, but just enough to get you started. 0.20 Leaflet, Deeper Dive I know that I praised leaflet a lot already, but I am not done yet. Leaflet, along with plotly and shiny (which we will cover later) gave me a huge boost in terms of my drive to learn R and code in general. Going through dry tutorials and hundreds and hundreds of dry lines of code gets very boring at some point. Some people do enjoy coding just for the coding part, others enjoy crunching numbers and solving problems, however, the majority of us want to be entertained from time to time. Crunching numbers and solving problems can be entertaining too, but when you are just starting, in most cases, you need that tangible progress. Not many things in programming are more tangible than making things move on the screen. That is why giving yourself a boost by learning how to inject interactivity in your code will get your further than just sitting and learning dry code. It definitely worked for me. Before we move to our routine of pulling data from a database, messing with it, and outputting it on a fancy map, I want to go through some leaflet basics. Basically, I want to show you how to place a dot on a map and play with a few parameters. You do not actually have to follow my tutorial on this if you hate me already. Leaflet has an amazing and simple tutorial on their GitHub page, just google ‘leaflet R’. But if you still tolerate me, keep reading. Lets see what each part does and what kind of things we can layer on top. First, we will call the leaflet() function without anything else to see if it does anything. leaflet() Figure 3: Here is a nice figure! Apparently, it provides an empty canvas with some basic functionality. The difference between this and the one before is the addTiles() function. So, the addTiles() function must be the one that actually paints the map on top of the canvas. Since we already know that, lets add a few things. # Base layer leaflet() %&gt;% # Base map addTiles() %&gt;% # Centering view on the following coordinates and zooming in. setView(lng = -71.0589, lat = 42.3601, zoom = 12) Figure 4: Here is a nice figure! We are now centered and zoomed in on Boston. If you are not familiar with coordinates, every point on earth has it set of coordinates that consist of latitude and longitude. The place where you are sitting right now has its on pair as well. The more decimals, more precise the location is. Test it, find your set of coordinates on google maps and insert them instead of the ones that I gave you, increase the zoom to see your location. If we leave the addTiles() function empty, it will just give us the default OpenStreetMap. If you want something else (and you do), you should use the function addProviderTiles() to get the third-party maps. There are a lot of them, you can see most of them here: http://leaflet-extras.github.io/leaflet-providers/preview/index.html. Lets change the basemap to something different. I really like neutral grey colors. # Base layer leaflet() %&gt;% # Base map addProviderTiles(providers$CartoDB.Positron) %&gt;% # Centering view on the following coordinates and zooming in. setView(lng = -71.0589, lat = 42.3601, zoom = 12) Figure 5: Here is a nice figure! Go through those maps, experiment with them, find your favorite. One thing you might be confused about from the previous chunk of code is ‘providers$CartoDB.Positron’. The ‘providers’ is the leaflet provided dataframe with the avaliable maps. The ‘CartoDB.Positron’ is one of the maps in that dataframe. Lets double check. # Storing the providers inside of the maps variable maps &lt;- providers # Printing the first five print(head(maps,5)) ## $OpenStreetMap ## [1] &quot;OpenStreetMap&quot; ## ## $OpenStreetMap.Mapnik ## [1] &quot;OpenStreetMap.Mapnik&quot; ## ## $OpenStreetMap.BlackAndWhite ## [1] &quot;OpenStreetMap.BlackAndWhite&quot; ## ## $OpenStreetMap.DE ## [1] &quot;OpenStreetMap.DE&quot; ## ## $OpenStreetMap.CH ## [1] &quot;OpenStreetMap.CH&quot; Now that we got that down, lets add the last two things to our map. The only thing missing right now is some sort of marker. Lets add it. # Base layer leaflet() %&gt;% # Base map addProviderTiles(providers$CartoDB.Positron) %&gt;% # Centering view on the following coordinates and zooming in. setView(lng = -71.0589, lat = 42.3601, zoom = 12) %&gt;% # Adding a marker and a popup. addMarkers(lng = -71.0589, lat = 42.3601, popup = &#39;Sup?&#39;) Figure 6: Here is a nice figure! Just like that we added a marker and a popup. If you did not see the popup, just click on the marker. Obviously, this is far from it for the leaflet, but I think you get the idea. You just layer more and more things and add more bells and whissles. In the next part, we will use real data to create some real shit that will be good enough to even publish online. 0.21 Leaflet with Real Data In this section, we will, again, pull data from a database, work with it a little bit, and map it in different ways using leaflet maps. This will be a nice and entertaining project for you. We will still repeat the same workfrom of pulling, munging, and outputting, but at the very minimum compared to the previous chapters. The exciting part will be mapping the data and making everything look pretty. I can almost guarantee that you will love it. We got an extremely interesting dataset of car crashes provided be the New York City police (NYPD). That dataset has every car crash registered by NYPD since 2012. There are three particular things that we are interested in. They are the number of crashes, the number of injuries, and the number of deaths. First, we will retreive the data from the database, then work with it a bit to get it to the right shape, and then, using the leaflet flow that we learned, we will map the crashes. Taking it a step further, I will teach you how to map data using polygons from a shapefile. That should solidify your knowledge and interest in the topic. You can follow this however you want, but I think it is a good time to create a new project and keep everything there. I will show you how to do it, but I am not insisting because I myself did not start using projects until after my first nine months learning R. Now that I do use them, I know that it is the way to go. Let me refresh your memory on projets in R and how they differ form just opening an R file. To put it simply, a project will create a folder for you where you will be storing everything related to that project. These things will include the project file itself, an R file, any csv, excel, shape, plot, map, etc files that you are using in that project. The major benefit of it is that you do not need to look for all these files all over your computer and you do not need to specify their paths when loading them in, your project will know that they are in the same folder. Additionally, if you ever decide to move your project to another computer, you will just need to drag that project folder over and that is it. Sage Tip: Use projects, they are very convenient. Here is how to do it: Go to ‘File’ -&gt; ‘New Project…’ -&gt; ‘New Directory’ -&gt; ‘New Project’ -&gt; Give it a name and leave the checkboxes empty. Click ‘Create Project’. You should have an empty Rstudio now. Click ‘File’ -&gt; ‘New File’ -&gt; ‘R Script’. There you go, everything will be contained in that folder now. For the rest of the book, we will be working out of this project folder. It is not really mandatory, as long as you can reference all the files that we will be using. Before we proceed, I want you to install four packages that deal with shapefiles and geolocation. We will not need them all, but you should have them installed just in case. So, install.packages(c(&#39;raster&#39;, &#39;sf&#39;, &#39;rgdal&#39;, &#39;rgeos&#39;)) That was a new sintax for you, but this is how you install multiple packages without repeating install.packages() four times. You just feed a vector of package names to the function, that is it. # Connecting to the database connection = dbConnect(drv = MySQL(), user = &quot;xxx&quot;, password = &#39;xxx&#39;, host = &#39;mybookdatabase.cgac79lt7rx0.us-east-2.rds.amazonaws.com&#39;, port = 3306, dbname = &#39;nikita99&#39;) Lets pull just one month of data and see what it looks like if we map it. Lets select a day of data from the ‘pdData’ table: # Pulling. crashes &lt;- dbGetQuery(connection, &quot;SELECT * FROM book_pdData WHERE date = &#39;2019-10-01&#39; &quot;) # Printing the first few records print(head(crashes)) ## row_names date zip lat lon injured killed ## 1 86987 2019-10-01 NA NA NA 2 0 ## 2 87151 2019-10-01 NA NA NA 0 0 ## 3 114890 2019-10-01 10451 NA NA 1 0 ## 4 114937 2019-10-01 NA 40.62616 -74.15742 0 0 ## 5 114940 2019-10-01 11214 40.60693 -73.99941 0 0 ## 6 114947 2019-10-01 10462 40.85241 -73.86777 0 0 ## reason ## 1 Following Too Closely ## 2 Unspecified ## 3 Unspecified ## 4 Driver Inattention/Distraction ## 5 Failure to Yield Right-of-Way ## 6 Traffic Control Disregarded There are quite a few crashes that happened that day. Upon inspection of the first few records, we can see that there are missing coordinates. We can not map data with missing coordinates, therefore, we are not interested in the entries with missing either lat or lon or both. Lets get rid of them and map the rest. As a reminder, the sign ‘|’ means ‘or’ and the sign ‘&amp;’ means ‘and’ in R and in most programming languages. In terms of the map, only a couple of things will be different compared to our practice map. First, we will center the view on NYC instead of Boston and zoom out a litte. Second, the coordinates in the addMarkers() function will not be the actual two coordinates but a column of coordinates for both ‘lng’ and ‘lat’. Finally, the popup will represent a crash reason for each location. # Keeping the records where lat or long are not missing crashes &lt;- crashes[complete.cases(crashes$lat) | complete.cases(crashes$lon),] # Base layer leaflet() %&gt;% # Base map addProviderTiles(providers$CartoDB.Positron) %&gt;% # Centering view on NYC this time and zoom out a bit setView(lng = -74.0060, lat = 40.7128, zoom = 10) %&gt;% # Passing the column lon and lat as lng and lat inputs for # the function. Using the column reason for popups. addMarkers(lng = crashes$lon, lat = crashes$lat, popup = crashes$reason) Figure 7: Here is a nice figure! This is crap, really. You can still use it and some idiots would, but this is not a proper way of mapping things. It is way too crowded and confusing. We only mapped one day, imagine what it would look like if we mapped one month or one year. Not only would it be crowded but also heavy in terms of processign power. Each element on the map takes a little bit of processing power. If you have thousands and thousands of dynamic elements, you computer might just freeze. Sage Tip: Lets see what we can do without changing the whole thing completely. The function addMarkers() has an amazing option called ‘clusterOptions = markerClusterOptions()’. This thing will group all markers that are close to each other and instead of displaying them from the beginning, will do that only when you are zoomed in enough to see them properly. Until then, it will just display how many markers are in each cluster. Win-win! leaflet() %&gt;% addProviderTiles(providers$CartoDB.Positron) %&gt;% setView(lng = -74.0060, lat = 40.7128, zoom = 10) %&gt;% # Adding clusterOptions = markerClusterOptions() addMarkers(lng = crashes$lon, lat = crashes$lat, popup = crashes$reason, clusterOptions = markerClusterOptions()) Figure 8: Here is a nice figure! This is amazing, right? With one parameter, we took an overcrowded fucked up map and made a proper one, while adding some cool animation as well. If somebody showed it to me before I knew how it is done, I would pee my pants thinking how cool that is. Anyway, lets see if we can get away with scaling our data to a month and a year using the same trick. We are going to select a whole year this time so we will not have to do it again: # Pulling. crashesYear &lt;- dbGetQuery(connection, &quot;SELECT * FROM book_pdData WHERE date &gt;= &#39;2019-01-01&#39; and date &lt; &#39;2020-01-01&#39; &quot;) # Keeping the records where lat or long are not missing crashesYear &lt;- crashesYear[complete.cases(crashesYear$lat) | complete.cases(crashesYear$lon),] # Keeping only October crashesMonth &lt;- crashesYear[crashesYear$date &gt;= &#39;2019-10-01&#39; &amp; crashesYear$date &lt; &#39;2019-11-01&#39;,] Now that we got the data again, lets map it and see what it looks like. leaflet() %&gt;% addProviderTiles(providers$CartoDB.Positron) %&gt;% setView(lng = -74.0060, lat = 40.7128, zoom = 10) %&gt;% # Adding clusterOptions = markerClusterOptions() addMarkers(lng = crashesMonth$lon, lat = crashesMonth$lat, popup = crashesMonth$reason,clusterOptions = markerClusterOptions()) Figure 9: Here is a nice figure! This is even better. Lets scale up to a year. leaflet() %&gt;% addProviderTiles(providers$CartoDB.Positron) %&gt;% setView(lng = -74.0060, lat = 40.7128, zoom = 10) %&gt;% # Adding clusterOptions = markerClusterOptions() addMarkers(lng = crashesYear$lon, lat = crashesYear$lat, popup = crashesYear$reason, clusterOptions = markerClusterOptions()) Figure 10: Here is a nice figure! This one is ok and still usable, but you can notice already that it gets confusing even with the clustering trick that we did. There is a way to filter by, lets say, year in the leaflet, but I will show you how to do that later. What we covered so far is already pretty good. Howerver, I want to take it one step further and show you how to use polygons in leaflet. For this, we will first need to get the polygons and then add some data to them to make it all work. If you do not know what polygons are, here are the examples: https://rstudio.github.io/leaflet/choropleths.html. Polygons are areas. What are some example of areas? The states can be areas and therefore polygons, countries, zipcodes, neighborhoods, etc can be areas as well. What is available to us? It will not be useful to map polygons of the states or countries, because we do not have any corresponding data for them. If we look at our data, we can see that we have the column that holds the zipcodes of the corresponding crash locations. This is perfect, because we can calculate the number of accidents per zipcode and then get the corresponding polygons to nicely map that data. First thing we need to do is to download the polygons. Just paste this link into your browser and you will get the zip file that I prepared for you. The password is ‘shapeForBook’ (https://drive.google.com/open?id=1cAv35Epz3AMVCo-YwobsMiD_BAWaiU9M). Unzip the files into the project’s folder. The next thing we need to do is to get the data into the right shape, and we are good to go. # Grouping by zip and counting countByZip &lt;- crashesYear %&gt;% dplyr::group_by(zip) %&gt;% dplyr:: count() Before I show you how to add our count to the shapefile, lets just map the polygons that we downloaded. For this, we need to load the shapefiles into our environment first. We have already loaded the package ‘raster’. The ‘raster’ package has a function called shapefile(), which we will use. # shapefile() takes the path of the shapefile ourShape &lt;- raster::shapefile(&#39;shape/ZipCodes.shp&#39;) leaflet() %&gt;% addProviderTiles(providers$CartoDB.Positron) %&gt;% setView(lng = -74.0060, lat = 40.7128, zoom = 11) %&gt;% addPolygons(data = ourShape) Figure 11: Here is a nice figure! Ok, this works. However, it is empty. In order for this kind of map to be useful, we need colors of the polygons to be different. For that, we will need to use color paletts. A color palette is a range of colors from a collor ‘a’ to a color ‘b’. Here is an exapmle if you are confused: a zipcode ‘a’ has the smallest number of crashes (five) and a zipcode ‘b’ has the mose (one thousand), if we pick the blue-to-red palette the zipcode ‘a’ will be blue and the zipcode ‘b’ will be red, the rest of zipcode will turn into the different shades of these two colors. The topic of palettes is a big one and it takes practice to nail the colors right. For now, just follow my lead. Before we specify the palette, we need to left join our countByZip to the data file inside of the shapefile. We will be joining by the zipcode column. As you migh have noticed, the ‘ourShape’ file is not a standard dataframe. It is like a list of different files inside of it. The one we are interested is ‘data’. There are two ways to access the ‘data’ dataframe. We can either extract it, do the left join, and put it back; or do a straight left join using the ‘@’ character to access a column of a dataframe inside of a shapefile. Lets do the second one, because the first one is even more complicated. Do not worry, it only sounds complicated. The zip column inside of the shapefile is called ‘ZIPCODE’ and is in character string format. Lets reformat and rename the zip column of the ‘countByZip’ table to match the one in the shapefile. Then, we will be able to do a simple left join. Renaming the first column into ‘ZIPCODE’: # Renaming. colnames(countByZip)[1] &lt;- &#39;ZIPCODE&#39; Converting the first column into the character string. # To character. countByZip$ZIPCODE &lt;- as.character(countByZip$ZIPCODE) Doing a left join. Since the table ‘data’ is inside of the shapefile, we need to access it somehow. Luckily, with such shapefiles we can use the ‘@’ character just like we use ‘$’ character to access columns of dataframes. # Joining. ourShape@data &lt;- left_join(ourShape@data, countByZip) ## Joining, by = &quot;ZIPCODE&quot; Lets see what the first few lines of the table ‘data’ looks like now. # Printing. print(head(ourShape@data)) ## ZIPCODE BLDGZIP PO_NAME POPULATION AREA STATE COUNTY ST_FIPS ## 1 11436 0 Jamaica 18681 22699295 NY Queens 36 ## 2 11213 0 Brooklyn 62426 29631004 NY Kings 36 ## 3 11212 0 Brooklyn 83866 41972104 NY Kings 36 ## 4 11225 0 Brooklyn 56527 23698630 NY Kings 36 ## 5 11218 0 Brooklyn 72280 36868799 NY Kings 36 ## 6 11226 0 Brooklyn 106132 39408598 NY Kings 36 ## CTY_FIPS URL SHAPE_AREA SHAPE_LEN n ## 1 081 http://www.usps.com/ 0 0 366 ## 2 047 http://www.usps.com/ 0 0 932 ## 3 047 http://www.usps.com/ 0 0 1720 ## 4 047 http://www.usps.com/ 0 0 689 ## 5 047 http://www.usps.com/ 0 0 898 ## 6 047 http://www.usps.com/ 0 0 1655 Perfect. We added the column ‘n’ with the count of accidents per zipcode per year. Now we can create a palette and map the data. There are a few ways to create a palette. The two that you should start with are the functions colorNumeric() and colorBin(). We will be using the colorNumeric() function. The function colorNumeric() takes two inputs, the palette (There are a few of them, just google ‘R color cheatsheet’, they are at the bottom), a the domain. The domain is, basically, the numeric range that you are using to distribute colors. Our domain, for example, is the column ‘n’ (ourShape@data$n). The range from the smallest number there to the highest is the domain for us. We will use the ‘Blues’ palette. So, the zipcode with the smallest number of crashes will take the lighest shade of blue and the one with the highest number of crashes will be the darkest. # Creating the palette. pal &lt;- colorNumeric(palette = &quot;Blues&quot;, domain=ourShape@data$n) leaflet() %&gt;% addProviderTiles(providers$CartoDB.Positron) %&gt;% setView(lng = -73.809354, lat = 40.737084, zoom = 11) %&gt;% # This time, the map will recognize the color difference based # on the palette. The sintax &#39;~pal(n)&#39; might look weird right # now. It is Do not worry about it now. This is how you will # be specifying it from now on in leaflet. addPolygons(data = ourShape, color = ~pal(n)) Figure 12: Here is a nice figure! Sweet. However, the boundaries are all blurry and colors are watered down. I do not like it. The function addPolygons() has a few more parameters that will make that will make this map look amazing. The first one is ‘weight’. Weight is responsible for the thickness of the polygone boundaries. I have experimented with this parameter a lot and found that 1.3 is a good number. The second parameter is ‘fillOpacity’. The fillOpacity determines how transparent the polygons are. Right now, they are too transparent and we do not see the contrast, however, we do not want to make them completely solid, because, we still want too see the street names when we zoom in, for example. 0.7 is a good number. leaflet() %&gt;% addProviderTiles(providers$CartoDB.Positron) %&gt;% setView(lng = -73.809354, lat = 40.737084, zoom = 11) %&gt;% addPolygons(data = ourShape, color = ~pal(n), # Adding fillOpacity and weight fillOpacity = 0.7, weight = 1.3) Figure 13: Here is a nice figure! This is really good now. We can clearly see where the most car crashes happened in 2019. There are two missing things here, though. We must have a color reference to see what each color corresponds to, at least approximately. It would also be good to be able to click on a polygon and get a popup with some basic info. The first one is the ‘popup’ parameter of the addPolygons() function. It works just the same as in the addMarkers() function from before. I will complicate the popup a bit to make it more informative. The info that I want to display are the zipcodes and the number of crashes. I, also, want to prefix that info with corresponding titles, and I want to have them on separate lines. To do that, I will use the function paste0() to add the strings ‘zip’ and ‘crashes’ in front of the actual values. Additionaly, to have them on separate lines, we have to add an html tag ‘’ between them. Try with and without the tag to see the difference. After we done with that, we will want to add a legend (color reference). Leaflet provides the function addLegend() for this. This function takes position, palette, corresponding values, opacity, and tile as arguments. We will positiion it in the bottom right corner. See if you can position it in a different corner. I also, want to show you a defferent color palette (‘YlOrRd’). # Different palette. pal &lt;- colorNumeric(palette = &quot;YlOrRd&quot;, domain=ourShape@data$n) leaflet() %&gt;% addProviderTiles(providers$CartoDB.Positron) %&gt;% setView(lng = -73.809354, lat = 40.737084, zoom = 11) %&gt;% addPolygons(data = ourShape, color = ~pal(n), fillOpacity = 0.7, weight = 1.3, # Pasting together the prefixes and values, as well as # placing them on two lines. popup = paste0(&quot;Zip: &quot;, ourShape@data$ZIPCODE, &quot;&lt;br&gt;&quot;, &quot;Crashes: &quot;, ourShape@data$n)) %&gt;% # Adding a legend addLegend(&quot;bottomright&quot;, pal = pal, values = ourShape@data$n, title = &quot;Car Crashes&quot;, opacity = 0.8 ) Figure 14: Here is a nice figure! This is really usefull now. We are almost there. There are a couple more things that are not super essential. That is if you are a noob. To make people who are checking out your maps pee their pants, you absolutely must have the next two things that I am about to show you. The first one is the highlight option. If you hover over the map now, it is not clear which polygon is selected (especially if polygones are small). The highlight option solves this problem. The highlight options is a part of the addPolygons() function. The sintax is as follows: ‘highlightOptions = highlightOptions(weight = …, color = …, bringToFront = True)’. The weight is the thickness of the outline, the color is the color, and the ‘bringToFront’ parameter makes sure that the highlight does not get lost somehow. Before I explain the second thing that I want to add, lets add this one. leaflet() %&gt;% addProviderTiles(providers$CartoDB.Positron) %&gt;% setView(lng = -73.809354, lat = 40.737084, zoom = 11) %&gt;% addPolygons(data = ourShape, color = ~pal(n), fillOpacity = 0.7, weight = 1.3, popup = paste0(&quot;Zip: &quot;, ourShape@data$ZIPCODE, &quot;&lt;br&gt;&quot;, &quot;Crashes: &quot;, ourShape@data$n), # Adding the highlightOptions highlightOptions = highlightOptions(weight = 4, color = &quot;white&quot;, bringToFront = TRUE)) %&gt;% addLegend(&quot;bottomright&quot;, pal = pal, values = ourShape@data$n, title = &quot;Car Crashes&quot;, opacity = 0.8 ) Figure 15: Here is a nice figure! We are almost done. As far as leaflet goes, this is pretty much what you need for most of your tasks. I know, this might seem like a lot when taking in all at once, but It does not seem that bad when you layer things gradually. That is what we did. Using this template, you can create your own maps. There are many more bells and whissles and other capabilities that you can layer. You should be able to figure them out referencing what we just covered. As a bonus, I want to show you how to display multiple months of data using the same polygon map. That should show you, both, opportunity for creating really interactive stuff in R, as well as the limitations for working with just maps. Lets create three dataframes, each holding one month of crashes. We have already pulled the one year of data. We just need to filter for the correct month and count crashes again. We are basically, repeating the same steps that we did but for the whole year. # Changing the date format from character to date crashesYear$date &lt;- ymd(crashesYear$date) # Filtering only for the month of Jan crashes201901 &lt;- crashesYear %&gt;% dplyr::filter(date &gt;= &#39;2019-01-01&#39; &amp; date &lt; &#39;2019-02-01&#39;) # Filtering only for the month of Feb crashes201902 &lt;- crashesYear %&gt;% dplyr::filter(date &gt;= &#39;2019-02-01&#39; &amp; date &lt; &#39;2019-03-01&#39;) # Filtering only for the month of Mar crashes201903 &lt;- crashesYear %&gt;% dplyr::filter(date &gt;= &#39;2019-03-01&#39; &amp; date &lt; &#39;2019-04-01&#39;) # Grouping by zip and counting crashes201901 &lt;- crashes201901 %&gt;% dplyr::group_by(zip) %&gt;% dplyr:: count() # Grouping by zip and counting crashes201902 &lt;- crashes201902 %&gt;% dplyr::group_by(zip) %&gt;% dplyr:: count() # Grouping by zip and counting crashes201903 &lt;- crashes201903 %&gt;% dplyr::group_by(zip) %&gt;% dplyr:: count() As you can see, we just repeated the same stuff that we did a few paragraphs before. Some ‘real’ programmers will tell you that you should not repeat your code more than two or three times. While it is true when you know what the hell you are doing, in my opinion, it is impossible to learn that way. The topic of functions and loops are too complicated for beginners and you should tell those ‘masters’ of code to go screw themselves. You will eventually learn how to optimize your code. For now, repetition is good. In the next chunk of code, we will do exactly the same. We got three months of data. Now, we need to join each month with its own shapefile. So, again, we will repeat the steps (multiplied by three) that we took to get the shapefile and join it with our data. # Renaming the first column (three times) colnames(crashes201901)[1] &lt;- &#39;ZIPCODE&#39; colnames(crashes201902)[1] &lt;- &#39;ZIPCODE&#39; colnames(crashes201903)[1] &lt;- &#39;ZIPCODE&#39; # Converting the ZIPCODE column into character (three times) crashes201901$ZIPCODE &lt;- as.character(crashes201901$ZIPCODE) crashes201902$ZIPCODE &lt;- as.character(crashes201902$ZIPCODE) crashes201903$ZIPCODE &lt;- as.character(crashes201903$ZIPCODE) # Loading the shapefile three times into different variables ourShape201901 &lt;- raster::shapefile(&#39;shape/ZipCodes.shp&#39;) ourShape201902 &lt;- raster::shapefile(&#39;shape/ZipCodes.shp&#39;) ourShape201903 &lt;- raster::shapefile(&#39;shape/ZipCodes.shp&#39;) # Joining three times ourShape201901@data &lt;- left_join(ourShape201901@data, crashes201901) ## Joining, by = &quot;ZIPCODE&quot; ourShape201902@data &lt;- left_join(ourShape201902@data, crashes201902) ## Joining, by = &quot;ZIPCODE&quot; ourShape201903@data &lt;- left_join(ourShape201903@data, crashes201903) ## Joining, by = &quot;ZIPCODE&quot; Great. We got three shapefiles. Now, we can just add each as a separate addPolygons() function. It will look like a lot of code, but we are just copying and pasting it three times one after another. The only two differences will be the shapefile name and we will need to add a grouping name. So the first addPolygons() will look something like this: addPolygons(data = ourShape201901, group = ‘2019-01’, there rest is the same). On top of that, we will need to add the addLayersControl() function. This function will let us switch between the polygons. You will see once it is rendered. # Using ourShape201903 randomly. You can use any one of three. pal &lt;- colorNumeric(palette = &quot;YlOrRd&quot;, domain=ourShape201903@data$n) leaflet() %&gt;% addProviderTiles(providers$CartoDB.Positron) %&gt;% setView(lng = -73.809354, lat = 40.737084, zoom = 11) %&gt;% # Adding the first layer of polygons addPolygons(data = ourShape201901, color = ~pal(n), fillOpacity = 0.7, weight = 1.3, # We must include group so we can switch between them. group = &quot;2019-01&quot;, popup = paste0(&quot;Zip: &quot;, ourShape201901@data$ZIPCODE, &quot;&lt;br&gt;&quot;, &quot;Crashes: &quot;, ourShape201901@data$n), highlightOptions = highlightOptions(weight = 4, color = &quot;white&quot;, bringToFront = TRUE)) %&gt;% # Same as with the previous polygones. The shapefile is # different addPolygons(data = ourShape201902, color = ~pal(n), fillOpacity = 0.7, weight = 1.3, # Different group. group = &quot;2019-02&quot;, popup = paste0(&quot;Zip: &quot;, ourShape201902@data$ZIPCODE, &quot;&lt;br&gt;&quot;, &quot;Crashes: &quot;, ourShape201902@data$n), highlightOptions = highlightOptions(weight = 4, color = &quot;white&quot;, bringToFront = TRUE)) %&gt;% # Same as with the previous polygones. The shapefile is # different addPolygons(data = ourShape201903, color = ~pal(n), fillOpacity = 0.7, weight = 1.3, # Different group. group = &quot;2019-03&quot;, popup = paste0(&quot;Zip: &quot;, ourShape201903@data$ZIPCODE, &quot;&lt;br&gt;&quot;, &quot;Crashes: &quot;, ourShape201903@data$n), highlightOptions = highlightOptions(weight = 4, color = &quot;white&quot;, bringToFront = TRUE)) %&gt;% addLegend(&quot;bottomright&quot;, pal = pal, values = ourShape201903@data$n, title = &quot;Car Crashes&quot;, opacity = 0.8) %&gt;% # Here, we must use the names that we gave to the groups so we can # switch between them. Collapsed = FALSE means visible. addLayersControl(baseGroups = c(&quot;2019-01&quot;, &quot;2019-02&quot;,&quot;2019-03&quot;), options = layersControlOptions(collapsed = FALSE)) Figure 16: Here is a nice figure! This map is complete now. You can say that it is not a hundred percent accurate, because there were a lot of NAs in the ZIPCODE column, and you would be correct. There is a way to fix that. If there is no zipcode, but there is a set of coordinates, we could still geocode a zipcode from coordinates. It is an advanced technique and I will not be explaining it in this book. Just know that it is possible. The final code looks complicated if you see it as one chunk of code. I hope, you do not. I purposly extended this chapter to show you how a map like this is constructed. Instead of creating it all at once, you will usually layer it one step at a time. If you scroll through the layers that we been gradually adding, you will see that it is not complicated at all. Ultimatelly, we went from a single line leaflet() to the 30+ liner interactive map with multiple layers. With some practice, you will have enough chunks that you will be able to take from one project to the next without creating a single map from scratch. This is it. You completed the maps section. The stuff that we covered in this section should give you a good foundation about static and, most importantly, interactive maps. Maps are exteremely important. For example, seventy percent of my first year learning R revolved around maps in some way. In the next books, we will be spending a lot more time dealing with maps. Knowing how to map and geocode will give you a different angle in the field of data. It will make your progress more enjoyable, because of the interactive nature of data handling. At the same time, it will put you a step above your competition. In the next chapter we will use both maps and plots that we created to generate an html visualization. It will be a report similar to the one we did at the end of the ‘Big Assignment’. We will not be using the markdown this time, although, the sintax and the format will be similar. This time, we will use the package called ‘flexdashboard’. We will use the crash data to create an informative dashboard that you will be able to use as a reference for your future projects. Lets go. R, Not the Best Practices by Nikita Voevodin is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. "],
["flexdahsboard.html", "FlexDahsboard 0.22 Data 0.23 Layouts 0.24 Conclusion", " FlexDahsboard You are back at work. Your completed your first major assignment and really impressed you superiors. You had a bit more free time and since you did not want to waste it, you spent that time learning interactive mapping techniques. You have built a few prototypes and even showed them around at work. People there are impressed that you continue developing but your place is very bottomline oriented and you start hearing questions like: ‘how can we use a map like this?’ or ‘can we create a dashboard around it?’. After the euphoria of learning something new and cool subsides, you should really start thinking about the utility of you work. Producing scattered visualizations is ok, however, you work will be valued much more if you also include a presentational component to it. What kind of presentational component? Am I not fucking amazing already? You are. Compared to yourself who did not know shit just a few weeks ago, that is. So, put aside your imagined glory and lets learn another cool presentation tool. It is called ‘flexdashboard’, and it is similar to the Rmarkdown that we covered at the end of the main assignment. The difference is the layout arrangement. The Rmardown is a report type of document where informations is presented vertically paragraph after paragraph. The flexdashboard lets you create a real dashboard with tabs, buttons, dropdowns, etc. It is as static as a markdown, however, if you dive deeper into it, there is a way to make it truly dynamic. We will not be doing that just yet, though. In this section, again, we will learn just enough about the topic so we can add it to our arsenal of R tools. Before we begin, I want to say that flexdashboard is definitely a useful tool that you should know about. For me personally, it was a stepping stone to the next and the biggest for me topic ‘RShiny’. The flexdashboard is great to create a quick report in the dashboard format, but it lacks the features that I was looking for when I was learning. I used it twice during my first year of working with R. The first time is for this: https://medium.com/@NYCTLC/visualizing-taxis-and-for-hire-vehicle-models-in-nyc-19278ad23466 and particularly for this dashboard: https://tlc_blog_posts.gitlab.io/word_cloud/car_cloud1.html. The second time was to generate a seriously complicated report for the TLC DATA HUB that I created for the Taxi and Limousine Commission of New York City here: https://tlcanalytics.shinyapps.io/tlc_dash/ (the button ‘Download This Page’ will generate a flexdashboard report). Although, I am saying that it lacks the functionality that I wanted, without knowing it, I would not be able to generate that kind of sophisticated report for the TLC DATA HUB. Anyway, I want you to create a new project. You should know how by now. If not, go back. In the new project, open a new R file and install the flexdashboard package. install.packages(&#39;flexdashboard&#39;) Before we start working on the dashboard, we need to get the data ready again. 0.22 Data We need to load the libraries and connect to the database again. After that, we will prepare three datasets that we will display using the dashboard. The first dataset will have crashes per zipcode in 2019, and we will use it for the map. The second dataset will have crashes per month in 2019 and we will create a ggplotly bar plot out of it. The third dataset will have the total number of injured and the total number of killed in those crashes. We will use these numbers for value boxes. Value boxes are important, you will see what they look like. # Loading the libraries library(lubridate) library(data.table) library(dplyr) library(tidyr) library(tibble) library(RMySQL) # Connecting to the database connection = dbConnect(drv = MySQL(), user = &quot;xxx&quot;, password = &#39;xxx&#39;, host = &#39;mybookdatabase.cgac79lt7rx0.us-east-2.rds.amazonaws.com&#39;, port = 3306, dbname = &#39;nikita99&#39;) # Pulling initial data crashes2019 &lt;- dbGetQuery(connection, &quot;SELECT * FROM book_pdData WHERE date &gt;= &#39;2019-01-01&#39; and date &lt; &#39;2020-01-01&#39; &quot;) # The first dataset byZip &lt;- crashes2019 %&gt;% dplyr::group_by(zip) %&gt;% count() # The second dataset byMonth &lt;- crashes2019 byMonth$date &lt;- lubridate::ymd(byMonth$date) byMonth$date &lt;- lubridate::floor_date(byMonth$date, &#39;month&#39;) byMonth &lt;- byMonth %&gt;% dplyr::group_by(date) %&gt;% count() # The third dataset injuredAndKilled &lt;- crashes2019 %&gt;% dplyr::summarise(injured = sum(injured), killed = sum(killed)) # Saving the datasets fwrite(byZip, &#39;byZip.csv&#39;) fwrite(byMonth, &#39;byMonth.csv&#39;) fwrite(injuredAndKilled, &#39;injuredAndKilled.csv&#39;) 0.23 Layouts Flexdashboard provides multimple layout patterns, however, since this is only a functional introduction to the topic, I will show you only the two layouts that I like the most, the column-based and the row-based. I will show you how to create both layouts using the same data. You do not have to create both. Just pick the one that you prefer (row or column based). To create a flexdashboard, you need to go to ‘File’ -&gt; ‘R Markdown..’ -&gt; ‘From Template’ -&gt; ‘Flex Dashboard’. Name it something and click ‘OK’. New session. 0.23.1 Column based When we hit ‘OK’, Rstudio give as a column based template, which is cool. Lets explore it. The flexdashboard has similar structure to the Rmarkdown. It has the same five components that the markdown has. The difference is the layout. Below, I highlighed the areas that are different. You can see two main differences: Special sintax for specifying columns (or rows if the dashboard is row-based), and the tripple hashes. The tripple hashes create boxes in the flexdashboard. As you might recall, in a simple markdown a tripple hash sign specifies the smallest title. Enough reading, you will understand better if you just knit this dashboard. Go agead and press ‘Knit’. New session. New session. There you go. We got an empty dashboard. The whole layout thing should become clear now. We got the main header (blue top bar) that displays the title and three boxes that we created in the layout. As far as I know, the width of a page in R, usually, adds up to 1200px or 12, depending on the context. It does not strictly apply to the flexdahsboard for some reason. In the template, we can see that the widths of two columns add up to a thousand. Even if you change the width of one of the columns to, lets say, 5000, it wont break it. Instead, it resizes proportionally. What does it mean? Means that you will have to experiment with sizes. It is not a real problem, though, so, lets move on. Lets actually insert our crash map into the main window. Before we are able to recreate the map from the last chapter, we need to load the libraries that we will be using. They are the libraries that we have been using so far. You can just copy and paste them from our previous projects, or you can type them if you want. Use the illustration below as reference. Make sure you have all of them installed and loaded. New session. Now that we got the libraries down, lets prepare the data for the map. We have already done all these steps in the previous chapter, so you can just copy and paste them into the chunk. Use the illustration below as reference. New session. The data are ready. Now, literally, just copy the map code from the previous chapter and paste in the first empty chunk provided in the template under the ‘### Chart A’. Use the illustration below as reference. New session. We have anough code in there to see some nice results already. Lets knit the documnet to see what it looks like at this stage. Press ‘Knit’. New session. This is really good already. The structure is there. The map is fully interactive. We are half way there. Lets load the second dataset. It will serve as the base for the bar plot that we will fit into the second box of the dashboard. The second one is much easier, because we do not need to agregate and join anything. When we will read it in, the date column will turn into character. We will need to revert it back to date. Reference the illustration below. New session. Once the data are in, we need to build our plot. The plot that we want to build here will be almost axactly the same as the bar plot that we built at the end of the our big assignment. Go and find that plot. It is called ‘ourBarPlot’. Copy it and paste into the second empty chunk provided in the template under the ‘### Chart B’. There are a couple of things to change here. First, add the ‘fill = “blue”’ parameter to the geom_bar() function. This will change the color of our bars to blue. You can pick a different color if you want. It will be dark grey if we will not include it. Second, change the title to ’’ (empty). We will later rename the ‘### Chart B’ to something else, and we do not want to have two titles there. Finally, wrap the ‘ourBarPlot’ in the ggplotly() function to turn the ggplot2 into plotly. Reference the illustration below. New session. Once you done, knit the dashboard to see what we got. New session. We got two interactive elements that we learned in the last two chapters. Lets fill the third box. Remember I mentioned some value box and that it was important. Lets see what it is. Value boxes are great for highlighting important numbers. You can assign different colors to them and even add icons. It will be better if I just show you. Lets import the third dataset first. No modifications this time. Reference the illustration below. New session. Now, paste the following code in the empty chunk provided by the template under the ‘### Chart C’: valueBox(injuredAndKilled$injured, icon = ‘fa-angry’, color = ‘warning’). What does this mean? Well, the valueBox() is the function for value boxes. It takes the number (which is contained in the column ‘injured’ of the table ‘injuredAndKilled’), icon (we are using the fontawesome icon library, here is the link for more information: https://fontawesome.com/icons?d=gallery), and color. You might wonder, what does color = ‘warning’ mean? It is the bootstrap-library standard color. You will learn about bootsrap in the future. For now, just know that bootstrap is a styling library developed by tweeter for web developement. There are just a few standard colors in bootstrap. For instance, warning means orange. New session. Lets knit and see what we got. New session. Great. As you can see, we got an orange value box displaying the number of injuries in a big fat font with an angry face icon. Value boxes are extremely important, because they can highligh the most important numbers in your report or dashboard. Lets add the second value box displaying the number of killed. We will use red color and some different icon for it. If we just add another chunk with similar code, the value boxes will overlap for some reason. We need to add ‘### Chart D’ for the second value box to be properly displayed. It does not have to be ‘Chart D’ precisely, it be called anything. We will rename them all later. Use the illustration below as reference. New session. We are almost done here. Lets knit and see what everything looks like. New session. Perfect. We are done here. One last thing to do is to change the names of the boxes from Chart A,B,C, and D to proper names. For example, instead of ‘### Chart A’ I wrote ‘### Number of Car Accidents by Zipcode in 2019’. You can rename them as you see fit. Use the illustration below as reference for the names. New session. This is it for the row-based flexdashboard. It looks really good and is informative anough to share with others. You should have an html file with this dashboard in your project’s folder. That html can be opened by most browsers and is small enough to be shared via email. 0.23.2 Row based We will not have to change much to switch from the column-based layout to the row-based. Go the the hat of the document and change the orientation parameter to ‘rows’. See the illustration below. New session. In the body, change ‘Column’ to Row and instead of data-width = … write data-height = … . You can knit the document now, but you will see that the layout is not great at all. We will have to move our bar plot from the second row to the first one. Do it according to the illustration below. Once done, knit the document to see what it looks like. New session. It is better but the value boxes are too tall. Change the height of the second row to 150 like below. New session. We should be go to go. Knit. New session. Good. This is usable but I prefer the column-based one. 0.24 Conclusion In this section we covered everything that you need to really get started with this cool tool. There are more than just two layouts that I showed you here. However, these two are the easiest to get started with. You should use them as baselayers for your experimentations. As I said a few times here, it is much much easier to take a working prototype and start layering thing on top. You can do interesting things with flexdashboard. You can add tabs to boxes and even add multiple pages. At the moment, it should be impressive for you, but you will quickly realize, just like I did, that flexdashboard can not do all the thing that you want. Therefore, there is no point in trying to truly master it. Instead, it makes sence to practive with it a little bit, add it to your toolbox, and move on to the topic of web applications. This is the end of this book. I will not be teaching you anything else here. Instead, as a bonus, I want to show you a little preview of what we will be doing in the next books. R, Not the Best Practices by Nikita Voevodin is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. "],
["shiny-bonus.html", "Shiny (Bonus)", " Shiny (Bonus) Straight from the RStudio website: “Shiny is an R package that makes it easy to build interactive web apps straight from R. You can host standalone apps on a webpage or embed them in R Markdown documents or build dashboards. You can also extend your Shiny apps with CSS themes, htmlwidgets, and JavaScript actions.” This is a bonus section, so I will not teach you anything here. I just want to talk about the Shiny package or framework if we can call it that. Shiny is a package, however, it is so big and spun so many additions that I want to call it a framework. If you do not know what a framework is, it is something between a package and a whole new language. Anyway, Shiny is big and it has its own special sintax. That is why I want to call it a framework. Around the time when I was messing around with maps and flexdashboards, I started to run into some limitations of static code. I could only display data once. If, for example, I wanted to change a timeline on a plot, I needed to re-aggregate my data and re-render the plot again. Basically, I needed a new script. I thought, ‘It would be cool if I just could add a slider or a switch to the flexdashboard that would do something like that.’ I was told that there is a solution, the package called ‘Shiny’. I thought, ‘What a stupid name.’ Still think that. Why not ‘Pink Unicorn’? I would name it ‘the Plague’ or ‘the Archangel’ or something cool like that. Anyway, I started learning Shiny and it was amazing. Basically, in a matter of days, I turned from a data genetor to a web app developer. It was definitely hard and it took me many months, but even in the beginning, I knew that this is how I will learn the rest of R. Below is the generic Shiny App that uses data that RStudio provides for us. The app does not do much, but you can already see reactivity. Just copy the code and paste it into a new R script and it will render an app. # Installing shiny install.packages(&#39;shiny&#39;) library(shiny) # Define UI for application that draws a histogram ui &lt;- fluidPage( # Application title titlePanel(&quot;Old Faithful Geyser Data&quot;), # Sidebar with a slider input for number of bins sidebarLayout( sidebarPanel( sliderInput(&quot;bins&quot;, &quot;Number of bins:&quot;, min = 1, max = 50, value = 30) ), # Show a plot of the generated distribution mainPanel( plotOutput(&quot;distPlot&quot;) ) ) ) # Define server logic required to draw a histogram server &lt;- function(input, output) { output$distPlot &lt;- renderPlot({ # generate bins based on input$bins from ui.R x &lt;- faithful[, 2] bins &lt;- seq(min(x), max(x), length.out = input$bins + 1) # draw the histogram with the specified number of bins hist(x, breaks = bins, col = &#39;darkgray&#39;, border = &#39;white&#39;) }) } # Run the application shinyApp(ui = ui, server = server) It is not our goal here to understand the code, but, if you are curious, below is a diagram of what each chunk does. Shiny structure. This is what this generic app should look by the way: Shiny structure. Lets take one of the datasets that we saved a while ago and generate our own app by modifying that generic code. First, I will load the libraries that I will need: library(shiny) library(data.table) library(dplyr) library(lubridate) library(ggplot2) library(ggthemes) library(scales) library(plotly) Then, I will load some data that we saved a while ago. I think, that dataset holds average ages of incoming vehicles by month. I will modify the generic app code to show the plotly plot while being able to filter it with a double slider. Will not explain how, though, as this is just a demonstration. ui &lt;- fluidPage( # Application title titlePanel(&quot;Avg. Age of New Vehicles&quot;), # Sidebar with a slider input for number of bins sidebarLayout( sidebarPanel( sliderInput(&quot;monthdate&quot;, &quot;Choose a Date Range&quot;, min = min(forBarPlot$date), max = max(forBarPlot$date), value = c(min(forBarPlot$date), max(forBarPlot$date)), timeFormat=&quot;%b %Y&quot;) ), mainPanel( plotlyOutput(&quot;plot&quot;) ) ) ) server &lt;- function(input, output) { # Dynamically filtering the dataset based on slider values and storing it # in the &#39;data&#39; variable. data &lt;- reactive({ forBarPlot %&gt;% dplyr::filter(date &gt;= input$monthdate[1], date &lt;= input$monthdate[2]) }) # Plotting. ggplotly( ggplot(data(), aes(date, age)) + geom_bar(stat = &quot;identity&quot;) + labs(title=&quot;Incoming Cars (by age)&quot;, x=&quot;Date (month)&quot;, y=&quot;Age&quot;) + scale_x_date(labels = date_format(&quot;%Y-%b&quot;), breaks = date_breaks(&quot;1 months&quot;)) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + theme_hc() ) } # Run the application shinyApp(ui = ui, server = server) This is what our app ‘new cars’ app should look like: Shiny structure. Great! We built an app. What now? It is a good start. Keep practicing and in six to eight months you will be able to build this: TLC Data Hub. At least, that is how long it took me. This was just a glimpse of what is comming in the next books. This app lives on your computer now. It will not open on anybody elses computer unless that computer has R installed along with everything that you used to created this app. To share a Shiny app, you need to host it. That and many other techniques and tricks will be covered in the next books. R, Not the Best Practices by Nikita Voevodin is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. "],
["final-thoughts.html", "Final Thoughts", " Final Thoughts Congradulations! You have made it to the end of the book. You have followed the first three months of my path to R proficiency. Hopefully, you armed yourself with the things that I showed you in this book. If you did, then you are not completely useless as a data something, anymore. You better not be, because three months is about all get to be tollerably useless. Beyond that, you will quickly find yourself on the bench of your data team. Believe me, in the world where this field is the new gold mine, you do not want to become a bench warmer. This is a slippery slope that will, eventually, result in you crawling on the floor of your sublet studio looking for rats to eat. There are, definitely, many job openings rignt not as there is a shortage of skill in the field, but do not give yourself too much time because of that as that shortage will quickly decrease. Before I say: “In all seriousness, you have accomplished quite a lot here. I wish you a good luck and happy birthday, you are like a brother to me, and I want to see you in the next book. Good bye!”, I would, first, like to go over the things that we have covered in this book. For each thing, I will add a few personal thoughts, so it does not become a stupid repetition of the same shit. We began with a general overview of the programming world and R’s place in it. In partucular, we learned that if we want to make it in the field of data analysis or engineering, we must leave behind things like Excel, SPSS, STATA, and SAS, and focus on real languages like R, Python, and SQL. We also got more familiar with what other languages do in general and what kind of infrastructure we will ever be dealing with while learning R. Personal take on this: It is important to know what is out there and what surrounds the language you are learning. The faster you become aware of these things, the less distracted you will be by that temptation of unknown. By the temptation of unknown, I mean the stuff that I talked about in the ‘Tutorial Purgatory’ section. In my opinion, it is very important to know what you do not know, so you understand the scope of your challenge. In the beginning, anything new that you are learnign seems bigger than it is, because you do not know that scope. Once you realize that there are five, ten, or twenty things that you need to know, you can start moving towards the end more confidently. That was my experience, at least. In the second chapter, we learned to work with the RStudio. We installed R and RStudio; got familiar with the layout; created new scripts; saved them; opened multiple sessions; installed and removed packages; wrote our first code; uninstalled and reinstalled RStudio; and messed with RStudio, in general, to see what happens. Personal take on this: Learning basics of R and RStudio was the obvious part that any book or tutorial would teach you. There was nothing special about it, so I do not want to even mention it. The important thing that I wanted to accomplish in that part was to eliminate the fear of messing something up in your code or session. I remember the feeling of opening RStudio for the first time and being affraid to mess it up. That fear really hinders progress, so I wanted to kick it out of you straigt away. Hopefully, it worked. Next, we covered our asses in terms of code basics. I do not really have anything special to say about that section. It was boring as fuck but necessary to cover. One important takeway though: factors are stupid as fuuuck, and you should stay away from them for awhile, untill you are a bulletproof programmer. Otherwise, you will suffer. The big assignment is where the majority of learning was happening, I hope. We went from receiving the task along with the complicated code; to running it line by line in order to understand what the fuck was going on; to rewriting and simplifying it to make it ours; to modifying and adding extra stuff to it; to aggregating, graphing, and wrapping it in a nice markdown report. Along the way, we used a great number of functions for extracting, transforming, loading, using, and saving our data. The few things that stand out in my head are: Connecting to and using a database; Using an API (Although, might still be too advanced right now); Diving deep in the lubridate package for working with dates and times; Learning about the ‘Tutorial Purgatory’; Building a few plots with ggplot2 and later converting them to plotly; Creating a markdown report, ready to be presented. Personal take on this: The big assignment chapter is what this book revolves around. The main part of my story happens in that part. In that chapter, I showed and described it to you 99% the way it actually happened. And if you thought that it was just one of the excercises along the way, it was not. The first assignment that I received when I just started at my job, created foundation for my overall progress as a programmer. My intention was to walk you the path that I walked, so that you start building similar foundation for yourself. Understanding this chapter is extremely important, because the stuff that we covered there will be 85-95% of what you will ever be doing as a data something guy. The end of the main assignment, we opened the doors to the topic of interactive and dynamic visualizations for us. We quickly skipped static maps, because they are really boring, and moved towards interactive mapping with leaflet. If you absolutely need to know static maps, there are specialized books for that topic out there. We worked with another dataset in that section. The dataset was quite big and that displayed some limitations of maps. We covered many different scenarios and found ways around the issues that we faced there. Overall, we covered the majority of the stuff that you will ever need on that topic, especially during your first year or so. Personal take on this: As I said, we opened the doors to the topic of interactive and dynamic visualizations. I do not want you to close those doors any time soon. Most of the things that I worked and am still working on involved some kind of interactive visualization, be it mapping or plotting. Seeing things move on the screed and knowing that you made them is a great source of inspiration and drive. That is important, because programming can get boring, and a lot of people burn out. After mapping, we got familiar with another reporting tool called flexdashboard. We learned how easy it is to, basically, create a website out of some plots and maps that we put together. We covered two types of layout, horisontal and vertical. There are more than just two, but with the foundation that you got from that chapter, you should be able to experiment with the rest of the layouts on your own, should you need to. Personal take on this: Honestly, at first, I did not see too much value in flexdashboard. I though, it was limiting in what I can do. During my learning process, I got familiar with it, did two or three small projects and brushed it aside. My eyes were on the bigger fish, RShiny. However, after some time, I began to understand the importance of being able to generate a quick and well laid out report or dashboard. At first, as a stand alone tool, it might not be super valuable, but once you learn things like dynamic steaming and data pyping, you will be able to combine them with flexdashboard, which will make you unstoppable. Overall, it is good that we learned it now. Finally, as a bonus, I showed you glimpse of what RShiny can do. We have not covered almost anything there as it is not the intention of this book. The next books are the ones where we will invest heavily into learning Shiny. We are done here. If you would like to report an issue, correction, or something else, here is the GitHub of this book: And, as promissed: In all seriousness, you have accomplished quite a lot here. I wish you good luck and happy birthday, you are like a brother to me, and I want to see you in the next book. Good bye! R, Not the Best Practices by Nikita Voevodin is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. "],
["references.html", "References", " References TLC Data Hub, https://tlcanalytics.shinyapps.io/tlc_dash/, Nikita Voevodin &amp; Fausto Lopez, 2019; TLC VIN Decoder, https://tlcanalytics.shinyapps.io/decoder/, Nikita Voevodin, 2019; TLC DataMeetup App, https://tlcanalytics.shinyapps.io/tasks/, Nikita Voevodin &amp; Fausto Lopez, 2019; Some definitions, https://rstudio.github.io/leaflet/, R Leaflet GitHub; Some definitions, https://rstudio.com/, RStudio; Some definitions, https://lubridate.tidyverse.org/ Lubridate docs; If I left you out in references, please, contact me at 471central@gmail.com. R, Not the Best Practices by Nikita Voevodin is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. "]
]
